
- [Sparse MoEs Meet Efficient Ensembles](https://arxiv.org/pdf/2110.03360.pdf), Google Brain.
- [Which Shortcut Cues Will DNN Choose? A Study from the Parameter-Space Perspective](https://arxiv.org/pdf/2110.03095.pdf), `shortcut` `spurious correlation`.
- [Double Descent in Adversarial Training: An Implicit Label Noise Perspective](https://arxiv.org/pdf/2110.03135.pdf), `learning under noise` `label flipping noise` `double descent`
- [Exploring Architectural Ingredients of Adversarially Robust Deep Neural Networks](https://arxiv.org/pdf/2110.03825.pdf), `nips` `robustness`
- [Creating Training Sets via Weak Indirect Supervision](https://arxiv.org/pdf/2110.03484.pdf), `iclr` `weakly-supervised learning`
- [Robustness and reliability when training with noisy labels](https://arxiv.org/pdf/2110.03321.pdf), `learning under noise`
- [Exploiting the Intrinsic Neighborhood Structure for Source-free Domain Adaptation](https://arxiv.org/pdf/2110.04202.pdf), `domain adaptation` `nips`
- [THE INFORMATION GEOMETRY OF UNSUPERVISED REINFORCEMENT LEARNING](https://arxiv.org/pdf/2110.02719.pdf), `reinforcement learning theory`
- [ANOMALY TRANSFORMER: TIME SERIES ANOMALY DETECTION WITH ASSOCIATION DISCREPANCY](https://arxiv.org/pdf/2110.02642.pdf), `ood detection`
- [Exploring the Limits of Large Scale Pre-training](https://arxiv.org/pdf/2110.02095.pdf), Google Research.
- [Noisy Feature Mixup](https://arxiv.org/pdf/2110.02180.pdf), `data augmentation`
- [UNIFYING LIKELIHOOD-FREE INFERENCE WITH BLACK-BOX SEQUENCE DESIGN AND BEYOND](https://arxiv.org/pdf/2110.03372.pdf), `likelihood free inference`
- [A Few More Examples May Be Worth Billions of Parameters](https://arxiv.org/pdf/2110.04374.pdf), `few-shot learning`, Facebook AI.
- [NORMFORMER: IMPROVED TRANSFORMER PRETRAINING WITH EXTRA NORMALIZATION](https://openreview.net/pdf?id=GMYWzWztDx5), `normalization` techniques.
- [BEIR: A Heterogeneous Benchmark for Zero-shot Evaluation of Information Retrieval Models](https://openreview.net/forum?id=wCu6T5xFjeJ), `information retrieval`
