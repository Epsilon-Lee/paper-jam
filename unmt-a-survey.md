
### Pretraining techniques

- [SemFace: Pre-training Encoder and Decoder with a Semantic Interface for Neural Machine Translation](https://aclanthology.org/2021.acl-long.348/), `acl2021`

### Lexicon induction

- [Data Augmentation with Unsupervised Machine Translation Improves the Structural Similarity of Cross-lingual Word Embeddings](https://aclanthology.org/2021.acl-srw.17/), `acl2021`
- [A Bidirectional Transformer Based Alignment Model for Unsupervised Word Alignment](https://aclanthology.org/2021.acl-long.24/), `acl2021`
- [Bilingual Lexicon Induction via Unsupervised Bitext Construction and Word Alignment](https://aclanthology.org/2021.acl-long.67/), `acl2021`

### Unsupervised NMT

- [Unsupervised Neural Machine Translation for Low-Resource Domains via Meta-Learning](https://aclanthology.org/2021.acl-long.225/), `acl2021`.
- [Unsupervised NMT with Generative Language Models Only](https://arxiv.org/pdf/2110.05448.pdf), `iclr 2022` submitted.
- [Multilingual Unsupervised Neural Machine Translation with Denoising Adapters](https://arxiv.org/pdf/2110.10472.pdf), Oct. 20 2021, NAVER Lab Europe. [tweet](https://twitter.com/ahmetustun89/status/1451501787450576901).
