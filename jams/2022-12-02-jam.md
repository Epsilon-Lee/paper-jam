
- [Algorithms for Acyclic Weighted Finite-State Automata with Failure Arcs](https://www.cs.jhu.edu/~jason/papers/svete+al.emnlp22.pdf), `emnlp2022`. `structured prediction`
- [Synergy Between Disentanglement and Sparsity: A Multi-Task Learning Perspective](https://arxiv.org/pdf/2211.14666.pdf), Nov. 26 2022. `future neural architecture`
- [What Learning Algorithm is In-Context Learning? Investigations with Linear Models](https://arxiv.org/pdf/2211.15661.pdf), Nov. 29 2022. `in-context learning` `interpretability`.
- [A Unifying Theory of Distance from Calibration](https://arxiv.org/abs/2211.16886), Nov. 30 2022. `calibration` `trustworthy`
- [Characterizing Verbatim Short-Term Memory in Neural Language Models](https://arxiv.org/abs/2210.13569), Oct. 24 2022.
  - Studies retrieval-based LMs, the essence of this type of memory-based methods.
- [Online Unsupervised Learning of Visual Representations and Categories](https://arxiv.org/pdf/2109.05675.pdf), May 28 2022.
  - The author of [semi-supervised prototype network](https://arxiv.org/abs/1803.00676), which has reaches 1000+ citations.'
- [Learning Structure from the Ground up---Hierarchical Representation Learning by Chunking](https://openreview.net/forum?id=c9IvZqZ8SNI), `iclr2022` rejected, but `nips2022` accepted.
  - New principle for self-supervised learning, chunking.
- [Is Conditional Generative Modeling all you need for Decision-Making?](https://arxiv.org/pdf/2211.15657.pdf), Nov. 28 2022.

### Representation learning

**Issues with representation learning**
> with an emphasis on text representation learning like word2vec, bert and seq2seq. Issues like depth severes unidentifiability/info redundancy, frequency severse bias to high-frequency tokens etc.

- [FRAGE: Frequency-Agnostic Word Representation](https://proceedings.neurips.cc/paper/2018/file/e555ebe0ce426f7f9b2bef0706315e0c-Paper.pdf), `nips2018`.
- [Representation Degeneration Problem in Training Natural Language Generation Models](https://arxiv.org/pdf/1907.12009.pdf), `iclr2019`.
- [GNN: Over-smoothing](https://disco.ethz.ch/courses/fs21/seminar/talks/GNN_Oversmoothing.pdf)
  - **Over-smoothing**: as model gets deeper, node features become similar everywhere.
- [Revisiting Over-smoothing in BERT from the Perspectives of Graph](https://openreview.net/pdf?id=dUV91uaXm3), `iclr2022`.

### Algorithmic game theory

- [Incentive-Aware Recommender Systems in Two-Sided Markets](https://arxiv.org/pdf/2211.15381.pdf), Nov. 23 2022. `recommender system` `algorithmic game theory`.
- [Similarity-based cooperation](https://arxiv.org/pdf/2211.14468.pdf), Nov. 26 2022. `multi-agent learning`

### LLMs

**In-context learning**

- [Teaching Algorithmic Reasoning via In-context Learning](https://arxiv.org/pdf/2211.09066.pdf), Nov. 15 2022.

**Evaluation**

- [Holistic Evaluation of Language Models](https://arxiv.org/pdf/2211.09110.pdf), Nov. 16 2022. `evaluation` `benchmark`

**Compositionality**

- [https://arxiv.org/pdf/2211.08473.pdf](https://arxiv.org/pdf/2211.08473.pdf), Nov. 15 2022.

### Few-shot learning

- [On Measuring the Intrinsic Few-Shot Hardness of Datasets](https://arxiv.org/pdf/2211.09113.pdf), Nov. 16 2022. `data-centric`.
  - *"To estimate. intrinsic few-shot hardness,  we then propose a simple and lightweight metric called Spread that captures the intuition that few-shot. learningis made possible by exploiting feature-space invariances between training and test samples"*
- [NANO: Nested Human-in-the-Loop Reward Learning for Few-shot Language Model Control](https://arxiv.org/pdf/2211.05750.pdf), Nov. 10. 2022. `interactive`.

### Comparing old goodies with dl

> Old goodies: svm, boosting (xgboost etc.)

-  [Language Model Classifier Aligns Better with Physician Word Sensitivity than XGBoost on Readmission Prediction](https://arxiv.org/pdf/2211.07047.pdf),  Nov. 12 2022.
