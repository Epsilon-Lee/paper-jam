
- [Learning Rich Rankings](https://arxiv.org/pdf/2312.15081.pdf), Dec. 22 2023. `l2r`.
- [The thermodynamics of prediction](https://arxiv.org/pdf/1203.3271.pdf), Oct. 5 2023.
- [Trajeglish: Learning the langauge of driving senarios](https://arxiv.org/pdf/2312.04535.pdf), Dec. 7 2023. `autonomous driving`.
- [Pearl: A Production-Ready Reinforcement Learning Agent](https://arxiv.org/pdf/2312.03814.pdf), Dec. 6 2023. [github](https://pearlagent.github.io/).
- [What planning problems can a relational neural network solve?](https://arxiv.org/pdf/2312.03682.pdf), Dec. 6 2023. `inductive bias`.
- [Distribution-Dependent Rates for Multi-Distribution Learning](https://arxiv.org/pdf/2312.13130.pdf), Dec. 20 2023. `multi-distribution learning`.
- [A Novel Metric for Measuring Data Quality in Classification Applications](https://arxiv.org/pdf/2312.08066.pdf), Dec. 13 2023.
- [Discovering modular solutions that generalize compositionally](https://arxiv.org/pdf/2312.15001.pdf), Dec. 22 2023.
- [A Weighted K-Center Algorithm for Data Subset Selection](https://arxiv.org/pdf/2312.10602.pdf), Dec. 17 2023. `data selection`.

### Interpretability

- [LETA: Learning Transferable Attribution for Generic Vision Explainer](https://arxiv.org/pdf/2312.15359.pdf), Dec. 23 2023.
- [Position Paper: Bridging the Gap Between Machine Learning and Sensitivity Analysis](https://arxiv.org/pdf/2312.13234.pdf), Dec. 20 2023.
- [Pyreal: A Framework for Interpretable ML Explanations](https://arxiv.org/pdf/2312.13084.pdf), Dec. 20 2023.

### Time series

- [Deep non-parametric time series forcaster](https://arxiv.org/pdf/2312.14657.pdf), Dec. 22 2023.
- [SutraNets: Sub-series autoregressive networks for long-sequence, probabilistic forecasting](https://arxiv.org/pdf/2312.14880.pdf), Dec. 22 2023.

### Generalization and optimization mysteries

- [Strong inductive biases provably prevent harmless interpolations](https://arxiv.org/pdf/2301.07605.pdf), Mar. 1 2023.
- [Understanding the Role of Optimization in Double Descent](https://arxiv.org/pdf/2312.03951.pdf), Dec. 6 2023.
- [On the Trajectories of SGD Without Replacement](https://arxiv.org/pdf/2312.16143.pdf), Dec. 26 2023.

### Distribution shift

- [Generative posterior networks for approximately Bayesian epistemic uncertainty estimation](https://arxiv.org/pdf/2312.17411.pdf), Dec. 29 2023.
- [Deep unsupervised domain adaptation for time series classification: A benchmark](https://arxiv.org/pdf/2312.09857.pdf), Dec. 18 2023.
- [When Model Meets New Normals: Test-time Adaptation for Unsupervised Time-series Anomaly Detection](https://arxiv.org/pdf/2312.11976.pdf), Dec. 19 2023.

### LLMs and beyond

- [Principled Gradient-based Markov Chain Monte Carlo for Text Generation](https://arxiv.org/pdf/2312.17710.pdf), Dec. 29 2023.
- [Large Language Models for Generative Information Extraction: A Survey](https://arxiv.org/pdf/2312.17617.pdf), Dec. 29 2023.
  - This might an entrance of useful information extraction techniques that can be applied to collection dialogues or same product identification task.
- [Using Large Language Models for Hyperparameter Optimizatio](https://arxiv.org/pdf/2312.04528.pdf), Dec. 7 2023.
- [AutoNumerics-Zero: Automated Discovery of State-of-the-Art Mathematical Functions](https://arxiv.org/pdf/2312.08472.pdf), Dec. 13 2023.

#### In-context learning

- [Can Transformers Learn Sequential Function Classes In Context?](https://arxiv.org/pdf/2312.12655.pdf), Dec. 21 2023.

#### Model merging

- [Merging by matching models in task subspaces](https://arxiv.org/pdf/2312.04339.pdf), Dec. 7 2023. [github](https://github.com/r-three/mats).
- [Concrete subspace learning based interference elimination for multi-task model fusion](https://arxiv.org/pdf/2312.06173.pdf), Dec. 11 2023.

#### Watermarks

- [On the learnability of watermarks for language models](https://arxiv.org/pdf/2312.04469.pdf), Dec. 7 2023. [github](https://github.com/chenchenygu/watermark-learnability).

#### Alignment

- [Teaching language models with canonical examples](https://openreview.net/pdf?id=SJwXWwc47T), `neurips2023`.
- [Learning and Forgetting Unsafe Examples in Large Language Models](https://arxiv.org/pdf/2312.12736.pdf), Dec. 20 2023.
- [What makes good data for alignment? A comprehensive study of automatic data selection in instruction tuning](https://arxiv.org/pdf/2312.15685.pdf), Dec. 25 2023.
- [Understanding data influence on context scaling: a close look at baseline solution](https://yaofu.notion.site/Understanding-data-influence-on-context-scaling-a-close-look-at-baseline-solution-eb17eab795dd4132b1a1ffe73f5e850a), Dec. 22 2023.

#### Scaling law

- [Scaling Laws for Reward Model Overoptimization](https://arxiv.org/pdf/2210.10760.pdf), Oct. 19 2022.
- [SOLAR 10.7B: Scaling large language models with simple yet effective depth up-scaling](https://arxiv.org/pdf/2312.15166.pdf), Dec. 23 2023.

#### Finetuning

- [Learn or Recall? Revisiting Incremental Learning with Pre-trained Language Models](https://arxiv.org/pdf/2312.07887.pdf), Dec. 13 2023.

#### Reasoning

- [Neural algorithmic reasoning](https://thegradient.pub/neural-algorithmic-reasoning/), Oct. 14 2023.




