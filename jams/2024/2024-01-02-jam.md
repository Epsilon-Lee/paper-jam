
- [Learning Rich Rankings](https://arxiv.org/pdf/2312.15081.pdf), Dec. 22 2023. `l2r`.
- [The thermodynamics of prediction](https://arxiv.org/pdf/1203.3271.pdf), Oct. 5 2023.
- [Trajeglish: Learning the langauge of driving senarios](https://arxiv.org/pdf/2312.04535.pdf), Dec. 7 2023. `autonomous driving`.
- [Pearl: A Production-Ready Reinforcement Learning Agent](https://arxiv.org/pdf/2312.03814.pdf), Dec. 6 2023. [github](https://pearlagent.github.io/).
- [What planning problems can a relational neural network solve?](https://arxiv.org/pdf/2312.03682.pdf), Dec. 6 2023. `inductive bias`.
- [Distribution-Dependent Rates for Multi-Distribution Learning](https://arxiv.org/pdf/2312.13130.pdf), Dec. 20 2023. `multi-distribution learning`.
- [A Novel Metric for Measuring Data Quality in Classification Applications](https://arxiv.org/pdf/2312.08066.pdf), Dec. 13 2023.
- [Discovering modular solutions that generalize compositionally](https://arxiv.org/pdf/2312.15001.pdf), Dec. 22 2023.
- [A Weighted K-Center Algorithm for Data Subset Selection](https://arxiv.org/pdf/2312.10602.pdf), Dec. 17 2023. `data selection`.
- [Anomaly component analysis](https://arxiv.org/pdf/2312.16139.pdf), Dec. 26 2023. `anomaly detection`.
- [Dataset Difficulty and the Role of Inductive Bias](https://arxiv.org/pdf/2401.01867.pdf), Jan. 3 2024. `inductive bias`.
- [Probability tools, tricks and miracles](http://www.stat.yale.edu/~pollard/Books/Pttm/), with the Pollard Lectures starting Oct. 2023. `David Pollard` [homepage](http://www.stat.yale.edu/~pollard/).
- [Gradient-based planning with world models](https://arxiv.org/pdf/2312.17227.pdf), Dec. 28 2023.
- [CARD: Classification and Regression Diffusion Models](https://arxiv.org/abs/2206.07275), `neurips2022`. [code](https://github.com/XzwHan/CARD).

### Inductive bias

- [On the hardness of learning under symmetries](https://arxiv.org/pdf/2401.01869.pdf), Jan. 3 2024.

### Trustworthy ml and interpretability

- [Automatic classification of model errors on ImageNet](https://arxiv.org/pdf/2401.02430.pdf), Nov. 13 2023. `model debugging` `error analysis`.
- [LETA: Learning Transferable Attribution for Generic Vision Explainer](https://arxiv.org/pdf/2312.15359.pdf), Dec. 23 2023. `attribution`.
- [Position Paper: Bridging the Gap Between Machine Learning and Sensitivity Analysis](https://arxiv.org/pdf/2312.13234.pdf), Dec. 20 2023.
- [Pyreal: A Framework for Interpretable ML Explanations](https://arxiv.org/pdf/2312.13084.pdf), Dec. 20 2023.
- [Interpretable and explainable machine learning methods for predictive process monitoring: A systematic literature review](https://arxiv.org/pdf/2312.17584.pdf), Dec. 29 2023.
- [Do Concept Bottleneck Models Obey Locality?](https://arxiv.org/pdf/2401.01259.pdf), Jan. 2 2024.

### Time series

- [Deep non-parametric time series forcaster](https://arxiv.org/pdf/2312.14657.pdf), Dec. 22 2023.
- [SutraNets: Sub-series autoregressive networks for long-sequence, probabilistic forecasting](https://arxiv.org/pdf/2312.14880.pdf), Dec. 22 2023.

### Generalization and optimization mysteries

- [Strong inductive biases provably prevent harmless interpolations](https://arxiv.org/pdf/2301.07605.pdf), Mar. 1 2023.
- [Understanding the Role of Optimization in Double Descent](https://arxiv.org/pdf/2312.03951.pdf), Dec. 6 2023.
- [On the Trajectories of SGD Without Replacement](https://arxiv.org/pdf/2312.16143.pdf), Dec. 26 2023.
- [Weak correlations as the underlying principle for linearization of gradient-based learning systems](https://arxiv.org/pdf/2401.04013.pdf), Jan. 8 2024.

### Distribution shift

- [Generative posterior networks for approximately Bayesian epistemic uncertainty estimation](https://arxiv.org/pdf/2312.17411.pdf), Dec. 29 2023.
- [Deep unsupervised domain adaptation for time series classification: A benchmark](https://arxiv.org/pdf/2312.09857.pdf), Dec. 18 2023.
- [When Model Meets New Normals: Test-time Adaptation for Unsupervised Time-series Anomaly Detection](https://arxiv.org/pdf/2312.11976.pdf), Dec. 19 2023.
- [Out of the ordinary: Spectrally adapting regression for covariate shift](https://arxiv.org/pdf/2312.17463.pdf), Dec. 29 2023.
  - _"we return to first principles and analyze how the closed-form solution for Ordinary Least Squares (OLS) regression is sensitive to covariate shift [...] characterize the out-of-distribution risk of the OLS model in terms of the eigenspectrum decomposition of the source and target data"_
- [Revisiting knowledge distillation under distribution shift](https://arxiv.org/pdf/2312.16242.pdf), Jan. 7 2024.
- [Causality and Invariance](https://ff13.fastforwardlabs.com/#causality-and-invariance), CLOUDERA online book `Causality for Machine Learning`, recommended by Leon Bottou.
- [Unraveling the key components of ood generalization via diversification](https://arxiv.org/pdf/2312.16313.pdf), Dec. 26 2023.
  - Similar to ensemble methods for ood generalization.
- [Are all unseen data out-of-distribution](https://arxiv.org/pdf/2312.16243.pdf), Jan. 2 2024.
  - _"we redefine the ood data as a type of data outside the convex hull of the training domains and prove a new generalization bound based on this new definition [...] It implies that the effectiveness of a well-trained model can be guaranteed for the unseen data that is within the convex hull of the training domains. But for some data beyond the convex hull, a non-decreasing error trend can happen"_
- [Desiderata for representation learning: A causal perspective](https://www.semanticscholar.org/reader/6824aaba5f7c88eb432e2a927c84c9f0e1e66188), Feb. 10 2022.

### Representation learning

- [Universal Time-Series Representation Learning: A Survey](https://arxiv.org/pdf/2401.03717.pdf), Jan. 8 2024.
- [Understanding distributed representations of concepts in deep neural networks without supervision](https://arxiv.org/pdf/2312.17285.pdf), Dec. 28 2023. `aaai2024`.
- [Randomly weighted neuromodulation in neural networks facilitates learning of manifolds common across tasks](https://arxiv.org/pdf/2401.02437.pdf), Nov. 17 2023.
- [Is a caption worth a thousand images? A controlled study for representation learning](https://arxiv.org/abs/2310.01425), Sep. 27 2023.

---

### LLMs and beyond

- [Principled Gradient-based Markov Chain Monte Carlo for Text Generation](https://arxiv.org/pdf/2312.17710.pdf), Dec. 29 2023.
- [Large Language Models for Generative Information Extraction: A Survey](https://arxiv.org/pdf/2312.17617.pdf), Dec. 29 2023.
  - This might an entrance of useful information extraction techniques that can be applied to collection dialogues or same product identification task.
- [Using Large Language Models for Hyperparameter Optimizatio](https://arxiv.org/pdf/2312.04528.pdf), Dec. 7 2023.
- [AutoNumerics-Zero: Automated Discovery of State-of-the-Art Mathematical Functions](https://arxiv.org/pdf/2312.08472.pdf), Dec. 13 2023.
- [A philosophical introduction to language models part I: Continuity with class debates](https://arxiv.org/pdf/2401.03910.pdf), Jan. 8 2024.
- [Non-vacuous generalization bounds or large language models](https://arxiv.org/pdf/2312.17173.pdf), Dec. 28 2023.

#### Compression

- [The LLM surgeon](https://arxiv.org/pdf/2312.17244.pdf), Dec. 28 2023.

#### Tech. report

- [Mixtral of Experts](https://arxiv.org/pdf/2401.04088.pdf), Jan. 8 2024.
- [DeepSeek LLM Scaling Open-Source Language Models with Longtermism](https://arxiv.org/pdf/2401.02954.pdf), Jan. 5 2024.
- [TeleChat technical report](https://arxiv.org/pdf/2401.03804.pdf), Jan. 8 2024.

#### Multi-modal

- [GPT-4V(ision) is a Generalist Web Agent, if Grounded](https://arxiv.org/pdf/2401.01614.pdf), Jan. 3 2024.

#### Inductive bias and theory of Transformers

- [Turing Complete Transformers: Two Transformers Are More Powerful Than One](https://openreview.net/forum?id=MGWsPGogLH), `iclr2024 rejected`.

#### In-context learning

- [Can Transformers Learn Sequential Function Classes In Context?](https://arxiv.org/pdf/2312.12655.pdf), Dec. 21 2023.

#### Mechanistic interpretability

- [Evaluating Brain-Inspired Modular Training in Automated Circuit Discovery for Mechanistic Interpretability](https://arxiv.org/pdf/2401.03646.pdf), Jan. 8 2024.
- [Observable propagation: A data-efficient approach to uncover feature vectors in Transformers](https://arxiv.org/pdf/2312.16291.pdf), Dec. 26 2023. `linear feature`.

#### Model merging

- [Merging by matching models in task subspaces](https://arxiv.org/pdf/2312.04339.pdf), Dec. 7 2023. [github](https://github.com/r-three/mats).
- [Concrete subspace learning based interference elimination for multi-task model fusion](https://arxiv.org/pdf/2312.06173.pdf), Dec. 11 2023.

#### Watermarks

- [On the learnability of watermarks for language models](https://arxiv.org/pdf/2312.04469.pdf), Dec. 7 2023. [github](https://github.com/chenchenygu/watermark-learnability).

#### Alignment

- [Teaching language models with canonical examples](https://openreview.net/pdf?id=SJwXWwc47T), `neurips2023`.
- [Learning and Forgetting Unsafe Examples in Large Language Models](https://arxiv.org/pdf/2312.12736.pdf), Dec. 20 2023.
- [What makes good data for alignment? A comprehensive study of automatic data selection in instruction tuning](https://arxiv.org/pdf/2312.15685.pdf), Dec. 25 2023.
- [Understanding data influence on context scaling: a close look at baseline solution](https://yaofu.notion.site/Understanding-data-influence-on-context-scaling-a-close-look-at-baseline-solution-eb17eab795dd4132b1a1ffe73f5e850a), Dec. 22 2023.
- [Theoretical guarantees on the best-of-n alignment policy](https://arxiv.org/pdf/2401.01879.pdf), Jan. 3 2024.
- [A General Theoretical Paradigm to Understand Learning from Human Preferences](https://arxiv.org/pdf/2310.12036.pdf), Nov. 22 2023.
- [Human-centered loss functions](https://github.com/ContextualAI/HALOs/blob/main/assets/report.pdf), 
- [A Comprehensive Study of Knowledge Editing for Large Language Models](https://arxiv.org/pdf/2401.01286.pdf), Jan. 2 2024.

#### Scaling law

- [Scaling Laws for Reward Model Overoptimization](https://arxiv.org/pdf/2210.10760.pdf), Oct. 19 2022.
- [SOLAR 10.7B: Scaling large language models with simple yet effective depth up-scaling](https://arxiv.org/pdf/2312.15166.pdf), Dec. 23 2023.

#### Finetuning

- [Learn or Recall? Revisiting Incremental Learning with Pre-trained Language Models](https://arxiv.org/pdf/2312.07887.pdf), Dec. 13 2023.
- [Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models](https://arxiv.org/pdf/2401.01335.pdf), Jan. 2 2024.

#### Reasoning

- [Neural algorithmic reasoning](https://thegradient.pub/neural-algorithmic-reasoning/), Oct. 14 2023.
- [Generative AI for Math: Part I MATHPILE: A Billion-Token-Scale Pretraining Corpus for Math](https://arxiv.org/pdf/2312.17120.pdf), Dec. 28 2023.

#### Creativity

- [Can AI Be as Creative as Humans?](https://arxiv.org/pdf/2401.01623.pdf), Jan. 3 2024.

### Codebase

- [huggingface diffusers](https://github.com/huggingface/diffusers/tree/main).

---

### Montly special topics

#### Deep learning optimization

> An growing list of papers.

- [Don't decay the learning rate, increase the batch size](https://arxiv.org/pdf/1711.00489.pdf), Feb. 24 2018.
  - _"one can usually obtain the same learning curve on both training and test sets by instead increasing the batch size during training. This procedure is successful for stochastic gradient descent (SGD), SGD with momentum, Nesterov momentum, and Adam"_
  - _"reaches equivalent test accuracies after the same number of training epochs, but with fewer parameter updates, leading to greater parallism and shorter training times"_
- [Super-Convergence: Very fast training of neural networks using large learning rates](https://arxiv.org/pdf/1708.07120.pdf), May 17 2018.
  - _"where neural networks can be trained an order of magnitude faster than with standard training methods"_
  - _"The existence of super-convergence is relevant to understanding why deep networks generalize well"_
- [A disciplined approach to neural network hyper-parameters: Part I - learning rate, batch size, momentum, and weight decay](https://arxiv.org/pdf/1803.09820.pdf), Apr. 24 2018.
- [Understanding batch normalization](https://arxiv.org/pdf/1806.02375.pdf), `neurips2018`.
  - _"show that BN primarily enables training with larger learning rates, which is the cause for faster convergence and better generalization"_
- [A Bayesian perspective on generalization and stochastic gradient descent](https://arxiv.org/pdf/1710.06451.pdf), `iclr2018`.
  - _"We also demonstrate that, when one holds the learning rate fixed, there is an optimum batch size which maximizes the test set accuracy"_
- [Towards Explaining the Regularization Effect of Initial Large Learning Rate in Training Neural Networks](https://proceedings.neurips.cc/paper/2019/file/bce9abf229ffd7e570818476ee5d7dde-Paper.pdf), `neurips2019`.
  - _"Although a small initial learning rate allows for faster training and better test performance initially, the large learning rate achieves better generalization soon after the learning rate is annealed"_
  - _"because the small learning rate model first memorizes easy-to-generalize, hard-to-fit patterns, it generalize worse on hard-to-generalize, easier-to-fit patterns than its large learning rate counterpart"_
- [A convergence theory for deep learning via over-parameterization](http://proceedings.mlr.press/v97/allen-zhu19a/allen-zhu19a.pdf), `icml2019`.
- [Why do larger models generalize better? A theoretical perspective via XOR problem](http://proceedings.mlr.press/v97/brutzkus19b/brutzkus19b.pdf), `icml2019`.
- [Cyclical annealing schedule: A simple approach to mitigating KL vanishing](https://arxiv.org/pdf/1903.10145.pdf), `naacl2019`.
- [On empirical comparisons of optimizers for deep learning](https://arxiv.org/abs/1910.05446), Oct. 11 2019.
  - _"demonstrate the sensitivity of optimizer comparisons to the hyperparameter tuning protocol [...] Our findings suggest that the hyperparameter search space may be the single most important factor explaining the rankings obtained by recent empirical comparisons in the literature"_
  - _"As tuning effort grows without bound, more general optimizers should never underperform the ones they can approximate (i.e. Adam should never perform worse than momentum)"_









