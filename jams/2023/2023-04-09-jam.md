
- [Structure Learning with Continuous Optimization: A Sober Look and Beyond](https://arxiv.org/pdf/2304.02146.pdf), Apr. 4 2023.
- [Torch-Choice: a pytorch package for large-scale choice modelling with python](https://arxiv.org/pdf/2304.01906.pdf), Apr. 4 2023.
- [Rethinking the Role of Token Retrieval in Multi-Vector Retrieval](https://arxiv.org/pdf/2304.01982.pdf), Apr. 4 2023.
- [Predictive Heterogeneity: Measures and Applications](https://arxiv.org/pdf/2304.00305.pdf), Apr. 1 2023.
- [Neural Network Architectures](https://arxiv.org/pdf/2304.05133.pdf), Apr. 11 2023.
  - Learn how to write a concise and crystal clear sumamry of certain topic.
- [Scaling transformer to 1M tokens and beyond with RMT](https://arxiv.org/pdf/2304.11062.pdf), Apr. 19 2023.
- [Data Distillation: A Survey](https://arxiv.org/pdf/2301.04272.pdf), Jan. 11 2023.
- [On the Importance of Contrastive Loss in Multimodal Learning](https://arxiv.org/pdf/2304.03717.pdf), Apr. 7 2023.
- [Learning Personalized Decision Support Policies](https://arxiv.org/abs/2304.06701), Apr. 13 2023.
- [Do deep neural networks have an inbuilt Occam’s razor?](https://arxiv.org/pdf/2304.06670.pdf), Apr. 13 2023. `dl theory`.
- [Automatic gradient descent](https://github.com/jxbz/agd), Apr. 11 2023. [paper](https://arxiv.org/pdf/2304.05187.pdf).
- [The No Free Lunch Theorem, Kolmogorov Complexity, and the Role of Inductive Biases in Machine Learning](https://arxiv.org/pdf/2304.05366.pdf), Apr. 11 2023.
- [Nearest neighbor for realizable online classification](https://geelon.github.io/assets/talks/realizable-online-nn.pdf), Mar. 20 2023.
- [Efficient Methods for Natural Language Processing: A Survey](https://arxiv.org/abs/2209.00099), Aug. 31 2022.
- [A Combinatorial Perspective on the Optimization of Shallow ReLU Networks](https://arxiv.org/pdf/2210.00176.pdf), Oct. 1 2022.
- [Learning Personalized Decision Support Policies](https://arxiv.org/pdf/2304.06701.pdf), Apr. 13 2023.
- [A Survey on Recent Teacher-student Learning Studies](https://arxiv.org/pdf/2304.04615.pdf), Apr. 10 2023. `distillation` `survey`.
- [A Comprehensive Survey on Deep Graph Representation Learning](https://arxiv.org/pdf/2304.05055.pdf), Apr. 19 2023. `graph learning` `survey`.
- [Double descent in human learning](https://chris-said.io/2023/04/21/double-descent-in-human-learning/), Apr. 23 2023. `blogpost`.
- [Cross-Entropy Loss Functions: Theoretical Analysis and Applications](https://arxiv.org/pdf/2304.07288.pdf), Apr. 14 2023.
- [Learning to Compress Prompts with Gist Tokens](https://arxiv.org/pdf/2304.08467.pdf), Apr. 17 2023.
- [Causal models in string diagrams](https://arxiv.org/abs/2304.07638), Apr. 15 2023.
- [Dimensionality Reduction as Probabilistic Inference](https://arxiv.org/abs/2304.07658), Apr. 15 2023.
- [Meta-Learned Models of Cognition](https://arxiv.org/pdf/2304.06729.pdf), Apr. 12 2023.
- [Out-of-Variable Generalization](https://arxiv.org/pdf/2304.07896.pdf), Apr. 16 2023.
- [Decentralized Learning Made Easy with DecentralizePy](https://arxiv.org/pdf/2304.08322.pdf), Apr. 17 2023. `codebase`.
- [MLOps Spanning Whole Machine Learning Life Cycle: A Survey](https://arxiv.org/pdf/2304.07296.pdf), Apr. 2023.
- [Bridging RL Theory and Practice with the Effective Horizon](https://arxiv.org/pdf/2304.09853.pdf), Apr. 19 2023.
- [Loss minimization yields multicalibration for large neural networks](https://arxiv.org/pdf/2304.09424.pdf), Apr. 19 2023.
- [Generalization on the Unseen, Logic Reasoning and Degree Curriculum](https://arxiv.org/pdf/2301.13105.pdf), Jan. 30 2023.
- [Generalization and estimation error bounds for model-based neural networks](https://arxiv.org/pdf/2304.09802.pdf), Apr. 19 2023.
- [ContraSim – A Similarity Measure Based on Contrastive Learning](https://arxiv.org/pdf/2303.16992.pdf), Mar. 29 2023. `similarity measure`.
- [Efficient distributed representations beyond negative sampling](https://arxiv.org/pdf/2303.17475.pdf), Mar. 30 2023. `word2vec`.

### Interpretability

- [Evaluating the robustness of interpretability methods through explanation invariance and equivariance](https://arxiv.org/pdf/2304.06715.pdf), Apr. 13 2023.

### Evaluation

- [Why is the winner the best?](https://arxiv.org/pdf/2303.17719.pdf), Mar. 30 2023. `cvpr23`.

### Diffusion models

- [Reflected Diffusion Models](https://arxiv.org/pdf/2304.04740.pdf), Apr. 10 2023.

---

### LLMs

- [Self-refine: iteractive refinement with self-feedback](https://arxiv.org/pdf/2303.17651.pdf), Mar. 30 2023. `rlaif`.
- [TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs](https://arxiv.org/pdf/2303.16434.pdf), Mar. 29 2023.
- [Understanding Causality with Large Language Models: Feasibility and Opportunities](https://arxiv.org/pdf/2304.05524.pdf), Apr. 11 2023.
- [Evaluating Verifiability in Generative Search Engines](https://arxiv.org/pdf/2304.09848.pdf), Apr. 19 2023.
- [OpenAGI: When LLM Meets Domain Experts](https://arxiv.org/pdf/2304.04370.pdf), Apr. 12 2023.
- [Prompt Engineer Guide](https://www.promptingguide.ai/papers).
- [Model-tuning Via Prompts Makes NLP Models Adversarially Robust](https://arxiv.org/pdf/2303.07320.pdf), Mar. 13 2023.
- [ChatGPT Is a Blurry JPEG of the Web](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web), Feb. 9 2023.
- [Downstream Datasets Make Surprisingly Good Pretraining Corpora](https://arxiv.org/pdf/2209.14389.pdf), Sep. 28 2022.
- [Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study](https://arxiv.org/pdf/2304.06762.pdf), Apr. 13 2023.
- [Outlier Suppression+: Accurate quantization of large language models by equivalent and optimal shifting and scaling](https://arxiv.org/abs/2304.09145), Apr. 18 2023.
- [Towards Better Instruction Following Language Models for Chinese: Investigating the Impact of Training Data and Evaluation](https://arxiv.org/pdf/2304.07854.pdf), Apr. 16 2023.
- [BloombergGPT: A Large Language Model for Finance](https://arxiv.org/pdf/2303.17564.pdf), Mar. 30 2023.
- [Recognition, recall, and retention of few-shot memories in large language models](https://arxiv.org/pdf/2303.17557.pdf), Mar. 30 2023. `cognition`.

#### The sparks of scaling up

- [Exploring the Limits of Language Modeling](https://arxiv.org/pdf/1602.02410.pdf), Feb. 11 2016.
- [Unsupervised sentiment neuron](https://openai.com/research/unsupervised-sentiment-neuron), Apr. 6 2017. [code](Generating Reviews and Discovering Sentiment).
- [Learning to Generate Reviews and Discovering Sentiment](https://arxiv.org/pdf/1704.01444.pdf), Apr. 6 2017.
- [Towards Compute-Optimal Transfer Learning](https://arxiv.org/pdf/2304.13164.pdf), Apr. 25 2023.

#### Tool using

- [ART: Automatic multi-step reasoning and tool-use for large language models](https://arxiv.org/pdf/2303.09014.pdf), Mar. 16 2023.
- [Tool Learning with Foundation Models](https://arxiv.org/pdf/2304.08354.pdf), Apr. 27 2023.
- [HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face](https://arxiv.org/pdf/2303.17580.pdf), Apr. 2 2023.

#### Analysis

- [Pythia: A Suite for Analyzing Large Language Models](https://arxiv.org/pdf/2304.01373.pdf), Apr. 3 2023.
- [Measuring and Manipulating Knowledge Representations in Language Models](https://arxiv.org/pdf/2304.00740.pdf), Apr. 3 2023.
- [Can the Inference Logic of Large Language Models be Disentangled into Symbolic Concepts?](https://arxiv.org/pdf/2304.01083.pdf), Apr. 3 2023.
- [Why think step-by-step? Reasoning emerges from the locality of experience](https://arxiv.org/pdf/2304.03843.pdf), Apr. 7 2023.
- [Localizing model behavior with path patching](https://arxiv.org/pdf/2304.05969.pdf), Apr. 12 2023. `mechanistic interpretability`.
- [Emergent and Predictable Memorization in Large Language Models](https://arxiv.org/pdf/2304.11158.pdf), Apr. 21 2023.
- [A Latent Space Theory for Emergent Abilities in Large Language Models](https://arxiv.org/pdf/2304.09960.pdf), Apr. 19 2023.
- [Beyond Transformers for Function Learning](https://arxiv.org/pdf/2304.09979.pdf), Apr. 19 2023.

#### Data centric

- [Data Portraits: Recording Foundation Model Training Data](https://arxiv.org/pdf/2303.03919.pdf), Mar. 6 2023.
- [Learning Sample Difficulty from Pre-trained Models for Reliable Prediction](https://arxiv.org/pdf/2304.10127.pdf), Apr. 20 2023.
- [Language models enables simple systems for generating structured views of heteogeneous data lakes](https://arxiv.org/pdf/2304.09433.pdf), Apr. 20 2023.

#### Social impact

- [GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models](https://arxiv.org/pdf/2303.10130.pdf), Mar. 23 2023.
- [Ecosystem Graphs: The Social Footprint of Foundation Models](https://arxiv.org/pdf/2303.15772.pdf), Mar. 28 2023.
- [Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond](https://arxiv.org/abs/2304.13712), Apr. 26 2023.
- [Whose Opinions Do Language Models Reflect?](https://arxiv.org/pdf/2303.17548.pdf), Mar. 30 2023.

#### Alignment

- [MERMAIDE: Learning to Align Learners using Model-Based Meta-Learning](https://arxiv.org/pdf/2304.04668.pdf), Apr. 10 2023.
- [RRHF: Rank Responses to Align Language Models with Human Feedback without tears](https://arxiv.org/pdf/2304.05302.pdf), Apr. 11 2023.
- [Fundamental limitations of alignment in large language models](https://arxiv.org/pdf/2304.11082.pdf), Apr. 19 2023.
- [Supporting Human-AI Collaboration in Auditing LLMs with LLMs](https://arxiv.org/pdf/2304.09991.pdf), Apr. 19 2023.

### Distribution shift

- [Domain Adaptation for Time Series Under Feature and Label Shifts](https://arxiv.org/pdf/2302.03133.pdf), Feb. 6 2023.




