
- [Ten Years of Generative Adversarial Nets (GANs): A survey of the state-of-the-art](https://arxiv.org/pdf/2308.16316.pdf), Aug. 30 2023. `survey` `GAN`.
- [Construction Grammar and Artificial Intelligence](https://arxiv.org/pdf/2309.00135.pdf), Aug. 31 2023. `linguistics`.
- [Probabilistic Self-supervised Learning via Scoring Rules Minimization](https://arxiv.org/pdf/2309.02048.pdf), Sep. 5 2023. `interpretability` `self-supervised learning`.
- [Large Language Models for Generative Recommendation: A Survey and Visionary Discussions](https://arxiv.org/pdf/2309.01157.pdf), Sep. 3 2023. `recommender system`.
- [Maximum Mean Discrepancy Meets Neural Networks: The Radon-Kolmogorov-Smirnov Test](https://arxiv.org/pdf/2309.02422.pdf), Sep. 5 2023. `distribution match`.
- [Automating Behavioral Testing in Machine Translation](https://arxiv.org/pdf/2309.02553.pdf), Sep. 5 2023. `model debugging`.
- [Natural Example-Based Explainability: a Survey](https://arxiv.org/pdf/2309.03234.pdf), Sep. 5 2023. `interpretability`, `data attribution`.
- [Introduction to Quantization cooked in ðŸ¤—](https://huggingface.co/blog/merve/quantization), Aug. 2023.
- [Exploring the Landscape of Natural Language Processing Research](https://arxiv.org/abs/2307.10652), Jul. 20 2023. `to nlp or not to nlp`.
- [Eight Lessons Learned in Two Years of Ph.D.](https://ai.engin.umich.edu/2023/08/17/eight-lessons-learned-in-two-years-of-ph-d/), Aug. 17 2023. `blogpost` `advice`.
- [Geometry of Program Synthesis](https://arxiv.org/pdf/2103.16080.pdf), Mar. 2021.
- [Optimal Transport with Tempered Exponential Measures](https://arxiv.org/pdf/2309.04015.pdf), Sep. 7 2023. `optimal transport`.
  - this paper could be used as a entrance to the understanding of the topic ***Optimal Transport*** (OT), which I used to be afraid to learn
  - my old take on OT is that it seems to me another distribution matching objective or measure, but does it bring significantly usefulness in specific situations, I really don't know, so it's time to find out the answer
- [A Hands-on Tutorial for Learning with Noisy Labels](https://github.com/Docta-ai/IJCAI-tutorial), `ijcai2022`. `tutorial` `learning under noise`. `robust learning`.
- [DBsurve: A discrepancy based method for discrete stochastic gradient estimation](https://arxiv.org/pdf/2309.03974.pdf), Sep. 7 2023. `gradient estimation`.
- [Towards Mitigating Architecture Overfitting in Dataset Distillation](https://arxiv.org/pdf/2309.04195.pdf), Sep. 8 2023. `dataset distillation`.
- [A Gentle Introduction to Gradient-Based Optimization and Variational Inequalities for Machine Learning](https://arxiv.org/pdf/2309.04877.pdf), Sep. 9 2023. `machine learning and game theory`.
  - Michael Jordan's recent works on recommender system and computational market design
- [LLM.int8() and Emergent Features](https://timdettmers.com/2022/08/17/llm-int8-and-emergent-features/), Aug. 17 2022.
- [XAI-Bench](https://github.com/abacusai/xai-bench), 2021.
  - XAI-Bench is a library for benchmarking feature attribution explainability techniques
- [Boolformer: Symbolic Regression of Logic Functions with Transformers](https://arxiv.org/pdf/2309.12207.pdf), Sep. 21 2023.
- [Accelerating machine learning algorithms with adaptive sampling](https://arxiv.org/pdf/2309.14221.pdf), Sep. 25 2023. [code FastForest](https://github.com/ThrunGroup/FastForest/tree/main).
- [Learning to abstain from uninformative data](https://arxiv.org/pdf/2309.14240.pdf), Sep. 25 2023.
- [On Sparse Modern Hopfield Model](https://arxiv.org/pdf/2309.12673.pdf), Sep. 22 2023. `inductive bias`.

### Similar to distill

- [An Interactive Introduction to Model-Agnostic Meta-Learning](https://interactive-maml.github.io/), built upon [`svelte`](https://www.svelte.cn/).

### Prof. Le Song's representative works

- [Supervised Feature Selection via Dependence Estimation](https://browse.arxiv.org/pdf/0704.2668.pdf), `icml2007`.
  - propose to use a so-called Hilbert-Schmidt Independence Criteria as a measure of dependence between features and labels to select features (HSIC).
  - _"key idea is that good features should maximise such dependence"_
  - _"supervised feature selection can be cast as a combinatorial optimisation problem. We have a full set of features, denoted $$\mathcal{S}$$"_
  - in Table 1 of the paper, several feature selection methods are compared, to notice that, effectiveness of the mutual information and Pearson correlation criteria is very impressive
- [A dependence maximization view of clustering](https://pure.mpg.de/rest/items/item_1790434/component/file_3075621/content), `icml2007`.
  - _"Under HSIC, we unify the geometric, spectral, and statistical dependence view of clustering, and subsume many existing algorithms as special cases (e.g. k-means and spectral clustering)"_

### Data selection

- [Towards a statistical theory of data selection under weak supervision](https://arxiv.org/pdf/2309.14563.pdf), Sep. 25 2023.

### Trustworthy ml

- [FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare](https://arxiv.org/pdf/2309.12325.pdf), Aug. 11 2023.

#### Uncertainty quantification

#### Robustness

- [Adversarial Example Detection in Deployed Tree Ensembles](https://arxiv.org/pdf/2206.13083.pdf), Jun. 27 2022.

### Feature selection and data mining oldies

- [Subspace Clustering for High Dimensional Data: A Review](http://www.math.chalmers.se/Stat/Grundutb/GU/MSA220/S17/SubspaceClust.pdf), `kdd2004`.
- [A Rigorous Information-Theoretic Definition of Redundancy and Relevancy in Feature Selection Based on (Partial) Information Decomposition](https://www.jmlr.org/papers/volume24/21-0482/21-0482.pdf), `jmlr2023`.

### The recent influential work of `Shai Shalev-Shwartz`

- [Safe, Multi-Agent, Reinforcement Learning for Autonomous Driving](https://arxiv.org/pdf/1610.03295.pdf), 2016.
- [Failures of Gradient-Based Deep Learning](http://proceedings.mlr.press/v70/shalev-shwartz17a/shalev-shwartz17a.pdf), `icml2017`.
- [On a Formal Model of Safe and Scalable Self-driving Cars](https://arxiv.org/pdf/1708.06374.pdf), Oct. 27 2018.
- [Discriminative Active Learning](https://arxiv.org/pdf/1907.06347.pdf), Jul. 2019. [blogpost](https://dsgissin.github.io/DiscriminativeActiveLearning/).
- [Proving the Lottery Ticket Hypothesis: Pruning is All You Need](http://proceedings.mlr.press/v119/malach20a/malach20a.pdf), `icml2020`.

### Adaptive data analysis

- [The Limits of Post-Selection Generalization](https://arxiv.org/pdf/1806.06100.pdf), 2018.

### Causal inference

- [On the Actionability of Outcome Prediction](https://arxiv.org/pdf/2309.04470.pdf), Sep. 8 2023.
- [Human-in-the-Loop Causal Discovery under Latent Confounding using Ancestral GFlowNets](https://arxiv.org/pdf/2309.12032.pdf), Sep. 21 2023.
- [Uplift vs. predictive modeling: a theoretical analysis](https://arxiv.org/pdf/2309.12036.pdf), Sep. 21 2023.
- [Learning invariant representations with a nonparametric Nadaraya-Watson head](https://arxiv.org/pdf/2309.13377.pdf), Sep. 23 2023.
- [A Convex Framework for Confounding Robust Inference](https://arxiv.org/pdf/2309.12450.pdf), Sep. 21 2023.

### Data-centric ml

- [Lilac](https://github.com/lilacai/lilac), Lilac is an open-source product that helps you analyze, enrich, and clean unstructured data with AI.

### Intrinsic dimension

- [Intrinsic dimension](https://en.wikipedia.org/wiki/Intrinsic_dimension), wikipedia.
- [Estimating the intrinsic dimension of datasets by a minimal neighborhood information](https://www.nature.com/articles/s41598-017-11873-y), `nature scientific report 2017`.
- [Intrinsic dimension of data representations in deep neural networks](https://arxiv.org/abs/1905.12784), `nips2019`.
- [The Intrinsic Dimension of Images and Its Impact on Learning](https://openreview.net/forum?id=XJk19XzGq2J), `iclr2021`.
- [The Effect of Intrinsic Dimension on Metric Learning under Compression](https://arxiv.org/pdf/2309.05751.pdf), Sep. 11 2023.

### The most cited papers

- [Squeeze-and-Excitation Networks](https://arxiv.org/pdf/1709.01507.pdf), May 16 2019.
- [An image is worth 16 $$\times$$ 16 words: Transformers for image recognition at scale](https://arxiv.org/pdf/2010.11929.pdf), Jun. 3 2021.

### Uncertainty estimation

- [Adaptive conformal classification with noisy labels](https://arxiv.org/pdf/2309.05092.pdf), Sep. 10 2023.
- [Conservative Prediction via Data-Driven Confidence Minimization](https://arxiv.org/abs/2306.04974), Jun. 8 2023. `uncertainty estimation`.
  - new architecture of decision making.

### Class imbalance

- [Practical Lessons from Predicting Clicks on Ads at Facebook](http://quinonero.net/Publications/predicting-clicks-facebook.pdf), 2014.
- [To SMOTE, or not to SMOTE?](https://arxiv.org/pdf/2201.08528.pdf), May 11 2022.

### Efficiency

- [Unit Scaling: Out-of-the-Box Low-Precision Training](https://arxiv.org/pdf/2303.11257.pdf), May 30 2023. [code](https://console.paperspace.com/github/graphcore-research/out-of-the-box-fp8-training?machine=Free-IPU-POD4&container=graphcore/pytorch-paperspace%3A3.3.0-ubuntu-20.04-20230703&file=out_of_the_box_fp8_training.ipynb).

### Distribution shift

- [Better Practices for Domain Adaptation](https://arxiv.org/pdf/2309.03879.pdf), Sep. 7 2023.
- [On Pitfalls of Test-Time Adaptation](https://arxiv.org/pdf/2306.03536.pdf), Jun. 6 2023.
- [Distributionally robust post-hoc classifier under prior shifts](https://arxiv.org/pdf/2309.08825.pdf), Sep. 16 2023. [code](https://github.com/weijiaheng/Drops).
- [Context is Environment](https://arxiv.org/pdf/2309.09888.pdf), Sep. 20 2023. `in-context risk minimization`.
- [Robust Internal Representations for Domain Generalization](https://arxiv.org/pdf/2309.15522.pdf), Sep. 27 2023.
- [Rapid Network Adaptation: Learning to Adapt Neural Networks Using Test-Time Feedback](https://arxiv.org/pdf/2309.15762.pdf), Sep. 27 2023.

### AI safety

- [Provably safe systems: the only path to controllable AGI](https://arxiv.org/pdf/2309.01933.pdf), Sep. 5 2023.
  - a position paper from Mechanistic Interpretability workshop at MIT.
- [From Preference Elicitation to Participatory ML: A Critical Survey & Guidelines for Future Research](https://dl.acm.org/doi/pdf/10.1145/3600211.3604661), 2023.
- [Subtle adversarial image manipulations influence both human and machine perception](https://www.nature.com/articles/s41467-023-40499-0), Aug. 15 2023. `nature`.

### Graph deep learning

- [Transformers Meet Directed Graphs](https://arxiv.org/pdf/2302.00049.pdf), Aug. 31 2023. [code](https://github.com/deepmind/digraph_transformer).

### Generative modeling

- [Learning multi-modal generative models with permutation-invariant encoders and tighter variational bounds](https://arxiv.org/pdf/2309.00380.pdf), Sep. 1 2023.
- [Beta Diffusion](https://arxiv.org/pdf/2309.07867.pdf), Sep. 14 2023.

### Representation learning

- [Mechanism of feature learning in convolutional neural networks](https://arxiv.org/pdf/2309.00570.pdf), Sep. 1 2023.
- [Pareto Frontiers in Neural Feature Learning: Data, Compute, Width, and Luck](https://arxiv.org/pdf/2309.03800.pdf), Sep. 7 2023.
- [Gradient-Based Feature Learning under Structured Data](https://arxiv.org/pdf/2309.03843.pdf), Sep. 7 2023.
- [Probing transfer learning with a model of synthetic correlated datasets](https://arxiv.org/abs/2106.05418), Jan. 9 2021.
- [Towards understanding neural collapse: the effects of batch normalization and weight decay](https://arxiv.org/pdf/2309.04644.pdf), Sep. 9 2023. `neural collapse`.
- [Introspective Deep Metric Learning](https://arxiv.org/pdf/2309.09982.pdf), Sep. 11 2023.

### Learning dynamics and generalization

- [On the implicit bias of Adam](https://arxiv.org/pdf/2309.00079.pdf), Aug. 31 2023.
- [A law of data separation in deep learning](https://www.pnas.org/doi/full/10.1073/pnas.2221704120), Aug. 28 2023.
- [REPAIR: REnormalizing Permuted Activations for Interpolation Repair](https://arxiv.org/pdf/2211.08403.pdf), Dec. 2022.
- [Generalization Bounds: Perspectives from Information Theory and PAC-Bayes](https://arxiv.org/pdf/2309.04381.pdf), Sep. 8 2023.
- [How many Neurons do we need? A refined Analysis for Shallow Networks trained with Gradient Descent](https://arxiv.org/pdf/2309.08044.pdf), Sep. 14 2023.
- [Global Convergence of SGD For Logistic Loss on Two Layer Neural Nets](https://arxiv.org/pdf/2309.09258.pdf), Sep. 17 2023.

### Community detection surveys

- [A survey of community detection approaches: from statistical modeling to deep learning](https://arxiv.org/pdf/2101.01669.pdf), Aug. 14 2021.
- [A comprehensive survey on community detection with deep learning](https://arxiv.org/pdf/2105.12584.pdf), Oct. 11 2021.

### Classic work of C. E. Shannon

- [Communication in the Presence of Noise](http://shilov-sss.ru/wp-content/uploads/2018/05/Shannon-C.-Communication-in-the-presence-of-noise-PIRE-37-I-194910.pdf), 1949.
- [Prediction and entropy of printed English](https://languagelog.ldc.upenn.edu/myl/Shannon1950.pdf), 1950.
- [The redundancy of English](https://jontalle.web.engr.illinois.edu/uploads/537.F18/Papers/Shannon50b.pdf), 1953.
- [Coding theorems for a discrete source with a fidelity criterion](https://mast.queensu.ca/~math474/shannon59.pdf), 1959.
- [Communication theory of secrecy systems](http://www.fr.beejack.com/sites/default/files/u3/Claude-Elwood-Shannon.pdf).
- [The zero error capacity of a noisy channel](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=1056798).

### Optimization in NNs and beyond

- [Nevergrad](https://facebookresearch.github.io/nevergrad/index.html), a gradient-free optimization platform.

### CTR, recsys etc.

- [AntM2C: A large scale dataset for multi-scenario multi-modal CTR prediction](https://arxiv.org/pdf/2308.16437.pdf), Aug. 31 2023. `data resource`.

### Time-series

- [CenTime: Event-Conditional Modelling of Censoring in Survival Analysis](https://arxiv.org/pdf/2309.03851.pdf), Sep. 7 2023.
- [Examining the Effect of Pre-training Followed by Fine-tuning on Time Series Classification](https://arxiv.org/pdf/2309.05256.pdf), Sep. 11 2023. `pretraining`.

### Data-centric

- [Pervasive Label Errors in Test Sets Destabilize Machine Learning Benchmarks](https://arxiv.org/abs/2103.14749), Mar. 26 2021.
  - [Automated Data Quality at Scale](https://cleanlab.ai/blog/automated-data-quality-at-scale/), Jul. 2023.

---

### LLMs and the new era of machine learning

- [Augmented Language Models: a Survey](https://arxiv.org/pdf/2302.07842.pdf), Feb. 15 2023.
- [Ingredients of understanding](https://dileeplearning.substack.com/p/ingredients-of-understanding?utm_source=profile&utm_medium=reader2), Aug. 2023. `blogpost`.
- [Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient MoE for Instruction Tuning](https://arxiv.org/pdf/2309.05444.pdf), Sep. 11 2023. [code](https://github.com/for-ai/parameter-efficient-moe).
- [Does Writing with Language Models Reduce Content Diversity?](https://arxiv.org/pdf/2309.05196.pdf), Sep. 11 2023. `He He`.
- [Textbooks Are All You Need II: phi-1.5 technical report](https://arxiv.org/pdf/2309.05463.pdf), Sep. 11 2023.
- [On the Connection between Pre-training Data Diversity and Fine-tuning Robustness](https://arxiv.org/pdf/2307.12532.pdf), Jul. 24 2023.
- [Rethinking Learning Rate Tuning in the Era of Large Language Models](https://arxiv.org/pdf/2309.08859.pdf), Sep. 16 2023.
- [BTLM-3B-8K: 7B Parameter Performance in a 3B Parameter Model](https://arxiv.org/pdf/2309.11568.pdf), Sep. 20 2023.

#### Multimodal

- [A theory of multimodal learning](https://arxiv.org/pdf/2309.12458.pdf), Sep. 21 2023.
  - _"We demonstrate that multimodal learning allows for a superior generalization bound compared to unimodal learning, up to factor of $$O(\sqrt{n})$$, where $$n$$ represents the sample size. Such advantage occurs when both connection and heterogeneity exist between the modalities"_
- [Jointly training large autoregressive multimodal models](https://arxiv.org/pdf/2309.15564.pdf), Sep. 27 2023.

#### Shrink LLMs

- [Small-scale proxies for large-scale Transformer training instabilities](https://arxiv.org/pdf/2309.14322.pdf), Sep. 25 2023.
- [The Languini Kitchen: Enabling Language Modelling Research at Different Scales of Compute](https://arxiv.org/pdf/2309.11197.pdf), Sep. 20 2023. [project page](https://languini-kitchen.github.io/).

#### Continual learning

- [Investigating the Catastrophic Forgetting in Multimodal Large Language Models](https://arxiv.org/pdf/2309.10313.pdf), Sep. 19 2023.
- [Understanding catastrophic forgetting in language models via implicit inference](https://arxiv.org/pdf/2309.10105.pdf), Sep. 18 2023.
  - _"we demonstrate that improving performance on tasks within the fine-tuning data distribution comes at the expense of suppressing model capabilities on other tasks [...] degradation is especially pronounced for tasks closest to the fine-tuning distribution"_

#### Agents

- [Agents: An Open-source Framework for Autonomous Language Agents](https://arxiv.org/pdf/2309.07870.pdf), Sep. 14 2023.

#### Distributed SGD

- [Don't Use Large Mini-Batches, Use Local SGD](https://arxiv.org/abs/1808.07217), Aug. 22 2018.
- [Why (and when) does local SGD generalize better than SGD?](https://arxiv.org/pdf/2303.01215.pdf), Mar. 9 2023.

#### Multi-modal

- [A Joint Study of Phrase Grounding and Task Performance in Vision and Language Models](https://arxiv.org/pdf/2309.02691.pdf), arXiv Sep. 6 2023.
- [Scaling autoregressive multi-modal models: pretraining and instruction-tuning](https://arxiv.org/pdf/2309.02591.pdf), Sep. 5 2023. [metaseq](https://github.com/facebookresearch/metaseq).
- [NExT-GPT: Any-to-Any Multimodal LLM](https://arxiv.org/pdf/2309.05519.pdf), Sep. 11 2023. [project page](https://next-gpt.github.io/).

#### Data curation

- [The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only](https://arxiv.org/abs/2306.01116), Jun. 1 2023.
- [MADLAD-400: A Multilingual And Document-Level Large Audited Dataset](https://arxiv.org/pdf/2309.04662.pdf), Sep. 9 2023.
  - model checkpoints are available
- [When Less is More: Investigating Data Pruning for Pretraining LLMs at Scale](https://arxiv.org/pdf/2309.04564.pdf), Sep. 8 2023.
- [SlimPajama-DC: Understanding Data Combinations for LLM Training](https://arxiv.org/pdf/2309.10818.pdf), Sep. 19 2023.
- [CulturaX: A Cleaned, Enormous, and Multilingual Dataset for Large Language Models in 167 Languages](https://arxiv.org/pdf/2309.09400.pdf), Sep. 17 2023.

#### Reasoning

- [On the Planning, Search, and Memorization Capabilities of Large Language Models](https://arxiv.org/pdf/2309.01868.pdf), Sep. 5 2023.
- [Taken out of context: On measuring situational awareness in LLMs](https://arxiv.org/pdf/2309.00667.pdf), Sep. 1 2023.
- [Making large language models better reasoners with alignment](https://arxiv.org/pdf/2309.02144.pdf), Sep. 5 2023.
- [Large language models as optimizers](https://arxiv.org/pdf/2309.03409.pdf), Sep. 7 2023.
- [Hypothesis search: Inductive reasoning with language models](https://arxiv.org/pdf/2309.05660.pdf), Sep. 11 2023.
- [Evaluating the Deductive Competence of Large Language Models](https://arxiv.org/pdf/2309.05452.pdf), Sep. 11 2023.
- [Memory Injections: Correcting Multi-Hop Reasoning Failures during Inference in Transformer-Based Language Models](https://arxiv.org/pdf/2309.05605.pdf), Sep. 11 2023.
- [Chain-of-thought reasoning is a policy improvement operator](https://arxiv.org/pdf/2309.08589.pdf), Sep. 15 2023.
- [Can Large Language Models Understand Real-World Complex Instructions?](https://arxiv.org/pdf/2309.09150.pdf), Sep. 17 2023.
- [Design of chain-of-thought in math problem solving](https://arxiv.org/pdf/2309.11054.pdf), Sep. 20 2023.

#### Hallucination and factuality

- [Contrastive decoding improves reasoning in large language models](https://arxiv.org/pdf/2309.09117.pdf), Sep. 17 2023.
- [How to catch an AI liar: lie detection in black-box LLMs by asking unrelated questions](https://arxiv.org/pdf/2309.15840.pdf), Sep. 26 2023.

#### Alignment

- [RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback](https://arxiv.org/pdf/2309.00267.pdf), Sep. 1 2023.
- [Baseline defenses for adversarial attacks against aligned language models](https://arxiv.org/pdf/2309.00614.pdf), Sep. 1 2023.
- [Efficient RLHF: Reducing the memory usage of PPO](https://arxiv.org/pdf/2309.00754.pdf), Sep. 1 2023.
- [Bias and Fairness in Large Language Models: A Survey](https://arxiv.org/pdf/2309.00770.pdf), Sep. 2 2023.
- [Generative Social Choice](https://arxiv.org/pdf/2309.01291.pdf), Sep. 3 2023.
- [A Survey on Hallucination in Large Language Models](https://arxiv.org/pdf/2309.01219.pdf), Sep. 3 2023.
- [Beyond human data: RLAIF needs a rebrand](https://www.interconnects.ai/p/beyond-human-data-rlaif), Apr. 26 2023. `blogpost`.
- [Specifying objectives in RLHF](https://www.interconnects.ai/p/specifying-objectives-in-rlhf), Aug. 2 2023. `blogpost`.
- [Certifying LLM safety against adversarial prompting](https://arxiv.org/pdf/2309.02705.pdf), Sep. 6 2023.
- [Speciality vs Generality: An Empirical Study on Catastrophic Forgetting in Fine-tuning Foundation Models](https://arxiv.org/pdf/2309.06256.pdf), Sep. 12 2023.
- [Flesch or Fumble? Evaluating Readability Standard Alignment of Instruction-Tuned Language Models](https://arxiv.org/pdf/2309.05454.pdf), Sep. 11 2023.
- [Quantifying and Attributing the Hallucination of Large Language Models via Association Analysis](https://arxiv.org/pdf/2309.05217.pdf), Sep. 11 2023.
- [Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions](https://arxiv.org/pdf/2309.07875.pdf), Sep. 14 2023.
- [Exploring the impact of low-rank adaptation on the performance, efficiency, and regularization of RLHF](https://arxiv.org/pdf/2309.09055.pdf), Sep. 16 2023.
- [Adapting LLMs via reading comprehension](https://arxiv.org/pdf/2309.09530.pdf), Sep. 18 2023.
- [Identifying the Risks of LM Agents with an LM-Emulated Sandbox](https://arxiv.org/pdf/2309.15817.pdf), Sep. 25 2023.

#### Understanding transformers

- [Transformers as Support Vector Machines](https://arxiv.org/pdf/2308.16898.pdf), Aug. 31 2023.
- [Uncovering mesa-optimization algorithms in Transformers](https://arxiv.org/pdf/2309.05858.pdf), Sep. 11 2023.

#### Scaling law

- [Deep Learning Scaling is Predictable, Empirically](https://arxiv.org/abs/1712.00409), Dec. 1 2017.
- [Uncovering Neural Scaling Laws in Molecular Representation Learning](https://arxiv.org/pdf/2309.15123.pdf), Sep. 15 2023.

#### Mechanistic interpretability

- [Interpreting Neural Networks through the Polytope Lens](https://arxiv.org/pdf/2211.12312.pdf), Nov. 22 2022.
- [Can Neural Network Memorization Be Localized?](https://pratyushmaini.github.io/mem_web/), 2023. `project page`.
- [NeuroSurgeon: A Toolkit for Subnetwork Analysis](https://arxiv.org/pdf/2309.00244.pdf), Sep. 1 2023. [code](https://github.com/mlepori1/NeuroSurgeon).
- [Cognitive architectures for language agents](https://arxiv.org/pdf/2309.02427.pdf), Sep. 5 2023.
- [Emergent Linear Representations in World Models of Self-Supervised Sequence Models](https://arxiv.org/pdf/2309.00941.pdf), Sep. 2 2023.
- [Explainability for Large Language Models: A Survey](https://arxiv.org/pdf/2309.01029.pdf), Sep. 2 2023.
- [Explaining grokking through circuit efficiency](https://arxiv.org/pdf/2309.02390.pdf), Sep. 5 2023.
- [Representations Matter: Embedding Modes of Large Language Models using Dynamic Mode Decomposition](https://arxiv.org/pdf/2309.01245.pdf), Sep. 3 2023.
- [A function interpretation benchmark for evaluating interpretability methods](https://arxiv.org/pdf/2309.03886.pdf), Sep. 7 2023.
- [Neurons in Large Language Models: Dead, N-gram, Positional](https://arxiv.org/pdf/2309.04827.pdf), Sep. 9 2023.
- [Faith and Fate: Limits of Transformers on Compositionality](https://arxiv.org/pdf/2305.18654.pdf), Jun. 1 2023. [tweet](https://twitter.com/sirbayes/status/1702137607839457479).
- [Sparse autoencoders find highly interpretable features in language models](https://arxiv.org/pdf/2309.08600.pdf), Sep. 15 2023.
- [On Model Explanations with Transferable Neural Pathways](https://arxiv.org/pdf/2309.09887.pdf), Sep. 18 2023.
- [Traveling Words: A Geometric Interpretation of Transformers](https://arxiv.org/pdf/2309.07315.pdf), Sep. 19 2023.
- [Physics of Language Models: Part 3.1, Knowledge Storage and Extraction](https://arxiv.org/pdf/2309.14316.pdf), Sep. 25 2023.
- [Attention satisfies: a constraint-satisfication lens on factual errors of language models](https://arxiv.org/pdf/2309.15098.pdf), Sep. 26 2023.
  - _"investigate the internal behavior of Transformer-based LLMs when they generate factually incorrect text"_
  - _"modeling factual queries as Constraint Satisfication Problems and use this framework to investigate how the model interacts internally with factual constraints"_
  - _"a strong positive relation between model's attention to constraint tokens and the factual accuracy of its response"_

#### Emergence and in-context learning

- [Emergence of segmentation with minimalistic white-box transformers](https://arxiv.org/pdf/2308.16271.pdf), Aug. 30 2023.
- [Are Emergent Abilities in Large Language Models just In-Context Learning?](https://arxiv.org/pdf/2309.01809.pdf), Sep. 4 2023.
- [Can LLMs learn from a single example?](https://www.fast.ai/posts/2023-09-04-learning-jumps/), Sep. 4 2023. `blogpost`.
- [How does representation impact in-context learning: A exploration on a synthetic task](https://arxiv.org/pdf/2309.06054.pdf), Sep. 12 2023.
- [Language Modeling Is Compression](https://arxiv.org/pdf/2309.10668.pdf), Sep. 19 2023.
- [In-Context Learning for Text Classification with Many Labels](https://arxiv.org/pdf/2309.10954.pdf), Sep. 19 2023.

#### Applications

- [Towards Ecologically Valid Research on Language User Interfaces](https://arxiv.org/abs/2007.14435), Jul. 28 2020.
- [Large language models in medicine: the potential and pitfalls](https://arxiv.org/ftp/arxiv/papers/2309/2309.00087.pdf), Sep. 8 2023.
- [On the Security Vulnerabilities of Text-to-SQL Models](https://arxiv.org/pdf/2211.15363.pdf), Mar. 2023.
- [When do Generative Query and Document Expansions Fail? A Comprehensive Study Across Methods, Retrievers, and Datasets](https://arxiv.org/pdf/2309.08541.pdf), Sep. 15 2023. `information retrieval`.
- [A Conversation is Worth A Thousand Recommendations: A Survey of Holistic Conversational Recommender Systems](https://arxiv.org/pdf/2309.07682.pdf), Sep. 14 2023.
- [Summarization is (Almost) Dead](https://arxiv.org/pdf/2309.09558.pdf), Sep. 18 2023.
- [PDFTriage: Question Answering over Long, Structured Documents](https://arxiv.org/pdf/2309.08872.pdf), Sep. 16 2023.
- [Guess & sketch: language model guided transpilation](https://arxiv.org/pdf/2309.14396.pdf), Sep. 25 2023.

---

### Evaluation

- [Thresh: A Unified, Customizable and Deployable Platform for Fine-Grained Text Evaluation](https://github.com/davidheineman/thresh), Aug. 2023. [paper](https://arxiv.org/abs/2308.06953).

### Codebase

- [nanoT5: A PyTorch Framework for Pre-training and Fine-tuning T5-style Models with Limited Resources](https://arxiv.org/pdf/2309.02373.pdf), Sep. 5 2023.
- [Adversarial Robustness Toolbox v1.0.0](https://arxiv.org/pdf/1807.01069.pdf), Nov. 15 2019.
  - **this codebase could be refered to for system design of machine learning toolkits**
  - _"Supported Machine Learning Libraries include TensorFlow (v1 and v2), Keras, PyTorch, MXNet, Scikit-learn, XGBoost, LightGBM, CatBoost, and GPy"_

### Systems

- [Saturn: An Optimized Data System for Multi-Large-Model Deep Learning Workloads](https://arxiv.org/pdf/2309.01226.pdf), Sep. 3 2023.




