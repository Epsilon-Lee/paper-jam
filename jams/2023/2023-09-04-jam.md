
- [Ten Years of Generative Adversarial Nets (GANs): A survey of the state-of-the-art](https://arxiv.org/pdf/2308.16316.pdf), Aug. 30 2023.
- [Construction Grammar and Artificial Intelligence](https://arxiv.org/pdf/2309.00135.pdf), Aug. 31 2023.
- [Probabilistic Self-supervised Learning via Scoring Rules Minimization](https://arxiv.org/pdf/2309.02048.pdf), Sep. 5 2023. `interpretability`.
- [Large Language Models for Generative Recommendation: A Survey and Visionary Discussions](https://arxiv.org/pdf/2309.01157.pdf), Sep. 3 2023.
- [Maximum Mean Discrepancy Meets Neural Networks: The Radon-Kolmogorov-Smirnov Test](https://arxiv.org/pdf/2309.02422.pdf), Sep. 5 2023. `distribution match`.
- [Automating Behavioral Testing in Machine Translation](https://arxiv.org/pdf/2309.02553.pdf), Sep. 5 2023.
- [Natural Example-Based Explainability: a Survey](https://arxiv.org/pdf/2309.03234.pdf), Sep. 5 2023. `interpretability`, `data attribution`.
- [Conservative Prediction via Data-Driven Confidence Minimization](https://arxiv.org/abs/2306.04974), Jun. 8 2023.
  - new architecture of decision making.
- [Introduction to Quantization cooked in ðŸ¤—](https://huggingface.co/blog/merve/quantization), Aug. 2023.
- [Exploring the Landscape of Natural Language Processing Research](https://arxiv.org/abs/2307.10652), Jul. 20 2023.
- [Eight Lessons Learned in Two Years of Ph.D.](https://ai.engin.umich.edu/2023/08/17/eight-lessons-learned-in-two-years-of-ph-d/), Aug. 17 2023. `blogpost` `advice`.
- [Geometry of Program Synthesis](https://arxiv.org/pdf/2103.16080.pdf), Mar. 2021.
- [Optimal Transport with Tempered Exponential Measures](https://arxiv.org/pdf/2309.04015.pdf), Sep. 7 2023. `optimal transport`.
  - this paper could be used as a entrance to the understanding of the topic ***Optimal Transport*** (OT), which I used to be afraid to learn
  - my old take on OT is that it seems to me another distribution matching objective or measure, but does it bring significantly usefulness in specific situations, I really don't know, so it's time to find out the answer
- [A Hands-on Tutorial for Learning with Noisy Labels](https://github.com/Docta-ai/IJCAI-tutorial), `ijcai2022`. `tutorial` `learning under noise`.
- [DBsurve: A discrepancy based method for discrete stochastic gradient estimation](https://arxiv.org/pdf/2309.03974.pdf), Sep. 7 2023.
- [Towards Mitigating Architecture Overfitting in Dataset Distillation](https://arxiv.org/pdf/2309.04195.pdf), Sep. 8 2023. `dataset distillation`.
- [A Gentle Introduction to Gradient-Based Optimization and Variational Inequalities for Machine Learning](https://arxiv.org/pdf/2309.04877.pdf), Sep. 9 2023.
  - Michael Jordan's recent works on recommender system and computational market design

### The most cited papers

- [Squeeze-and-Excitation Networks](https://arxiv.org/pdf/1709.01507.pdf), May 16 2019.
- [An image is worth 16 $$\times$$ 16 words: Transformers for image recognition at scale](https://arxiv.org/pdf/2010.11929.pdf), Jun. 3 2021.

### Uncertainty estimation

- [Adaptive conformal classification with noisy labels](https://arxiv.org/pdf/2309.05092.pdf), Sep. 10 2023.

### Class imbalance

- [Practical Lessons from Predicting Clicks on Ads at Facebook](http://quinonero.net/Publications/predicting-clicks-facebook.pdf), 2014.
- [To SMOTE, or not to SMOTE?](https://arxiv.org/pdf/2201.08528.pdf), May 11 2022.

### Efficiency

- [Unit Scaling: Out-of-the-Box Low-Precision Training](https://arxiv.org/pdf/2303.11257.pdf), May 30 2023. [code](https://console.paperspace.com/github/graphcore-research/out-of-the-box-fp8-training?machine=Free-IPU-POD4&container=graphcore/pytorch-paperspace%3A3.3.0-ubuntu-20.04-20230703&file=out_of_the_box_fp8_training.ipynb).

### Distribution shift

- [Better Practices for Domain Adaptation](https://arxiv.org/pdf/2309.03879.pdf), Sep. 7 2023.
- [On Pitfalls of Test-Time Adaptation](https://arxiv.org/pdf/2306.03536.pdf), Jun. 6 2023.

### AI safety

- [Provably safe systems: the only path to controllable AGI](https://arxiv.org/pdf/2309.01933.pdf), Sep. 5 2023.
- [From Preference Elicitation to Participatory ML: A Critical Survey & Guidelines for Future Research](https://dl.acm.org/doi/pdf/10.1145/3600211.3604661), 2023.
- [Subtle adversarial image manipulations influence both human and machine perception](https://www.nature.com/articles/s41467-023-40499-0), Aug. 15 2023. `nature`.

### Graph deep learning

- [Transformers Meet Directed Graphs](https://arxiv.org/pdf/2302.00049.pdf), Aug. 31 2023. [code](https://github.com/deepmind/digraph_transformer).

### Generative modeling

- [Learning multi-modal generative models with permutation-invariant encoders and tighter variational bounds](https://arxiv.org/pdf/2309.00380.pdf), Sep. 1 2023.

### Representation learning

- [Mechanism of feature learning in convolutional neural networks](https://arxiv.org/pdf/2309.00570.pdf), Sep. 1 2023.
- [Pareto Frontiers in Neural Feature Learning: Data, Compute, Width, and Luck](https://arxiv.org/pdf/2309.03800.pdf), Sep. 7 2023.
- [Gradient-Based Feature Learning under Structured Data](https://arxiv.org/pdf/2309.03843.pdf), Sep. 7 2023.
- [Probing transfer learning with a model of synthetic correlated datasets](https://arxiv.org/abs/2106.05418), Jan. 9 2021.
- [Towards understanding neural collapse: the effects of batch normalization and weight decay](https://arxiv.org/pdf/2309.04644.pdf), Sep. 9 2023. `neural collapse`.

### Learning dynamics and generalization

- [On the implicit bias of Adam](https://arxiv.org/pdf/2309.00079.pdf), Aug. 31 2023.
- [A law of data separation in deep learning](https://www.pnas.org/doi/full/10.1073/pnas.2221704120), Aug. 28 2023.
- [REPAIR: REnormalizing Permuted Activations for Interpolation Repair](https://arxiv.org/pdf/2211.08403.pdf), Dec. 2022.
- [Generalization Bounds: Perspectives from Information Theory and PAC-Bayes](https://arxiv.org/pdf/2309.04381.pdf), Sep. 8 2023.

### Community detection surveys

- [A survey of community detection approaches: from statistical modeling to deep learning](https://arxiv.org/pdf/2101.01669.pdf), Aug. 14 2021.
- [A comprehensive survey on community detection with deep learning](https://arxiv.org/pdf/2105.12584.pdf), Oct. 11 2021.

### Classic work of C. E. Shannon

- [Communication in the Presence of Noise](http://shilov-sss.ru/wp-content/uploads/2018/05/Shannon-C.-Communication-in-the-presence-of-noise-PIRE-37-I-194910.pdf), 1949.
- [Prediction and entropy of printed English](https://languagelog.ldc.upenn.edu/myl/Shannon1950.pdf), 1950.
- [The redundancy of English](https://jontalle.web.engr.illinois.edu/uploads/537.F18/Papers/Shannon50b.pdf), 1953.
- [Coding theorems for a discrete source with a fidelity criterion](https://mast.queensu.ca/~math474/shannon59.pdf), 1959.
- [Communication theory of secrecy systems](http://www.fr.beejack.com/sites/default/files/u3/Claude-Elwood-Shannon.pdf).
- [The zero error capacity of a noisy channel](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=1056798).

### Optimization in NNs and beyond

- [Nevergrad](https://facebookresearch.github.io/nevergrad/index.html), a gradient-free optimization platform.

### CTR, recsys etc.

- [AntM2C: A large scale dataset for multi-scenario multi-modal CTR prediction](https://arxiv.org/pdf/2308.16437.pdf), Aug. 31 2023.

### Time-series

- [CenTime: Event-Conditional Modelling of Censoring in Survival Analysis](https://arxiv.org/pdf/2309.03851.pdf), Sep. 7 2023.
- [Examining the Effect of Pre-training Followed by Fine-tuning on Time Series Classification](https://arxiv.org/pdf/2309.05256.pdf), Sep. 11 2023. `pretraining`.

### Data-centric

- [Pervasive Label Errors in Test Sets Destabilize Machine Learning Benchmarks](https://arxiv.org/abs/2103.14749), Mar. 26 2021.
  - [Automated Data Quality at Scale](https://cleanlab.ai/blog/automated-data-quality-at-scale/), Jul. 2023.

---

### LLMs and the new era of machine learning

- [Augmented Language Models: a Survey](https://arxiv.org/pdf/2302.07842.pdf), Feb. 15 2023.
- [Ingredients of understanding](https://dileeplearning.substack.com/p/ingredients-of-understanding?utm_source=profile&utm_medium=reader2), Aug. 2023. `blogpost`.
- [Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient MoE for Instruction Tuning](https://arxiv.org/pdf/2309.05444.pdf), Sep. 11 2023. [code](https://github.com/for-ai/parameter-efficient-moe).
- [Does Writing with Language Models Reduce Content Diversity?](https://arxiv.org/pdf/2309.05196.pdf), Sep. 11 2023. `He He`.
- [Textbooks Are All You Need II: phi-1.5 technical report](https://arxiv.org/pdf/2309.05463.pdf), Sep. 11 2023.

#### Distributed SGD

- [Don't Use Large Mini-Batches, Use Local SGD](https://arxiv.org/abs/1808.07217), Aug. 22 2018.
- [Why (and when) does local SGD generalize better than SGD?](https://arxiv.org/pdf/2303.01215.pdf), Mar. 9 2023.

#### Multi-modal

- [A Joint Study of Phrase Grounding and Task Performance in Vision and Language Models](https://arxiv.org/pdf/2309.02691.pdf), arXiv Sep. 6 2023.
- [Scaling autoregressive multi-modal models: pretraining and instruction-tuning](https://arxiv.org/pdf/2309.02591.pdf), Sep. 5 2023. [metaseq](https://github.com/facebookresearch/metaseq).
- [NExT-GPT: Any-to-Any Multimodal LLM](https://arxiv.org/pdf/2309.05519.pdf), Sep. 11 2023. [project page](https://next-gpt.github.io/).

#### Data curation

- [The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only](https://arxiv.org/abs/2306.01116), Jun. 1 2023.
- [MADLAD-400: A Multilingual And Document-Level Large Audited Dataset](https://arxiv.org/pdf/2309.04662.pdf), Sep. 9 2023.
  - model checkpoints are available
- [When Less is More: Investigating Data Pruning for Pretraining LLMs at Scale](https://arxiv.org/pdf/2309.04564.pdf), Sep. 8 2023.

#### Reasoning

- [On the Planning, Search, and Memorization Capabilities of Large Language Models](https://arxiv.org/pdf/2309.01868.pdf), Sep. 5 2023.
- [Taken out of context: On measuring situational awareness in LLMs](https://arxiv.org/pdf/2309.00667.pdf), Sep. 1 2023.
- [Making large language models better reasoners with alignment](https://arxiv.org/pdf/2309.02144.pdf), Sep. 5 2023.
- [Large language models as optimizers](https://arxiv.org/pdf/2309.03409.pdf), Sep. 7 2023.
- [Hypothesis search: Inductive reasoning with language models](https://arxiv.org/pdf/2309.05660.pdf), Sep. 11 2023.

#### Alignment

- [RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback](https://arxiv.org/pdf/2309.00267.pdf), Sep. 1 2023.
- [Baseline defenses for adversarial attacks against aligned language models](https://arxiv.org/pdf/2309.00614.pdf), Sep. 1 2023.
- [Efficient RLHF: Reducing the memory usage of PPO](https://arxiv.org/pdf/2309.00754.pdf), Sep. 1 2023.
- [Bias and Fairness in Large Language Models: A Survey](https://arxiv.org/pdf/2309.00770.pdf), Sep. 2 2023.
- [Generative Social Choice](https://arxiv.org/pdf/2309.01291.pdf), Sep. 3 2023.
- [A Survey on Hallucination in Large Language Models](https://arxiv.org/pdf/2309.01219.pdf), Sep. 3 2023.
- [Beyond human data: RLAIF needs a rebrand](https://www.interconnects.ai/p/beyond-human-data-rlaif), Apr. 26 2023. `blogpost`.
- [Specifying objectives in RLHF](https://www.interconnects.ai/p/specifying-objectives-in-rlhf), Aug. 2 2023. `blogpost`.
- [Certifying LLM safety against adversarial prompting](https://arxiv.org/pdf/2309.02705.pdf), Sep. 6 2023.

#### Understanding transformers

- [Transformers as Support Vector Machines](https://arxiv.org/pdf/2308.16898.pdf), Aug. 31 2023.

#### Scaling law

- [Deep Learning Scaling is Predictable, Empirically](https://arxiv.org/abs/1712.00409), Dec. 1 2017.

#### Mechanistic interpretability

- [NeuroSurgeon: A Toolkit for Subnetwork Analysis](https://arxiv.org/pdf/2309.00244.pdf), Sep. 1 2023. [code](https://github.com/mlepori1/NeuroSurgeon).
- [Cognitive architectures for language agents](https://arxiv.org/pdf/2309.02427.pdf), Sep. 5 2023.
- [Emergent Linear Representations in World Models of Self-Supervised Sequence Models](https://arxiv.org/pdf/2309.00941.pdf), Sep. 2 2023.
- [Explainability for Large Language Models: A Survey](https://arxiv.org/pdf/2309.01029.pdf), Sep. 2 2023.
- [Explaining grokking through circuit efficiency](https://arxiv.org/pdf/2309.02390.pdf), Sep. 5 2023.
- [Representations Matter: Embedding Modes of Large Language Models using Dynamic Mode Decomposition](https://arxiv.org/pdf/2309.01245.pdf), Sep. 3 2023.
- [A function interpretation benchmark for evaluating interpretability methods](https://arxiv.org/pdf/2309.03886.pdf), Sep. 7 2023.

#### Emergence and in-context learning

- [Emergence of segmentation with minimalistic white-box transformers](https://arxiv.org/pdf/2308.16271.pdf), Aug. 30 2023.
- [Are Emergent Abilities in Large Language Models just In-Context Learning?](https://arxiv.org/pdf/2309.01809.pdf), Sep. 4 2023.
- [Can LLMs learn from a single example?](https://www.fast.ai/posts/2023-09-04-learning-jumps/), Sep. 4 2023. `blogpost`.

#### Applications

- [Towards Ecologically Valid Research on Language User Interfaces](https://arxiv.org/abs/2007.14435), Jul. 28 2020.
- [Large language models in medicine: the potential and pitfalls](https://arxiv.org/ftp/arxiv/papers/2309/2309.00087.pdf), Sep. 8 2023.
- [On the Security Vulnerabilities of Text-to-SQL Models](https://arxiv.org/pdf/2211.15363.pdf), Mar. 2023.

---

### Evaluation

- [Thresh: A Unified, Customizable and Deployable Platform for Fine-Grained Text Evaluation](https://github.com/davidheineman/thresh), Aug. 2023. [paper](https://arxiv.org/abs/2308.06953).

### Codebase

- [nanoT5: A PyTorch Framework for Pre-training and Fine-tuning T5-style Models with Limited Resources](https://arxiv.org/pdf/2309.02373.pdf), Sep. 5 2023.

### Systems

- [Saturn: An Optimized Data System for Multi-Large-Model Deep Learning Workloads](https://arxiv.org/pdf/2309.01226.pdf), Sep. 3 2023.




