
- [Out-of-Domain Robustness via Targeted Augmentations](https://arxiv.org/pdf/2302.11861.pdf), Feb. 23 2023. `ood generalizatioin`.
- [Reduce, Reuse, Recycle: Compositional Generation with Energy-Based Diffusion Models and MCMC](https://arxiv.org/abs/2302.11552), Feb. 22 2023.
- [Goal Driven Discovery of Distributional Differences via Language Descriptions](https://arxiv.org/pdf/2302.14233.pdf), Feb. 28 2023.
- [Understanding the Covariance Structure of Convolutional Filters](https://arxiv.org/abs/2210.03651), Oct. 7 2022.
- [Toolkit: Interpretability rule extraction, learning](https://github.com/scikit-learn-contrib/skope-rules).
- [Provable Robustness for Streaming Models with a Sliding Window](https://arxiv.org/pdf/2303.16308.pdf), Mar. 28 2023.
- [Identification of Negative Transfers in Multitask Learning Using Surrogate Models](https://arxiv.org/pdf/2303.14582.pdf), Mar. 25 2023. `mtl`.
- [A Comprehensive Survey on Test-Time Adaptation under Distribution Shifts](https://arxiv.org/pdf/2303.15361.pdf), Mar. 27 2023. `distribution shift`.

### Continual learning

- [Sparse distributed memory is a continual learner](https://arxiv.org/pdf/2303.11934.pdf), Mar. 20 2023.

### Active learning

- [Streaming Active Learning with Deep Neural Networks](https://arxiv.org/pdf/2303.02535.pdf), Mar. 5 2023. `streaming`.

### Causal inference

- [Causal Deep Learning](https://arxiv.org/pdf/2303.02186.pdf), Mar. 3 2023. `survey`.

### Evaluation, MLOps

- [Are We Learning Yet? A Meta-Review of Evaluation Failures Across Machine Learning](https://thomasliao.com/are_we_learning_yet.pdf), `nips2021` `dataset and benchmark track`.
- [The Dangers of Underclaiming: Reasons for Caution When Reporting How NLP Systems Fail](https://arxiv.org/abs/2110.08300), Mar. 2022. `acl2022` `position paper`.

### classics

- [Mining Frequent Patterns without Candidate Generation: A Frequent-Pattern Tree Approach](https://cs.nju.edu.cn/_upload/tpl/01/0b/267/template267/zhouzh.files/course/dm/reading/reading04/han_dmkd04.pdf), 2004.
- [A Survey of Sequential Pattern Mining](https://www.philippe-fournier-viger.com/dspr-paper5.pdf), 2017.

### Self-supervised learning, representation learning

- [Towards Democratizing Joint-Embedding Self-Supervised Learning](https://arxiv.org/abs/2303.01986), Mar. 3 2023.
- [Toward a Geometric Theory of Manifold Untangling](https://arxiv.org/pdf/2303.04203.pdf), Mar. 7 2023.
- [A message passing perspective on learning dynamics of contrastive learning](https://arxiv.org/pdf/2303.04435.pdf), Mar. 8 2023.
  - _"if we cast a contrastive objective equivalently into the feature space, then its learning dynamics admits an interpretable form [...] its gradient descent corresponds to a specific message passing scheme on the corresponding augmentation graph"_
- [Active Self-Supervised Learning: A Few Low-Cost Relationships Are All You Need](https://arxiv.org/pdf/2303.15256.pdf), Mar. 27 2023. `ssl` `active learning`.
- [Temperature schedules for self-supervised contrastive methods on long-tail data](https://arxiv.org/pdf/2303.13664.pdf), Mar. 2023. `contrastive learning`.
- [On the stepwise nature of self-supervised learning](https://arxiv.org/pdf/2303.15438.pdf), Mar. 27 2023. `ssl`.
- [On the duality between contrastive and non-contrastive self-supervised learning](https://openreview.net/forum?id=kDEL91Dufpa), `iclr23`.

### LLMs

- [The Shaky Foundations of Foundation Models in Healthcare](https://twitter.com/katieelink/status/1633123165043048448). [blog](https://hai.stanford.edu/news/shaky-foundations-foundation-models-healthcare). Feb 27, 2023.
- [core-views-on-ai-safety](https://twitter.com/AnthropicAI/status/1633873176995168268), Anthropic.
- [Reward redesign with language models](https://arxiv.org/pdf/2303.00001.pdf), Feb. 27 2023.
- [A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT](https://arxiv.org/pdf/2303.04226.pdf), Mar. 7 2023. `survey`.
- [Foundation Models for Decision Making: Problems, Methods, and Opportunities](https://arxiv.org/pdf/2303.04129.pdf), Mar. 7 2023. `survey` `rl`.
- [Training Language Models with Language Feedback at Scale](https://arxiv.org/pdf/2303.16755.pdf), Mar. 28 2023.
- [Improving Code Generation by Training with Natural Language Feedback](https://arxiv.org/pdf/2303.16749.pdf), Mar. 28 2023.
- [Scaling Expert Language Models with Unsupervised Domain Discovery](https://arxiv.org/pdf/2303.14177.pdf)，Mar. 24 2023.
- [Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning](https://arxiv.org/pdf/2303.10475.pdf), Mar. 21 2023. `survey` of `instruction learning`.
- [The Life Cycle of Knowledge in Big Language Models: A Survey](https://arxiv.org/pdf/2303.07616.pdf), Mar. 14 2023. `survey`.
- [ChatGPT and leaderboard](https://ehudreiter.com/2023/03/27/chatgpt-and-leaderboard/), Mar. 27 2023. `blogpost`.

#### Ability of LLMs

- [Language Model Behavior: A Comprehensive Survey](https://arxiv.org/pdf/2303.11504.pdf), Mar. 20 2023.
- [A Comprehensive Capability Analysis of GPT-3 and GPT-3.5 Series Models](https://arxiv.org/ftp/arxiv/papers/2303/2303.10420.pdf), Mar. 2023.
- [Zero-shot Clinical Entity Recognition using ChatGPT](https://arxiv.org/pdf/2303.16416.pdf), Mar. 29 2023. `ner` of `clilical` texts.
- [ChatGPT is a Knowledgeable but Inexperienced Solver: An Investigation of Commonsense Problem in Large Language Models](https://arxiv.org/pdf/2303.16421.pdf), Mar. 29 2023. `commonsense`.
- [Consistency Analysis of ChatGPT](https://arxiv.org/pdf/2303.06273.pdf), Mar. 11 2023.

#### Memorization, privacy

- [Data-copying in generative models: a formal framework](https://arxiv.org/pdf/2302.13181.pdf), Mar. 1 2023.

#### Decoding

- [Navigating the grey area: expressions of overconfidence and uncertainty in language models](https://arxiv.org/pdf/2302.13439.pdf), Feb. 26 2023.
- [On the Risks of Stealing the Decoding Algorithms of Language Models](https://arxiv.org/pdf/2303.04729.pdf), Mar. 9 2023.
  - _"an adversary with typical API access to an LM can steal the type and hyperparameters of its decoding algorithms at very low monetary costs [...] We demonstrate the feasibility of stealing such information with only a few dollars $0.8, $1, $4 and $40 for the four versions of GPT-3"_

#### Representaion learning

- [Improving representational continuity with supervised continued pretraining](https://arxiv.org/pdf/2302.13289.pdf), Feb. 26 2023.
  - [Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution](https://arxiv.org/pdf/2202.10054.pdf), Feb. 21 2022.

#### Factual faithfulness

- [Recitation-Augmented Language Models](https://arxiv.org/abs/2210.01296), Oct. 4 2022.

#### Alignment, RLHF

- [Opinion on RL for ChatGPT](https://twitter.com/zhengyaojiang/status/1630674348443934721).
- [Foundation models and fair use](https://arxiv.org/pdf/2303.15715.pdf), Mar. 28 2023.

#### Products

- [The first AI product for UI design](https://twitter.com/Saboo_Shubham_/status/1630617260749643777).
- [写作猫](https://xiezuocat.com/chat). Created by Yi Ma's student.

### Code processing, translation

- [A Syntactic Neural Model for General-Purpose Code Generation](https://arxiv.org/pdf/1704.01696.pdf), Apr. 2017.
- [Learning to Mine Aligned Code and Natural Language Pairs from Stack Overflow](https://arxiv.org/pdf/1805.08949.pdf), May 2018.
- [Unsupervised Translation of Programming Languages](https://arxiv.org/pdf/2006.03511.pdf), `nips2020`.
- [Evaluating Large Language Models Trained on Code](https://arxiv.org/pdf/2107.03374.pdf), `icml2021`.
- [Natural Language to Code Translation with Execution](https://arxiv.org/pdf/2204.11454.pdf), Nov. 2022.

### Codebase

- [ChatDoctor](https://github.com/Kent0n-Li/ChatDoctor).

### Interpretability

- [Understanding and Exploring the Whole Set of Good Sparse Generalized Additive Models](https://arxiv.org/pdf/2303.16047.pdf), Mar. 28 2023. `transparent model`.
- [How good neural network interpretation methods really are? A quantitative benchmark](https://arxiv.org/pdf/2304.02383.pdf), Apr. 5 2023.
- [IDGI: A Framework to Eliminate Explanation Noise from Integrated Gradients](https://arxiv.org/abs/2303.14242), Mar. 24 2023. `cvpr23`.
