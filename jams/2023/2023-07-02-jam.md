
- [Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding](https://openreview.net/attachment?id=bF1LVbP493&name=pdf), `icml2023`.
- [Effective resistance in metric spaces](https://arxiv.org/pdf/2306.15649.pdf), Jun. 27 2023.
- [ZipIt! Merging Models from Different Tasks without Training](https://arxiv.org/pdf/2305.03053.pdf), May 4 2023. `cvpr2023`.
- [Should you marginalize over possible tokenizations?](https://arxiv.org/pdf/2306.17757.pdf), Jun. 30 2023.
  - _"we analyze whether the practice of ignoring the marginalization is justified"_
  - _"results show that the gap in log-likelihood is no larger than 0.5% in most cases, but it becomes more pronounced for data with long complex words"_
- [Log-linear Guardedness and its Implications](https://arxiv.org/abs/2210.10012), Jun. 29 2023. `acl2023`.

### XXXformer

- [Memformer: A Memory-Augmented Transformer for Sequence Modeling](https://arxiv.org/pdf/2010.06891.pdf), Apr. 12 2022.

### Active learning

- [Understanding Uncertainty Sampling](https://arxiv.org/pdf/2307.02719.pdf), Jul. 6 2023.

### Uncertainty estimation

- [Quantification of Uncertainty with Adversarial Models](https://arxiv.org/pdf/2307.03217.pdf), Jul. 6 2023.
- [A Novel Bayes’ Theorem for Upper Probabilities](https://arxiv.org/pdf/2307.06831.pdf), Jul. 13 2023.
- [Beyond Intuition, a Framework for Applying GPs to Real-World Data](https://arxiv.org/pdf/2307.03093.pdf), Jul. 6 2023.

### Distribution shift

- [Tackling Combinatorial Distribution Shift: A Matrix Completion Perspective](https://arxiv.org/pdf/2307.06457.pdf), Jul. 12 2023.

### Learning dynamics

- [Trajectory Alignment: Understanding the Edge of Stability Phenomenon via Bifurcation Theory](https://arxiv.org/pdf/2307.04204.pdf), Jul. 9 2023.

### Time series

- [Generalized Time Warping Invariant Dictionary Learning for Time Series Classification and Clustering](https://arxiv.org/pdf/2306.17690.pdf), Jun. 30 2023.

### Inductive bias

- [The ELM Neuron: an Efficient and Expressive Cortical Neuron Model Can Solve Long-Horizon Tasks.](https://arxiv.org/pdf/2306.16922.pdf), Jun. 14 2023.
- [The Architecture of a Biologically Plausible Language Organ](https://arxiv.org/pdf/2306.15364.pdf), Jun. 27 2023.
- [The Shaped Transformer: Attention Models in the Infinite Depth-and-Width Limit](https://arxiv.org/pdf/2306.17759.pdf), Jun. 30 2023.
  - _"we believe that our theory sets the stage for future work on training and generalization in deep learning"_
- [How Deep Neural Networks Learn Compositional Data: The Random Hierarchy Model](https://arxiv.org/pdf/2307.02129.pdf), Jul. 5 2023.

### Fintech

- [Realistic Synthetic Financial Transactions for Anti-Money Laundering Models](https://arxiv.org/pdf/2306.16424.pdf), Jun. 22 2023.

### Data imputation

- [Numerical Data Imputation for Multimodal Data Sets: A Probabilistic Nearest-Neighbor Kernel Density Approach](https://arxiv.org/pdf/2306.16906.pdf), Jun. 29 2023.

### Evaluation

- [What Makes ImageNet Look Unlike LAION](https://arxiv.org/pdf/2306.15769.pdf), Jun. 27 2023.
  - _"Our explanation formalizes a long-held intuition in the community that ImageNet images are stereotypical, unnatural, and overly simple representations of the class category"_
 
### Hyperparameter optimization

- [PriorBand: Practical Hyperparameter Optimization in the Age of Deep Learning](https://arxiv.org/pdf/2306.12370.pdf), Jun. 21 2023.

### Machine unlearning

- [Ticketed Learning–Unlearning Schemes](https://arxiv.org/pdf/2306.15744.pdf), Jun. 27 2023.

### Interpretability

- [Delivering Inflated Explanations](https://arxiv.org/pdf/2306.15272.pdf), Jun. 27 2023. `feature attribution`.
- [Where Does My Model Underperform? A Human Evaluation of Slice Discovery Algorithms](https://arxiv.org/pdf/2306.08167.pdf), Jun. 13 2023. `systematic error analysis`.
- [Adversarial Attacks on the Interpretation of Neuron Activation Maximization](https://arxiv.org/pdf/2306.07397.pdf), Jun. 12 2023.
- [On Minimizing the Impact of Dataset Shifts on Actionable Explanations](https://arxiv.org/pdf/2306.06716.pdf), Jun. 11 2023. `distribution shift`.
- [GuidedMixup: An Efficient Mixup Strategy Guided by Saliency Maps](https://arxiv.org/pdf/2306.16612.pdf), Jun. 29 2023. `explanation-guided learning`.
- [High Fidelity Image Counterfactuals with Probabilistic Causal Models](https://arxiv.org/pdf/2306.15764.pdf), Jun. 27 2023. `counterfactual`.
- [Geometric Autoencoders – What You See is What You Decode](https://arxiv.org/pdf/2306.17638.pdf), Jun. 30 2023. `dimension reduction`.

### Good old nlp

- [Linear Classifier: An Often-Forgotten Baseline for Text Classification](https://aclanthology.org/2023.acl-short.160.pdf), `acl2023`.

### Compositionality

- [Compositional Generalization from First Principles](https://arxiv.org/pdf/2307.05596.pdf), Jul. 10 2023.

### Representation learning

- [Provable Multi-Task Representation Learning by Two-Layer ReLU Neural Networks](https://arxiv.org/pdf/2307.06887.pdf), Jul. 13 2023.

---

### LLMs

- [Next Steps for Human-Centered Generative AI: A Technical Perspective](https://arxiv.org/ftp/arxiv/papers/2306/2306.15774.pdf), Jun. 28 2023.
- [Beyond Scale: the Diversity Coefficient as a Data Quality Metric Demonstrates LLMs are Pre-trained on Formally Diverse Data](https://arxiv.org/pdf/2306.13840.pdf), Jun. 24 2023.
- [Provable Robust Watermarking for AI-Generated Text](https://arxiv.org/pdf/2306.17439.pdf), Jun. 30 2023.
- [Large Language Models](https://arxiv.org/pdf/2307.05782.pdf), Jul. 11 2023.

#### Data-centric

- [Improving Retrieval-Augmented Large Language Models via Data Importance Learning](https://arxiv.org/pdf/2307.03027.pdf), Jul. 6 2023.

#### Pre-training

- [Text Alignment Is An Efficient Unified Model for Massive NLP Tasks](https://arxiv.org/pdf/2307.02729.pdf), Jul. 6 2023. [code](https://github.com/yuh-zha/Align).

#### Fine-tuning

- [Parameter-Efficient Fine-Tuning of LLaMA for the Clinical Domain](https://arxiv.org/pdf/2307.03042.pdf), Jul. 6 2023.
- [Contrastive Error Attribution for Finetuned Language Models](https://arxiv.org/pdf/2212.10722.pdf), Jul. 11 2023.

#### Formal language

- [Why can neural language models solve next-word prediction? A mathematical perspective](https://arxiv.org/pdf/2306.17184.pdf), Jun. 20 2023.

#### Alignment

- [Is RLHF More Difficult than Standard RL?](https://arxiv.org/pdf/2306.14111.pdf), Jun. 25 2023.
- [Are aligned neural networks adversarially aligned?](https://arxiv.org/pdf/2306.15447.pdf), Jun. 26 2023.
- [Automatic Calibration and Error Correction for Large Language Models via Pareto Optimal Self-Supervision](https://arxiv.org/pdf/2306.16564.pdf), Jun. 28 2023.
- [On the Exploitability of Instruction Tuning](https://arxiv.org/pdf/2306.17194.pdf), Jun. 28 2023.

#### Longer context

- [Extending context window of large language models via position interpolation](https://arxiv.org/pdf/2306.15595.pdf), Jun. 28 2023.
- [Length Generalization in Arithmetic Transformers](https://arxiv.org/pdf/2306.15400.pdf), Jun. 27 2023.
- [Lost in the Middle: How Language Models Use Long Contexts](https://arxiv.org/pdf/2307.03172.pdf), Jul. 6 2023.

#### Scaling law

- [The Underlying Scaling Laws and Universal Statistical Structure of Complex Datasets](https://arxiv.org/pdf/2306.14975.pdf), Jun. 26 2023.
- [Scaling Laws Do Not Scale](https://arxiv.org/pdf/2307.03201.pdf), Jul. 5 2023.

#### In-context learning

- [Pretraining task diversity and the emergence of non-Bayesian in-context learning for regression](https://arxiv.org/pdf/2306.15063.pdf), Jun.26 2023.
- [One Step of Gradient Descent is Provably the Optimal In-Context Learner with One Layer of Linear Self-Attention](https://arxiv.org/pdf/2307.03576.pdf), Jul. 7 2023.
- [Scaling in-context demonstration with structured attention](https://arxiv.org/pdf/2307.02690.pdf), Jul. 5 2023.
  - _"to overcome length limit, order sensitivity of in-context demonstration"_ 

#### Mechanistic interpretability

- [The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks](https://arxiv.org/pdf/2306.17844.pdf), Jun. 30 2023.

#### Algorthm learning

- [Teaching Arithmetic to Small Transformers](https://arxiv.org/pdf/2307.03381.pdf), Jul. 7 2023. [code](https://github.com/lee-ny/teaching_arithmetic).

#### Prompting

- [SCOTT: Self-Consistent Chain-of-Thought Distillation](https://arxiv.org/pdf/2305.01879.pdf), May 21 2023.

#### Application

- [What Should Data Science Education Do with Large Language Models?](https://arxiv.org/pdf/2307.02792.pdf), Jul. 7 2023. `education`.
- [Building Community Driven Libraries of Natural Programs](https://openreview.net/forum?id=iRea6QCxi1), `iclr2023`.

#### Safety

- [Jailbroken: How Does LLM Safety Training Fail?](https://arxiv.org/pdf/2307.02483.pdf), Jul. 5 2023.

#### Continual learning

- [Towards Robust and Efficient Continual Language Learning](https://arxiv.org/pdf/2307.05741.pdf), Jul. 11 2023.




