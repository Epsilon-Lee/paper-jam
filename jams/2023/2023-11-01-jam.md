
- [Factor Fitting, Rank Allocation, and Partitioning in Multilevel Low Rank Matrices](https://arxiv.org/pdf/2310.19214.pdf), Oct. 30 2023.
- [Revisiting the Learnability of Apple Tasting](https://arxiv.org/pdf/2310.19064.pdf), Oct. 29 2023.
- [Learning an inventory control policy with general inventory arrival dynamics](https://arxiv.org/pdf/2310.17168.pdf), Oct. 26 2023.
- [MaxEnt loss: Constrained maximum entropy for calibration under out-of-distribution shift](https://arxiv.org/pdf/2310.17159.pdf), Oct. 26 2023.

### Distribution shift

- [Learning optimal classification trees robust to distribution shifts](https://arxiv.org/pdf/2310.17772.pdf), Oct. 26 2023.

### Robustness vs generalization

- [Group robust classification: Without any group information](https://arxiv.org/pdf/2310.18555.pdf), Oct. 28 2023.

### Data weigting

- [A challenge in reweighting data with bilevel optimization](https://arxiv.org/pdf/2310.18123.pdf), Oct. 26 2023.
- [How re-sampling helps for long-tail learning](https://arxiv.org/pdf/2310.18236.pdf), Oct. 27 2023.

### Representation learning

- [A spectral condition for feature learning](https://arxiv.org/pdf/2310.17813.pdf), Oct. 26 2023.

### Causal inference

- [Object-centric architectures enable efficient causal representation learning](https://arxiv.org/pdf/2310.18496.pdf), Oct. 29 2023.
- [Sample complexity boudns for score-matching: Causal discovery and generative modeling](https://arxiv.org/pdf/2310.18123.pdf), Oct. 27 2023.
- [Identifying latent polynomial causal models through the lens of change](https://arxiv.org/pdf/2310.15580.pdf), Oct. 24 2023.

### Generalization mystery

- [A path to simpler model starts with noise](https://arxiv.org/pdf/2310.19726.pdf), Oct. 30 2023. `data-centric`
  - _"Our results explain a key aspect of why simpler models often tend to perform as well as black box models on complex, noisier datasets"_
- [The Memory Perturbation Equation: Understanding Modelâ€™s Sensitivity to Data](https://arxiv.org/pdf/2310.19273.pdf), Oct. 30 2023. `uncertainty` `data-centric`
  - _"we present Memory-Perturbation Equation which relates model's sensitivity to perturbation in its training data"_
- [Good regularity creates large learning rate implicit biases: edge of stability, balancing, and catapult](https://arxiv.org/pdf/2310.17087.pdf), Oct. 26 2023. `learning dynamics`

### Interpretability

- [Towards a fuller understanding of neurons with clustered compositional explanations](https://arxiv.org/pdf/2310.18443.pdf), Oct. 27 2023.
- [How well do feature-additive explainers explain feature-additive predictors](https://arxiv.org/pdf/2310.18496.pdf), Oct. 27 2023.

---

### LLMs

- [LAUGHING HYENA DISTILLERY: Extracting compact recurrences from convolutions](https://arxiv.org/pdf/2310.18780.pdf), Oct. 28 2023.
- [Proving test set contamination in black box language models](https://arxiv.org/pdf/2310.17623.pdf), Oct. 26 2023.
- [POE: Process of Elimination for Multiple Choice Reasoning](https://arxiv.org/pdf/2310.15575.pdf), Oct. 24 2023.
- [Improving generalization in large language models by learning prefix subspaces](https://arxiv.org/pdf/2310.15793.pdf), Oct. 24 2023.
- [Specialist or Generalist? Instruction Tuning for Specific NLP Tasks](https://arxiv.org/pdf/2310.15326.pdf), Oct. 23 2023.

#### Alignment

- [Persons as a way to model truthfulness in language models](https://arxiv.org/pdf/2310.17813.pdf), Oct. 30 2023.
- [Hallucination Detection for Grounded Instruction Generation](https://arxiv.org/pdf/2310.15319.pdf), Oct. 23 2023.
- [Failures Pave the Way: Enhancing Large Language Models through Tuning-free Rule Accumulation](https://arxiv.org/pdf/2310.15746.pdf), Oct. 24 2023.

#### Data-centric

- [DoGE: Domain reweigting with generalization estimation](https://arxiv.org/pdf/2310.15393.pdf), Oct. 23 2023.

#### Reasoning, coding ability

- [LILO: Learning interpretable libraries by compressing and documenting code](https://arxiv.org/pdf/2310.19791.pdf), Oct. 30 2023.

#### Generalization of LLMs

- [When do prompting and prefix-tuning work? A theory of capabilities and limitations](https://arxiv.org/pdf/2310.19698.pdf), Oct. 30 2023.
- [Skill-Mix: A flexible and expandable family of evaluations for AI models](https://arxiv.org/pdf/2310.17567.pdf), Oct. 26 2023.
- [In-context learning dynamics with random binary sequences](https://arxiv.org/pdf/2310.17639.pdf), Oct. 26 2023.
- [Transformers learn high-order optimization methods for in-context learning: A study with linear models](https://arxiv.org/pdf/2310.17086.pdf), Oct. 26 2023.

#### Mechanistic interpretability

- [Codebook features: Sparse and discrete interpretability for neural networks](https://arxiv.org/pdf/2310.17230.pdf), Oct. 26 2023.
- [How do language models bind entities in context](https://arxiv.org/pdf/2310.17191.pdf), Oct. 26 2023.
- [Function vectors in large language models](https://arxiv.org/pdf/2310.15213.pdf), Oct. 23 2023.
- [Is probing all you need? Indicator tasks as an alternative to probing embedding spaces](https://arxiv.org/pdf/2310.15905.pdf), Oct. 24 2023.
- [What algorithms can Transformers learn? A study in length generalization](https://arxiv.org/pdf/2310.16028.pdf), Oct. 24 2023.
