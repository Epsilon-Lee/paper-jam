
- [Statistical exploration of the manifold hypothesis](https://arxiv.org/pdf/2208.11665.pdf), Dec. 4 2023.
- [Occam's razor](https://homepages.math.uic.edu/~lreyzin/papers/blumer86.pdf), 1987.
- [Simplifying Neural Network Training Under Class Imbalance](https://arxiv.org/pdf/2312.02517.pdf), Dec. 5 2023.
- [An Invitation to Deep Reinforcement Learning](https://arxiv.org/pdf/2312.08365.pdf), Dec. 13 2023. `survey`.
- [Perspectives on the State and Future of Deep Learning - 2023](https://arxiv.org/pdf/2312.09323.pdf), Dec. 19 2023.
- [Understanding the Detrimental Class-level Effects of Data Augmentation](https://openreview.net/pdf?id=yageaKlk7S), `neurips2023`.
- [Lecture notes in probabilistic diffusion models](https://arxiv.org/pdf/2312.10393.pdf), Dec. 16 2023.
- [An Ambiguity Measure for Recognizing the Unknowns in Deep Learning](https://arxiv.org/pdf/2312.06077.pdf), Dec. 11 2023. `uncertainty`.
- [KBFormer: A diffusion model for structured entity completion](https://arxiv.org/pdf/2312.05253.pdf), Dec. 8 2023.
- [Train ’n Trade: Foundations of Parameter Markets](https://arxiv.org/pdf/2312.04740.pdf), Dec. 7 2023.
- [Certified Minimax Unlearning with Generalization Rates and Deletion Capacity](https://arxiv.org/pdf/2312.10336.pdf), Dec. 16 2023. `machine unlearning`.
- [TOD-Flow: Modeling the Structure of Task-Oriented Dialogues](https://arxiv.org/pdf/2312.04668.pdf), Dec. 7 2023. `dialogue system`.
- [Estimating Fréchet bounds for validating programmatic weak supervision](https://arxiv.org/pdf/2312.04601.pdf), Dec. 7 2023.
- [TaskMet: Task-Driven Metric Learning for Model Learning](https://arxiv.org/pdf/2312.05250.pdf), Dec. 8 2023.
- [Simplifying Neural Network Training Under Class Imbalance](https://arxiv.org/pdf/2312.02517.pdf), Dec. 5 2023.
- [TensorCodec: Compact Lossy Compression of Tensors without Strong Data Assumptions](https://arxiv.org/pdf/2309.10310.pdf), Sep. 20 2023.
- [On the Effects of Randomness on Stability of Learning with Limited Labelled Data: A Systematic Literature Review](https://arxiv.org/pdf/2312.01082.pdf), Dec. 2 2023.

### Generative models

- [$$t^3$$-Variational autoencoders: Learning heavy-tailed data with student's t and power divergence](https://arxiv.org/pdf/2312.01133.pdf), Dec. 2 2023.

### Optimization of deep neural networks

- [How to guess a gradient](https://arxiv.org/pdf/2312.05134.pdf), Dec. 7 2023.
- [Bridging Discrete and Backpropagation: Straight-Through and Beyond](https://arxiv.org/pdf/2304.08612.pdf), Oct. 16 2023.

### Self-supervised learning, representation learning etc.

- [LiDAR: Sensing linear probing performance in joint embedding SSL architectures](https://arxiv.org/pdf/2312.04000.pdf), Dec. 7 2023.
  - _"LiDAR (Linear Discriminant Analysis Rank), a metric designed to measure the quality of representations with JE architectures"_
- [Hard View Selection for Self-Supervised Learning](https://arxiv.org/abs/2310.03940), Dec. 1 2023.
  - sample efficiency
  - _"With only 300-epoch pretraining, HVS is able to closely rival the 800-epoch DINO baseline which remains very favorable even when factoring in the slowdown induced by the additional forwards of HVS."_

### Learning theory

- [The sample complexity of multi-distribution learning](https://arxiv.org/pdf/2312.04027.pdf), Dec. 7 2023.
- [Optimal multi-distribution learning](https://arxiv.org/pdf/2312.05134.pdf), Dec. 8 2023.
- [Generalization properties of retrieval-based models](https://arxiv.org/pdf/2210.02617.pdf), Oct. 6 2022.
  - _"We analyze a local learning framework that employs an explicit local empirical risk minimization based on retrieved examples for each input instance. [...] we show that breaking down the underlying learning task into local sub-tasks enables the model to employ a low complexity parametric component to ensure good overall accuracy."_
- [Understanding and Leveraging the Learning Phases of Neural Networks](https://arxiv.org/pdf/2312.06887.pdf), Dec. 14 2023.

### Interpretability and trustworthy ml

- [Error discovery by clustering influence embeddings](https://arxiv.org/pdf/2312.04712.pdf), Dec. 7 2023.
- [Deeper Understanding of Black-box Predictions via Generalized Influence Functions](https://arxiv.org/pdf/2312.05586.pdf), Dec. 9 2023.
- [Locally-minimal probabilistic explanations](https://arxiv.org/pdf/2312.11831.pdf), Dec. 19 2023.
  - One drawback of formal abductive explanations is explanation size
- [Understanding Text Classification Data and Models Using Aggregated Input Salience](https://r2hcai.github.io/AAAI-23/files/CameraReadys/23.pdf), `aaai2024`.
- [Anytime Approximate Formal Feature Attribution](https://arxiv.org/pdf/2312.06973.pdf), Dec. 12 2023.
- [Accelerating the Global Aggregation of Local Explanations](https://arxiv.org/pdf/2312.07991.pdf), Dec. 13 2023.
- [Interpreting black box models via hypothesis testing](https://arxiv.org/pdf/1904.00045.pdf), Aug. 17 2020.
- [Variable importance in high-dimensional settings requires grouping](https://arxiv.org/pdf/2312.10858.pdf), Dec. 18 2023.
- [Rethinking robustness of model attributions](https://arxiv.org/pdf/2312.10534.pdf), Dec. 16 2023.
- [ShuttleSHAP: A turn-based feature attribution approach for analyzing forecasting models in badminton](https://arxiv.org/pdf/2312.10942.pdf), Dec. 18 2023.
- [Artificial Neural Nets and the Representation of Human Concepts](https://arxiv.org/pdf/2312.05337.pdf), Dec. 8 2023.
- [A Brief Tutorial on Sample Size Calculations for Fairness Audits](https://arxiv.org/pdf/2312.04745.pdf), Dec. 7 2023. `fairness auditing`.
- [Identifying Spurious Correlations using Counterfactual Alignment](https://arxiv.org/pdf/2312.02186.pdf), Dec. 1 2023.

**Diffusion model interpretability**

- [The Journey, Not the Destination: How Data Guides Diffusion Models](https://arxiv.org/pdf/2312.06205.pdf), Dec. 11 2023.
  - _"provides a formal notion of data attribution in the context of diffusion models"_
- [FreeFlow: A comprehensive understanding on diffusion probabilistic models via optimal transport](https://arxiv.org/pdf/2312.05486.pdf), Dec. 9 2023.
  - _"While earlier DPMs relied upon the Markovian assumption, recent methods based on **differential equations** have been rapidly applied to enhance the efficency and capabilities of these models [...] a theoretical interpretation encapsulating these diverse alg orithms is insufficient yet pressingly required to guide further development of DPMs"_
  - _"a framework that provides a thorough explanation of the diffusion formula as time-dependent optimal transport "_

### Dataset distillation

- [On the diversity and realism of distilled dataset: an efficient dataset distillation paradigm](https://arxiv.org/pdf/2312.03526.pdf), Dec. 6 2023.

### Generative models

- [Schrodinger Bridges Beat Diffusion Models on Text-to-Speech Synthesis](https://arxiv.org/pdf/2312.03491.pdf), Dec. 65 2023.
  - _"because the pre-defined data-to-noise diffusion process, their pior distribution is restricted to a noisy representation, which provides little information of the generation target"_

### Distribution shift

- [Complementary Benefits of Contrastive Learning and Self-Training Under Distribution Shift](https://arxiv.org/pdf/2312.03318.pdf), Dec. 6 2023.
  - _"in domain adaptation settings, self-training and contrastive learning offer significant complementary gains, and in semi-supervised learning setting, suprisingly, the benefits are not synergistic"_
  - _"theoretically analyze these techniques in a simplified model of distribution shift, demonstrating scenarios under which the features produced by contrastive learning can yield a good initialization for self-training to further amplify gains and achieve optimal performance, even when either method alone would fail"_
- [Adversarial learning for feature shift detection and correcetion](https://arxiv.org/pdf/2312.04546.pdf), Dec. 7 2023.
  - _"the task of localizing and correcting the features originating such shifts has not been studied in depth."_ 
  - _"We show that mainstream supervised classifiers, such as random forest or gradient boosting trees, combined with simple iterative heuristics, can localize and correct feature shifts, outperforming current statistical and neural network-based techniques."_
- [How Well Does GPT-4V(ision) Adapt to Distribution Shifts? A Preliminary Investigation](https://arxiv.org/pdf/2312.07424.pdf), Dec. 13 2023.
- [Beyond Top-Class Agreement: Using Divergences to Forecast Performance under Distribution Shift](https://arxiv.org/pdf/2312.08033.pdf), Dec. 13 2023.
- [Benchmarking Distribution Shift in Tabular Data with TableShift](https://arxiv.org/pdf/2312.07577.pdf), Dec. 14 2023.
- [Subgroup Robustness Grows On Trees: An Empirical Baseline Investigation](https://arxiv.org/pdf/2211.12703.pdf), Apr. 17 2023.
- [Ask your distribution shift if pre-training is right for you](https://openreview.net/attachment?id=XQ1cGxdB3o&name=pdf), `neurips2023` `workshop`.
- [Reliable Test-Time Adaptation via Agreement-on-the-Line](https://openreview.net/attachment?id=fh0nxeyXDr&name=pdf), `neurips2023` `workshop`.

### Causal inference

- [Invariance & causal representation learning: Prospects and limitations](https://arxiv.org/pdf/2312.03580.pdf), Dec. 6 2023.
  - _"show that invariance alone is insufficient to identify latent causal variables"_

### LLMs and miracles beyond

- [Revisiting Topic-Guided Language Models](https://arxiv.org/pdf/2312.02331.pdf), Dec. 4 2023.
  - _"Suprisingly, we find that none of these methods outperform a standard LSTM language model baseline, and most fail to learn good topics"_
- [LLM360: Towards fully transparent open-source LLMs](https://arxiv.org/pdf/2312.06550.pdf), Dec. 11 2023.
  - _"We present LLM360, an initiative to fully open-source LLMs, which advocates for all training code and data, model checkpoints, and intermediate results to be made available to the community"_
  - _"We pretrain two new LLMs from scratch and release them under the LLM360 framework. AMBER is a 7B English LLM pretrained on 1.3T tokens. CRYSTALCODER is a 7B English and code LLM pretrained on 1.4T tokens [...] We release all all training code, pretraining data, model checkpoints and evaluation metrics collected during pretraining for both AMBER and CRYSTALCODER. AMBER is released with 360 model checkpoints saved during training, and CRYSTALCODER with 143."_
- [Large Language Models for Mathematicians](https://arxiv.org/pdf/2312.02517.pdf), Dec. 7 2023.
  - _"In this note, we discuss to what extent they can aid professional mathematicians"_
- [TinyGSM: achieving > 80% on GSM8k with small language models](https://arxiv.org/pdf/2312.09241.pdf), Dec. 14 2023.
- [Levels of AGI: Operationalizing Progress on the Path to AGI](https://arxiv.org/pdf/2311.02462.pdf), Nov. 4 2023.
- [Explaining data patterns in natural language with language models](https://aclanthology.org/2023.blackboxnlp-1.3.pdf), `emnlp2023`.

#### Understanding Transformers

- [Faith and Fate: Limits of Transformers on Compositionality](https://arxiv.org/pdf/2305.18654.pdf), Oct. 31 2023.
- [The emergence of clusters in self-attention dynamics](https://arxiv.org/pdf/2305.05465.pdf), Oct. 17 2023.
- [A mathematical perspective on Transformers](https://arxiv.org/pdf/2312.10794.pdf), Dec. 17 2023.
- [Understanding the regularity of self-attention with optimal transport](https://arxiv.org/pdf/2312.14820.pdf), Dec. 22 2023. `robustness`.
  - _"In particular, we show that for some inputs, attacks that duplicate tokens before perturbing them are more efficient than attacks that simply move tokens"_

#### Watermarking

- [Towards Optimal Statistical Watermarking](https://arxiv.org/pdf/2312.07930.pdf), Dec. 13 2023.

#### Alignment

- [A Study on the Calibration of In-context Learning](https://arxiv.org/pdf/2312.04021.pdf), Dec. 7 2023.
  - accuracy-calibration trade-off of ICL
  - _"show that such trade-offs may get worse as we increase model size, incorporate more ICL examples, and fine-tune models using instruction, dialog, or reinforcement learning from human feedback (RLHF) on carefully curated datasets"_
- [Self-evaluation improves selective generation in large language models](https://arxiv.org/pdf/2312.09300.pdf), Dec. 14 2023.
- [Helping or herding? Reward model ensembles mitigate but do not eliminate reward hacking](https://arxiv.org/pdf/2312.09244.pdf), Dec. 14 2023.
- [Alignment for Honesty](https://arxiv.org/pdf/2312.07000.pdf), Dec. 12 2023.
- [Steering Llama 2 via Contrastive Activation Addition](https://arxiv.org/pdf/2312.06681.pdf), Dec. 9 2023.
- [Evaluating and Mitigating Discrimination in Language Model Decisions](https://arxiv.org/pdf/2312.03689.pdf), Dec. 6 2023.
- [Aligner: One global token is worth millions of parameters when aligning large language models](https://arxiv.org/pdf/2312.05503.pdf), Dec. 9 2023.
- [Navigating the Grey Area: How Expressions of Uncertainty and Overconfidence Affect Language Models](https://arxiv.org/abs/2302.13439), Nov. 13 2023.
- [Reaons to reject? Aligning language models with judgements](https://arxiv.org/pdf/2312.14591.pdf), Dec. 22 2023. [github](https://github.com/wwxu21/CUT).
- [A survey of reinforcement learning from human feedback](https://arxiv.org/pdf/2312.14925.pdf), Dec. 22 2023.

#### The art of prompting

- [Prompt optimization via adversarial in-context learning](https://arxiv.org/pdf/2312.02614.pdf), Dec. 5 2023.

#### In-context learning

- [The mechanistic basis of data dependence and abrupt learning in an in-context classification task](https://arxiv.org/pdf/2312.03002.pdf), Dec. 3 2023.
  - _"Recent work has shown that specific distributional properties inherent in language, such as burstiness, large dictionaries and skewed rank-frequency distributions, control the trade-off or simultaneous appearance of these two forms of learning"_
  - _"ICL is driven by the abrupt emergence of an induction head, which subsequently competes with in-weights learning"_
- [Transformers Implement Functional Gradient Descent to Learn Non-Linear Functions In Context](https://arxiv.org/pdf/2312.06528.pdf), Dec. 14 2023.
  - _"We provide theoretical and empirical evidence that non-linear Transformers can and in fact do, learn to implement learning algorithms to learn non-linear functions in context"_
- [Can a Transformer Represent a Kalman Filter?](https://arxiv.org/pdf/2312.06937.pdf), Dec. 14 2023.
- [The ICL Consistency Test](https://arxiv.org/pdf/2312.04945.pdf), Dec. 8 2023.

#### Emergence

- [Compositional Abilities Emerge Multiplicatively: Exploring Diffusion Models on a Synthetic Task](https://arxiv.org/pdf/2310.09336.pdf), Nov. 14 2023.
 
#### Mechanistic interpretability

- [Towards Measuring Representational Similarity of Large Language Models](https://arxiv.org/pdf/2312.02730.pdf), Dec. 5 2023.
- [On the Role of Attention in Prompt-tuning](https://arxiv.org/pdf/2306.03435.pdf), Ju.n 6 2023.
  - Use simplified setting (simple model and formal language) for nearly total control of guaranteed analysis: _"we explore prompt-tuning for **one-layer attention architectures** and study contextual mixture-models where each input token belongs to a context-relevant or irrelevant set"_
- [Generating interpretable networks using hypernetworks](https://arxiv.org/pdf/2312.03051.pdf), Dec. 5 2023.
  - _"An essential goal in MI is to decode a network, i.e., to convert a neural network's raw weights to an interpretable algorithm"_
  - _"We explore the possibility of using hypernetworks to generate interpretable networks whose underlying algorithms are not yet known"_
- [Incidental Polysemanticity](https://arxiv.org/pdf/2312.03096.pdf), Dec. 5 2023.
  - _"polysemanticity occurs because random initialization can, by chance alone, initially assign multiple features to the same neuron, and the training dynamics then strengthen such overlap."_
- [Interpretability illusions in the generalization of simplified models](https://arxiv.org/pdf/2312.03656.pdf), Dec. 6 2023.
  - _"even if the simplified representations can accurately approximate the full model on the training set, they may fail to accurately capture the model's behavior out of distribution - the understanding developed from simplified representations may be an illusion"_
  - _"Together, our results raise questions about the extent to which mechanistic interpretations derived using tools like SVD can reliably predict what a model will do in novel situations"_
- [Transformers are uninterpretable with myopic methods: a case study with bounded Dyck grammars](https://arxiv.org/pdf/2312.01429.pdf), Dec. 3 2023.
- [Zoology: Measuring and improving recall in efficient language models](https://arxiv.org/pdf/2312.04927.pdf), Dec. 8 2023.
  - _"we find 82% of the gap is explained by each model's ability to recall information that is previously mentioned in-context, e.g. Hakuna Matata means no worries Hakuna Matata it means no ??"_
  - associative recall
  - _"we evaluate simple convolution-attention hybrids and show that hybrids with input-dependent sparse attention patterns can clos 97.4% of the gap to attention, while maintaining sub-quadratic scaling"_
- [Grokking group multiplication with cosets](https://arxiv.org/pdf/2312.06581.pdf), Dec. 11 2023.
- [Challenges with unsupervised LLM knowledge discovery](https://arxiv.org/pdf/2312.10029.pdf), Dec. 15 2023.
- [Successor heads: Recurring, interpretable attention heads in the wild](https://arxiv.org/pdf/2312.09230.pdf), Dec. 14 2023.
- [A simulatability benchmark for language model explainability](https://arxiv.org/pdf/2312.12747.pdf), Dec. 20 2023.
- [Exploring the Residual Stream of Transformers](https://arxiv.org/pdf/2312.12141.pdf), Dec. 19 2023.
- [Injecting structural hints: Using language models to study inductive biases in language learning](https://aclanthology.org/2023.findings-emnlp.563.pdf), `emnlp2023`.
- [Identification of Knowledge Neurons in Protein Language Model](https://arxiv.org/pdf/2312.10770.pdf), Dec. 17 2023.
- [Deep de Finetti: Recovering topic distributions from large language models](https://arxiv.org/pdf/2312.14226.pdf), Dec. 21 2023.
- [Embers of Autoregression: Understanding Large Language Models Through the Problem They are Trained to Solve](https://arxiv.org/pdf/2309.13638.pdf), Sep. 24 2023.

#### Benchmark

- [Paloma: A benchmark for evaluating language model fit](https://arxiv.org/pdf/2312.10523.pdf), Dec. 16 2023.
- [BARDA: A Belief and Reasoning Dataset that Separates Factual Accuracy and Reasoning Ability](https://arxiv.org/pdf/2312.07527.pdf), Dec. 12 2023.
- [NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language Models via Complexity Classe](https://arxiv.org/pdf/2312.14890.pdf), Dec. 22 2023. [github](https://github.com/casmlab/NPHardEval).
  - _"This benchmark is designed to evaluate the reasoning abilities of LLMs across a broad spectrum of 900 algorithmic questions, extending up to the NP-Hard complexity class"_
  - _"this benchmark is designed with a dynamic update mechanism, where the datapoints are refreshed on a montyly basis"_

#### For data science

- [Curated LLM: Synergy of LLMs and data curation for tabular augmentation in ultra low-data regimes](https://arxiv.org/pdf/2312.12112.pdf), Dec. 19 2023.
- [DBCopilot: Scaling Natural Language Querying to Massive Databases](https://arxiv.org/pdf/2312.03463.pdf), Dec. 6 2023.
- [Non-Programmers Can Label Programs Indirectly via Active Examples: A Case Study with Text-to-SQL](https://aclanthology.org/2023.emnlp-main.312.pdf), `emnlp2023`.

#### For health

- [Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine](https://www.microsoft.com/en-us/research/publication/can-generalist-foundation-models-outcompete-special-purpose-tuning-case-study-in-medicine/), Nov. 2023.

---

### Codebase

- [ml-explore](https://github.com/ml-explore), Apple's deep learning framework in `c++`.
- [trlX: A Framework for Large Scale Reinforcement Learning from Human Feedback](https://aclanthology.org/2023.emnlp-main.530.pdf), `emnlp2023`. [github](https://github.com/CarperAI/trlx).
- [LeanCopilot](https://github.com/lean-dojo/LeanCopilot).
- [MiniChain: A Small Library for Coding with Large Language Models](https://aclanthology.org/2023.emnlp-demo.27.pdf), `emnlp2023`. [github](https://github.com/srush/MiniChain).
- [MosaicBERT: A Bidirectional Encoder Optimized for Fast Pretraining](https://openreview.net/pdf?id=5zipcfLC2Z), `neurips2023`. [github](https://github.com/mosaicml/examples/tree/main/examples/benchmarks/bert).
- [modyn](https://github.com/eth-easl/modyn), Modyn is a research-platform for training ML models on dynamic datasets. [paper](https://arxiv.org/pdf/2312.06254.pdf).
- [ivy](https://github.com/unifyai/ivy), The Unified AI Framework.
  - Convert code into any framework: Use and build on top of any model, library, or device by converting any code from one framework to another using ivy.transpile.
- [Mixtral_Chatbot_with_Gradio](https://github.com/rohan-paul/LLM-FineTuning-Large-Language-Models/tree/main/Mixtral_Chatbot_with_Gradio).


