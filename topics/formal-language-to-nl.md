
In ACL 2019, Xintong and I attended a workshop named [Deep Learning and Formal Language](https://sites.google.com/view/delfol-workshop-acl19).
At that time, this workshop has not attracted many people to come.
However I think the study of formal language that approxmates natural language can control unwanted factors and focus on essential abstraction or main characteristics of natural language.
And the insights gained from studying neural networks learning over formal language can transfer to the study of natural language.
This repo function as a place to hold formal language related papers in computational linguistics and machine learning, focusing both on the processing (dynamic programming, parsing) aspect and learning aspect of formal language.

## Algorithms

- [Algorithms for Weighted Pushdown Automata](https://arxiv.org/pdf/2210.06884.pdf), Oct. 2022. [github repo](https://github.com/rycolab/wpda).


## Learning

- [Transparency Helps Reveal When Language Models Learn Meaning](https://arxiv.org/pdf/2210.07468.pdf), Oct. 14 2022.
- [Transformers Implement First-Order Logic with Memory Quantifiers](https://arxiv.org/pdf/2210.02671.pdf), Oct. 6 2022.


## Reasoning

- [Can language models handle recursively nested grammatical structures? A case study on comparing models and humans](https://arxiv.org/abs/2210.15303), Oct. 22 2022.
