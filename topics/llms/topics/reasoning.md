
> How to enhance the reasoning ability so as to largely improve intelligence of LLMs.

### Reasoning

- [STaR- Self-Taught Reasoner: Boostrapping reasoning with reasoning](https://arxiv.org/pdf/2203.14465), May 20 2022.
- [Reflexion: Language agents with verbal reinforcement learning](https://proceedings.neurips.cc/paper_files/paper/2023/file/1b44b878bb782e6954cd888628510e90-Paper-Conference.pdf), NeurIPS 20224.
- [Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks](https://arxiv.org/pdf/2211.12588), Oct. 23 2023. [code](https://github.com/TIGER-AI-Lab/Program-of-Thoughts).
- [System-1.x: Learning to Balance Fast and Slow Planning with Language Models](https://arxiv.org/pdf/2407.14414), Jul. 19 2024.
- [Does reasoning emerge? Examing the probabilities of causation in large language models](https://arxiv.org/pdf/2408.08210), Aug. 15 2024.
  - _"to what extent do LLMs perform actual reasoning"_
  - two key probabilistic concepts that are essential for connecting causes to their effects: the probability of necessity (PN) and the probability of sufficiency (PS)
  - Use PN and PS to assess LLMs.
- [Can Large Language Models Understand Symbolic Graphics Programs?](https://arxiv.org/pdf/2408.08313), Aug. 15 2024.
- [To cot or not to cot? Chain-of-thought helps mainly on math and symbolic reasoning](https://arxiv.org/pdf/2409.12183), Sep. 18 2024.
- [Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling](https://arxiv.org/pdf/2408.16737), Aug. 29 2024.
- [How Numerical Precision Affects Mathematical Reasoning Capabilities of LLMs](https://arxiv.org/pdf/2410.13857), Oct. 17 2024.
- [MathGAP: Out-of-distribution evaluation on problems with arbitrarily complex proofs](https://arxiv.org/pdf/2410.13502), Oct. 17 2024.
- [awesome-o1](https://github.com/srush/awesome-o1/).
- [LLMs Still Can't Plan; Can LRMs? A Preliminary Evaluation of OpenAI's o1 on PlanBench](https://arxiv.org/abs/2409.13373), Sep 20 2024.
- [Sampling Language from Latent System 2 Reasoning](https://openreview.net/pdf?id=OdUqJwu0Gr), NeurIPS 2024.
- [Thinking LLMs: General instruction following with thought generation](https://arxiv.org/pdf/2410.10630), Oct. 14 2024.
- [Building math agents with multi-turn iterative preference learning](https://arxiv.org/pdf/2409.02392), Sep. 4 2024.
- [Can large language models act as symbolic reasoners?](https://arxiv.org/pdf/2410.21490), Oct. 30 2024.
- [Mixture of parrots: Experts improve memorization more than reasoning](https://arxiv.org/pdf/2410.19034), Oct. 24 2024.
- [The surprising effectiveness of test-time training for abstract reasoning](https://arxiv.org/pdf/2411.07279), Nov. 11 2024.
- [Large Language Models Orchestrating Structured Reasoning Achieve Kaggle Grandmaster Level](https://arxiv.org/pdf/2411.03562), Nov. 5 2024.
- [Procedural knowledge in pretraining drives reasoning in large language models](https://arxiv.org/pdf/2411.12580), Nov. 19 2024.
- [Understanding chain-of-thought in LLMs through information theory](https://arxiv.org/pdf/2411.11984), Nov. 18 2024.
- [Out-of-Distribution Generalization as Reasoning: Are LLMs Competitive?](https://www.youtube.com/watch?v=rvLUo0xiSxg), Simons Institute talk by Les Viliant.
  - [Robust logics](https://dl.acm.org/doi/pdf/10.1145/301250.301425), STOC 1999.
  - [Knowledge infusion](https://cdn.aaai.org/AAAI/2006/AAAI06-247.pdf), AAAI 2006.
- [Embedding trajectory for out-of-distribution detection in mathematical reasoning](https://arxiv.org/pdf/2405.14039), Oct. 30 2024. [code](https://github.com/Alsace08/OOD-Math-Reasoning).
- [LLMs Do Not Think Step-by-step In Implicit Reasoning](https://arxiv.org/pdf/2411.15862), Nov. 24 2024.
  - _"We probe the info. of intermediate steps from the model's hidden states when it is performing implicit CoT. indicate that LLMs hardly think about intermediate steps, suggesting they may just rely on experience rather than strict step-by-step reasoning"_
- [Let's think var-by-var: Large language models enable ad hoc probabilistic reasoning](https://arxiv.org/pdf/2412.02081), Dec. 3 2024.
- [Artificial expert intelligence through pac-reasoning](https://arxiv.org/pdf/2412.02441), Dec. 3 2024.
- [Language Models are Hidden Reasoners: Unlocking Latent Reasoning Capabilities via Self-Rewarding](https://arxiv.org/abs/2411.04282), Nov. 6 2024.
- [Formal Mathematical Reasoning: A New Frontier in AI](https://arxiv.org/pdf/2412.16075), Dec. 20 2024.
- [Learning Beyond Pattern Matching? Assaying Mathematical Understanding in LLMs](https://arxiv.org/pdf/2405.15485), ICML 2024.
- [Tree of Problems: Improving structured problem solving with compositionality](https://arxiv.org/pdf/2410.06634), Oct. 9 2024.
- [CoT-based Synthesizer: Enhancing LLM Performance through Answer Synthesis](https://arxiv.org/pdf/2501.01668), Jan. 3 2025. [code](https://github.com/RUCKBReasoning/CoT-based-Synthesizer).
  - _"leverages CoT reasoning to synthesize superior answers by analyzing complementary info from multi candidate responses"_
- [Free process rewards without process labels](https://arxiv.org/pdf/2412.01981), Dec. 2 2024. [code](https://github.com/PRIME-RL/ImplicitPRM).
- [PRIME](https://curvy-check-498.notion.site/Process-Reinforcement-through-Implicit-Rewards-15f4fcb9c42180f1b498cc9b2eaf896f), [code](https://github.com/PRIME-RL/PRIME).
- [Reinforcing Thinking through Reasoning-Enhanced Reward Models](https://arxiv.org/pdf/2501.01457), Dec. 31 2024. `self-critique`. [code](https://github.com/dyang39/DRR).
- [GPT as Monte Carlo language tree: A probabilistic perspective](https://arxiv.org/pdf/2501.07641), Jan. 13 2025.
- [DeepSeek-R1: Incentivizing reasoning capability in LLMs via reinforcement learning](https://arxiv.org/pdf/2501.12948), Jan. 22 2025.
- [Step-KTO: Optimizing mathematical reasoning through stepwise binary feedback](https://arxiv.org/pdf/2501.10799), Jan. 18 2025.
- [LLMs can plan only if we tell them](https://arxiv.org/pdf/2501.13545), Jan. 23 2025.
- [RAG-Reward: Optimizing RAG with reward modeling and RLHF](https://arxiv.org/pdf/2501.13264), Jan. 22 2025.
- [LLM Reasoning: Key ideas and limitations](https://dennyzhou.github.io/LLM-Reasoning-Berkeley.pdf), talk by Denny Zhou from Google DeepMind.
- [s1: Simple test-time scaling](https://arxiv.org/pdf/2501.19393), Jan. 31 2025. [code](https://github.com/simplescaling/s1).
- [Demystifying long chain-of-thought reasoning in LLMs](https://arxiv.org/pdf/2502.03373), Feb. 5 2025. [code](https://github.com/eddycmu/demystify-long-cot).
- [Gold-medalist Performance in Solving Olympiad Geometry with AlphaGeometry2](https://arxiv.org/pdf/2502.03544), Feb. 5 2025.
- [ZebraLogic: On the scaling limits of LLMs for logic reasoning](https://arxiv.org/pdf/2502.01100), Feb. 3 2025.
- [Domaino1s: Guiding LLM reasoning for explainable answers in high-stakes domains](https://arxiv.org/pdf/2501.14431), Jan. 24 2025.
- [UGMathBench: A diverse and dynamic benchmark for undergraduate-level mathematical reasoning with large language models](https://arxiv.org/pdf/2501.13766), Jan. 23 2025.
- [STP: Self-play LLM theorem provers with iterative conjecturing and proving](https://arxiv.org/pdf/2502.00212), Feb. 4 2025.
- [MATH-Perturb: Benchmarking LLM's math reasoning abilities against hard perturbations](https://arxiv.org/abs/2502.06453), Feb. 10 2025.
- [Scaling up test-time compute with latent reasoning: A recurrent depth approach](https://www.arxiv.org/pdf/2502.05171), Feb. 7 2025. [code](https://github.com/seal-rg/recurrent-pretraining).
- [An analysis for reasoning bias of language models with small initialization](https://arxiv.org/pdf/2502.04375), Feb 5 2025.
- [Towards large reasoning models: A survey on scaling LLM reasoning capabilities](https://arxiv.org/pdf/2501.09686), Jan. 17 2025.
- [On the reasoning capacity of AI models and how to quantify it](https://arxiv.org/pdf/2501.13833), Jan. 23 2025.
- [Competitive programming with large reasoning models](https://arxiv.org/pdf/2502.06807), Feb. 3 2025.
- [Goedel-Prover: A frontier model for open-source automated theorem proving](https://arxiv.org/pdf/2502.07640), Feb. 11 2025.
- [When more is less: Understanding chain-of-thought length in LLMs](https://arxiv.org/pdf/2502.07266), Feb. 11 2025.
- [Exploring the limit of outcome reward for learning mathematical reasoning](https://arxiv.org/pdf/2502.06781), Feb. 10 2025.
- [ReasonFlux: Hierarchical LLM reasoning via scaling thought templates](https://arxiv.org/pdf/2502.06772), Feb. 10 2025.
- [Can 1B LLM surpass 405B LLM? Rethinking compute-optimal test-time scaling](https://arxiv.org/pdf/2502.06703), Feb. 10 2025.
- [Large language models meet symbolic provers for logical reasoning evaluation](https://arxiv.org/pdf/2502.06563), Feb. 10 2025. [code](https://github.com/opendatalab/ProverGen).
- [Examining false positives under inference scaling for mathematical reasoning](https://arxiv.org/pdf/2502.06217), Feb. 10 2025.
- [GSM-Infini: How do your LLMs behave over infinitely increasing context length and reasoning complexity](https://arxiv.org/pdf/2502.05252), Feb. 7 2025. [code](https://github.com/Infini-AI-Lab/gsm_infinite/).
- [On the emergence of thinking in LLMs I: Searching for the right intuition](https://arxiv.org/pdf/2502.06773), Feb. 10 2025.
- [Scalable oversight for superhuman AI via recursive self-critiquing](https://arxiv.org/pdf/2502.04675), Feb. 7 2025.
- [LLMs can easily learn to reason from demonstrations structure, not content, is what matters](https://arxiv.org/pdf/2502.07374), Feb. 11 2025. [code](https://arxiv.org/pdf/2502.07374).
- [CODEI/O: Condensing reasoning patterns via code input-output Prediction](https://arxiv.org/pdf/2502.07316), Feb. 12 2025. [code](https://github.com/hkust-nlp/CodeIO).
- [Diverse inference and verification for advanced reasoning](https://arxiv.org/pdf/2502.09955), Feb. 14 2025.
- [Direct value optimization: Improving chain-of-thought reasoning in LLMs with refined values](https://arxiv.org/pdf/2502.13723), Feb. 19 2025.
  - _"DVO utilizes value signals at individual reasoning steps, optimizing models via a mean square error loss"_
  - _"target values within the DVO are estimated using either MCTS or an outcome value model"_
- [Logic-RL: Unleashing LLM reasoning with rule-based reinforcement learning](https://arxiv.org/pdf/2502.14768), Feb. 20 2025.
- [Measuring faithfulness of chains of thought by unlearning reasoning steps](https://arxiv.org/pdf/2502.14829), Feb. 20 2025. [code](https://github.com/technion-cs-nlp/parametric-faithfulness).
- [Open-Reasoner-Zero](https://yasminezhang.notion.site/Open-Reasoner-Zero-19e12cf72d418007b9cdebf44b0e7903), Feb. 10 2025. [code](https://github.com/Open-Reasoner-Zero/Open-Reasoner-Zero).
- [Cognitive Behaviors that Enable Self-Improving Reasoners, or, Four Habits of Highly Effective STaRs](https://arxiv.org/pdf/2503.01307), Mar. 3 2025. [code](https://github.com/kanishkg/cognitive-behaviors).
  - [Do reasoning models use their scratchpad like we do? Evidence from distilling paraphrases](https://alignment.anthropic.com/2025/distill-paraphrases/), blogpost by Anthropic.
- [Compositional Reasoning with Transformers, RNNs, and Chain of Thought](https://arxiv.org/pdf/2503.01544), Mar. 3 2025.
- [The language of thought is not languages: Evidence from formal logical reasoning](https://alexanderdfung.github.io/assets/pdf/kean2024lotlang_extendedabstract.pdf), Mar. 2025.
- [All Roads Lead to Likelihood: The Value of Reinforcement Learning in Fine-Tuning](https://arxiv.org/abs/2503.01067), Mar. 3 2025. [youtube](https://www.youtube.com/watch?v=E4b3cSirpsg).
- [MALT: Improving Reasoning with Multi-Agent LLM Training](https://arxiv.org/pdf/2412.01928), Feb. 27 2025.
- [The Interface Between Reinforcement Learning Theory and Language Model Post-Training](https://www.let-all.com/blog/2025/03/05/the-interface-between-reinforcement-learning-theory-and-language-model-post-training/), Mar. 5 2025.


