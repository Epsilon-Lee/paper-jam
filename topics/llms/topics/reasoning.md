
> How to enhance the reasoning ability so as to largely improve intelligence of LLMs.

### Reasoning

- [How truncating weights improves reasoning in language models](https://arxiv.org/pdf/2406.03068), Jun. 5 2024. `reasoning`.
- [From explicit cot to implicit cot: Learning to internalize cot step by step](https://arxiv.org/pdf/2405.14838), May 23 2024. `reasoning`.
- [Towards understanding how transformer perform multi-step reasoning with matching operation](https://arxiv.org/pdf/2405.15302), May 24 2024. `reasoning`.
- [Learning beyond pattern matching? Assaying mathematical understanding in LLMs](https://arxiv.org/pdf/2405.15485), May 24 2024. `reasoning`.
- [STaR- Self-Taught Reasoner: Boostrapping reasoning with reasoning](https://arxiv.org/pdf/2203.14465), May 20 2022.
- [Reflexion: Language agents with verbal reinforcement learning](https://proceedings.neurips.cc/paper_files/paper/2023/file/1b44b878bb782e6954cd888628510e90-Paper-Conference.pdf), NeurIPS 20224.
- [Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks](https://arxiv.org/pdf/2211.12588), Oct. 23 2023. [code](https://github.com/TIGER-AI-Lab/Program-of-Thoughts).
- [How Far Can Transformers Reason? The Locality Barrier and Inductive Scratchpad](https://arxiv.org/pdf/2406.06467), Jun. 10 2024. `reasoning`.
- [System-1.x: Learning to Balance Fast and Slow Planning with Language Models](https://arxiv.org/pdf/2407.14414), Jul. 19 2024.
- [Does reasoning emerge? Examing the probabilities of causation in large language models](https://arxiv.org/pdf/2408.08210), Aug. 15 2024.
  - _"to what extent do LLMs perform actual reasoning"_
  - two key probabilistic concepts that are essential for connecting causes to their effects: the probability of necessity (PN) and the probability of sufficiency (PS)
  - Use PN and PS to assess LLMs.
- [Can Large Language Models Understand Symbolic Graphics Programs?](https://arxiv.org/pdf/2408.08313), Aug. 15 2024.
- [To cot or not to cot? Chain-of-thought helps mainly on math and symbolic reasoning](https://arxiv.org/pdf/2409.12183), Sep. 18 2024.
- [Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling](https://arxiv.org/pdf/2408.16737), Aug. 29 2024.
- [How Numerical Precision Affects Mathematical Reasoning Capabilities of LLMs](https://arxiv.org/pdf/2410.13857), Oct. 17 2024.
- [MathGAP: Out-of-distribution evaluation on problems with arbitrarily complex proofs](https://arxiv.org/pdf/2410.13502), Oct. 17 2024.
- [awesome-o1](https://github.com/srush/awesome-o1/).
- [LLMs Still Can't Plan; Can LRMs? A Preliminary Evaluation of OpenAI's o1 on PlanBench](https://arxiv.org/abs/2409.13373), Sep 20 2024.
- [Sampling Language from Latent System 2 Reasoning](https://openreview.net/pdf?id=OdUqJwu0Gr), NeurIPS 2024.
- [Thinking LLMs: General instruction following with thought generation](https://arxiv.org/pdf/2410.10630), Oct. 14 2024.
- [Building math agents with multi-turn iterative preference learning](https://arxiv.org/pdf/2409.02392), Sep. 4 2024.
- [Can large language models act as symbolic reasoners?](https://arxiv.org/pdf/2410.21490), Oct. 30 2024.
- [Mixture of parrots: Experts improve memorization more than reasoning](https://arxiv.org/pdf/2410.19034), Oct. 24 2024.
- [The surprising effectiveness of test-time training for abstract reasoning](https://arxiv.org/pdf/2411.07279), Nov. 11 2024.
- [Large Language Models Orchestrating Structured Reasoning Achieve Kaggle Grandmaster Level](https://arxiv.org/pdf/2411.03562), Nov. 5 2024.
- [Procedural knowledge in pretraining drives reasoning in large language models](https://arxiv.org/pdf/2411.12580), Nov. 19 2024.
- [Understanding chain-of-thought in LLMs through information theory](https://arxiv.org/pdf/2411.11984), Nov. 18 2024.
- [Out-of-Distribution Generalization as Reasoning: Are LLMs Competitive?](https://www.youtube.com/watch?v=rvLUo0xiSxg), Simons Institute talk by Les Viliant.
  - [Robust logics](https://dl.acm.org/doi/pdf/10.1145/301250.301425), STOC 1999.
  - [Knowledge infusion](https://cdn.aaai.org/AAAI/2006/AAAI06-247.pdf), AAAI 2006.
- [Embedding trajectory for out-of-distribution detection in mathematical reasoning](https://arxiv.org/pdf/2405.14039), Oct. 30 2024. [code](https://github.com/Alsace08/OOD-Math-Reasoning).
- [LLMs Do Not Think Step-by-step In Implicit Reasoning](https://arxiv.org/pdf/2411.15862), Nov. 24 2024.
  - _"We probe the info. of intermediate steps from the model's hidden states when it is performing implicit CoT. indicate that LLMs hardly think about intermediate steps, suggesting they may just rely on experience rather than strict step-by-step reasoning"_
- [Let's think var-by-var: Large language models enable ad hoc probabilistic reasoning](https://arxiv.org/pdf/2412.02081), Dec. 3 2024.
- [Artificial expert intelligence through pac-reasoning](https://arxiv.org/pdf/2412.02441), Dec. 3 2024.
- [Language Models are Hidden Reasoners: Unlocking Latent Reasoning Capabilities via Self-Rewarding](https://arxiv.org/abs/2411.04282), Nov. 6 2024.
- [Formal Mathematical Reasoning: A New Frontier in AI](https://arxiv.org/pdf/2412.16075), Dec. 20 2024.
- [Learning Beyond Pattern Matching? Assaying Mathematical Understanding in LLMs](https://arxiv.org/pdf/2405.15485), ICML 2024.
- [Tree of Problems: Improving structured problem solving with compositionality](https://arxiv.org/pdf/2410.06634), Oct. 9 2024.
- [CoT-based Synthesizer: Enhancing LLM Performance through Answer Synthesis](https://arxiv.org/pdf/2501.01668), Jan. 3 2025. [code](https://github.com/RUCKBReasoning/CoT-based-Synthesizer).
  - _"leverages CoT reasoning to synthesize superior answers by analyzing complementary info from multi candidate responses"_
- [Free process rewards without process labels](https://arxiv.org/pdf/2412.01981), Dec. 2 2024. [code](https://github.com/PRIME-RL/ImplicitPRM).
- [PRIME](https://curvy-check-498.notion.site/Process-Reinforcement-through-Implicit-Rewards-15f4fcb9c42180f1b498cc9b2eaf896f), [code](https://github.com/PRIME-RL/PRIME).
- [Reinforcing Thinking through Reasoning-Enhanced Reward Models](https://arxiv.org/pdf/2501.01457), Dec. 31 2024. `self-critique`. [code](https://github.com/dyang39/DRR).
- [Improve mathematical reasoning in language models by automated process supervision](https://arxiv.org/pdf/2406.06592), Dec. 11 2024.
- [GPT as Monte Carlo language tree: A probabilistic perspective](https://arxiv.org/pdf/2501.07641), Jan. 13 2025.
- [DeepSeek-R1: Incentivizing reasoning capability in LLMs via reinforcement learning](https://arxiv.org/pdf/2501.12948), Jan. 22 2025.
- [Step-KTO: Optimizing mathematical reasoning through stepwise binary feedback](https://arxiv.org/pdf/2501.10799), Jan. 18 2025.
- [LLMs can plan only if we tell them](https://arxiv.org/pdf/2501.13545), Jan. 23 2025.
- [RAG-Reward: Optimizing RAG with reward modeling and RLHF](https://arxiv.org/pdf/2501.13264), Jan. 22 2025.
- [LLM Reasoning: Key ideas and limitations](https://dennyzhou.github.io/LLM-Reasoning-Berkeley.pdf), talk by Denny Zhou from Google DeepMind.
- [s1: Simple test-time scaling](https://arxiv.org/pdf/2501.19393), Jan. 31 2025. [code](https://github.com/simplescaling/s1).
- [Demystifying long chain-of-thought reasoning in LLMs](https://arxiv.org/pdf/2502.03373), Feb. 5 2025. [code](https://github.com/eddycmu/demystify-long-cot).
- [Gold-medalist Performance in Solving Olympiad Geometry with AlphaGeometry2](https://arxiv.org/pdf/2502.03544), Feb. 5 2025.
- [ZebraLogic: On the scaling limits of LLMs for logic reasoning](https://arxiv.org/pdf/2502.01100), Feb. 3 2025.
- [Domaino1s: Guiding LLM reasoning for explainable answers in high-stakes domains](https://arxiv.org/pdf/2501.14431), Jan. 24 2025.
- [UGMathBench: A diverse and dynamic benchmark for undergraduate-level mathematical reasoning with large language models](https://arxiv.org/pdf/2501.13766), Jan. 23 2025.
- [STP: Self-play LLM theorem provers with iterative conjecturing and proving](https://arxiv.org/pdf/2502.00212), Feb. 4 2025. [code](https://github.com/kfdong/STP).
- [MATH-Perturb: Benchmarking LLM's math reasoning abilities against hard perturbations](https://arxiv.org/abs/2502.06453), Feb. 10 2025. [leaderboard](https://math-perturb.github.io/).
- [Scaling up test-time compute with latent reasoning: A recurrent depth approach](https://www.arxiv.org/pdf/2502.05171), Feb. 7 2025. [code](https://github.com/seal-rg/recurrent-pretraining).
- [An analysis for reasoning bias of language models with small initialization](https://arxiv.org/pdf/2502.04375), Feb 5 2025.
- [Towards large reasoning models: A survey on scaling LLM reasoning capabilities](https://arxiv.org/pdf/2501.09686), Jan. 17 2025.
- [On the reasoning capacity of AI models and how to quantify it](https://arxiv.org/pdf/2501.13833), Jan. 23 2025.
- [Competitive programming with large reasoning models](https://arxiv.org/pdf/2502.06807), Feb. 3 2025.
- [Goedel-Prover: A frontier model for open-source automated theorem proving](https://arxiv.org/pdf/2502.07640), Feb. 11 2025.
- [When more is less: Understanding chain-of-thought length in LLMs](https://arxiv.org/pdf/2502.07266), Feb. 11 2025.
- [Exploring the limit of outcome reward for learning mathematical reasoning](https://arxiv.org/pdf/2502.06781), Feb. 10 2025.
- [ReasonFlux: Hierarchical LLM reasoning via scaling thought templates](https://arxiv.org/pdf/2502.06772), Feb. 10 2025.
- [Can 1B LLM surpass 405B LLM? Rethinking compute-optimal test-time scaling](https://arxiv.org/pdf/2502.06703), Feb. 10 2025.
- [Large language models meet symbolic provers for logical reasoning evaluation](https://arxiv.org/pdf/2502.06563), Feb. 10 2025. [code](https://github.com/opendatalab/ProverGen).
- [Examining false positives under inference scaling for mathematical reasoning](https://arxiv.org/pdf/2502.06217), Feb. 10 2025.
- [GSM-Infini: How do your LLMs behave over infinitely increasing context length and reasoning complexity](https://arxiv.org/pdf/2502.05252), Feb. 7 2025. [code](https://github.com/Infini-AI-Lab/gsm_infinite/).
- [On the emergence of thinking in LLMs I: Searching for the right intuition](https://arxiv.org/pdf/2502.06773), Feb. 10 2025.
- [Scalable oversight for superhuman AI via recursive self-critiquing](https://arxiv.org/pdf/2502.04675), Feb. 7 2025.
- [LLMs can easily learn to reason from demonstrations structure, not content, is what matters](https://arxiv.org/pdf/2502.07374), Feb. 11 2025. [code](https://arxiv.org/pdf/2502.07374).
- [CODEI/O: Condensing reasoning patterns via code input-output Prediction](https://arxiv.org/pdf/2502.07316), Feb. 12 2025. [code](https://github.com/hkust-nlp/CodeIO).
- [Diverse inference and verification for advanced reasoning](https://arxiv.org/pdf/2502.09955), Feb. 14 2025.
- [Direct value optimization: Improving chain-of-thought reasoning in LLMs with refined values](https://arxiv.org/pdf/2502.13723), Feb. 19 2025.
  - _"DVO utilizes value signals at individual reasoning steps, optimizing models via a mean square error loss"_
  - _"target values within the DVO are estimated using either MCTS or an outcome value model"_
- [Logic-RL: Unleashing LLM reasoning with rule-based reinforcement learning](https://arxiv.org/pdf/2502.14768), Feb. 20 2025.
- [Measuring faithfulness of chains of thought by unlearning reasoning steps](https://arxiv.org/pdf/2502.14829), Feb. 20 2025. [code](https://github.com/technion-cs-nlp/parametric-faithfulness).
- [Open-Reasoner-Zero](https://yasminezhang.notion.site/Open-Reasoner-Zero-19e12cf72d418007b9cdebf44b0e7903), Feb. 10 2025. [code](https://github.com/Open-Reasoner-Zero/Open-Reasoner-Zero).
- [Cognitive Behaviors that Enable Self-Improving Reasoners, or, Four Habits of Highly Effective STaRs](https://arxiv.org/pdf/2503.01307), Mar. 3 2025. [code](https://github.com/kanishkg/cognitive-behaviors).
  - [Do reasoning models use their scratchpad like we do? Evidence from distilling paraphrases](https://alignment.anthropic.com/2025/distill-paraphrases/), blogpost by Anthropic.
- [Compositional Reasoning with Transformers, RNNs, and Chain of Thought](https://arxiv.org/pdf/2503.01544), Mar. 3 2025.
- [The language of thought is not languages: Evidence from formal logical reasoning](https://alexanderdfung.github.io/assets/pdf/kean2024lotlang_extendedabstract.pdf), Mar. 2025.
- [All Roads Lead to Likelihood: The Value of Reinforcement Learning in Fine-Tuning](https://arxiv.org/abs/2503.01067), Mar. 3 2025. [youtube](https://www.youtube.com/watch?v=E4b3cSirpsg).
- [MALT: Improving Reasoning with Multi-Agent LLM Training](https://arxiv.org/pdf/2412.01928), Feb. 27 2025.
- [The Interface Between Reinforcement Learning Theory and Language Model Post-Training](https://www.let-all.com/blog/2025/03/05/the-interface-between-reinforcement-learning-theory-and-language-model-post-training/), Mar. 5 2025.
- [What do learning dynamics reveal about generalization in LLM reasoning?](https://arxiv.org/pdf/2411.07681), Nov. 18 2024. [code](https://github.com/katiekang1998/reasoning_generalization).
- [A theory of learning with autoregressive chain-of-thought](https://arxiv.org/pdf/2503.07932), Mar. 11 2025.
- [MetaScale: Test-time scaling with evolving meta-thoughts](https://arxiv.org/pdf/2503.13447), Mar. 17 2025.
- [TAO: Using test-time compute to train efficient LLMs without labeled data](https://www.databricks.com/blog/tao-using-test-time-compute-train-efficient-llms-without-labeled-data), Mar. 25 2025.
- [PENCIL: Long thoughts with short memory](https://openreview.net/pdf?id=KRI2Fmffqr), ICLR 2025.
- [MegaMath: Pushing the limits of open math corpora](https://arxiv.org/pdf/2504.02807), Apr. 3 2025. [dataset](https://hf.co/datasets/LLM360/MegaMath).
- [Critical Thinking: Which Kinds of Complexity Govern Optimal Reasoning Length?](https://arxiv.org/pdf/2504.01935), Apr. 2 2025. [code](https://github.com/celine-lee/critical_thinking).
- [THINKPRUNE: Pruning Long Chain-of-Thought of LLMs via Reinforcement Learning](https://arxiv.org/abs/2504.01296), Apr. 2 2025. [code](https://github.com/UCSB-NLP-Chang/ThinkPrune).
- [Reasoning Models Don’t Always Say What They Think](https://assets.anthropic.com/m/71876fabef0f0ed4/original/reasoning_models_paper.pdf), Apr. 2025. `Anthropic`.
- [Generative evaluation of complex reasoning in large language models](https://arxiv.org/pdf/2504.02810), Apr. 3 2025.
- [Do Larger Language Models Imply Better Reasoning? A Pretraining Scaling Law for Reasoning](https://arxiv.org/abs/2504.03635), Apr. 4 2025.
- [Inference-time scaling for generalist reward modeling](https://arxiv.org/pdf/2504.02495), Apr. 5 2025.
- [Adversarial training of reward models](https://arxiv.org/pdf/2504.06141), Apr. 11 2025.
- [On the Markov property of neural algorithmic reasoning: Analyses and methods](https://arxiv.org/abs/2403.04929), Mar. 7 2024.
- [Inference-time scaling for complex tasks: Where we stand and what lies ahead](https://arxiv.org/pdf/2504.00294), Mar. 31 2025.
- [The "think" tool: Enabling Claude to stop and think in complex tool use situations](https://www.anthropic.com/engineering/claude-think-tool), Mar. 20 2925.
- [The first few tokens are all you need: An efficient and effective unsupervised prefix fine-tuning method for reasoning models](https://arxiv.org/pdf/2503.02875), Mar. 4 2025.
- [Cognitive Behaviors that Enable Self-Improving Reasoners](https://arxiv.org/pdf/2503.01307), May 3 2025. [code](https://github.com/kanishkg/cognitive-behaviors).
- [SPaR: Self-play with tree-search refinement to improve instruction-following in large language models](https://arxiv.org/pdf/2412.11605), Mar. 16 2025.
- [Process reward models that think](https://arxiv.org/pdf/2504.16828), Apr. 23 2025. [code](https://github.com/mukhal/thinkprm).
- [PipelineRL](https://huggingface.co/blog/ServiceNow/pipelinerl), Apr. 25 2025. [code](https://github.com/ServiceNow/PipelineRL).
- [Reinforcement learning for reasoning in large language models with one training example](https://arxiv.org/pdf/2504.20571), Apr. 29 2025. [code](https://github.com/ypwang61/One-Shot-RLVR).
- [Self-improvement in language models: The sharpening mechanism](https://arxiv.org/pdf/2412.01951), Dec. 4 2024.
- [AdaptMI: Adaptive skill-based in-context math instructions for small language models](https://arxiv.org/pdf/2505.00147), Apr. 30 2025. [code](https://github.com/princeton-pli/AdaptMI).
- 【Absolute zero: Reinforced self-play reasoning with zero data](https://arxiv.org/pdf/2505.03335), May 7 2025. [code]().
- [Think when you need: Self-adaptive chain-of-thought learning](https://arxiv.org/pdf/2504.03234), Apr. 4 2025.
- [Implicit chain of thought reasoning via knowledge distillation](https://arxiv.org/pdf/2311.01460), Nov. 2 2023. [code](https://github.com/da03/implicit_chain_of_thought/).
- [A study on overfitting in deep reinforcement learning](https://arxiv.org/pdf/1804.06893), Apr. 20 2025.
- [General-Reasoner: Advancing llm reasoning across all domains](https://arxiv.org/pdf/2505.14652v1), May 20 2025. [code](https://github.com/TIGER-AI-Lab/General-Reasoner).
- [Synthetic data rl: Task definition is all you need](https://arxiv.org/abs/2505.17063), May 18 2025. [code](https://github.com/gydpku/Data_Synthesis_RL/).
- [Deep reinforcement learning](https://arxiv.org/pdf/2201.02135), Apr. 23 2023. `book`.
- [Decomposing elements of problem solving: What math does RL teach?](https://arxiv.org/pdf/2505.22756), May 28 2025. [code](https://github.com/cfpark00/RL-Wall).
- [Knowledge or reasoning? A close look at how LLMs think across domains](https://arxiv.org/pdf/2506.02126), Jun. 2 2025. [code](https://github.com/UCSC-VLAA/ReasoningEval).
- [A taxonomy for next-generation reasoning models](https://www.interconnects.ai/p/next-gen-reasoners), Jun. 4 2025. `blogpost`.
  - [Elicitation, the simplest way to understand post-training](https://www.interconnects.ai/p/elicitation-theory-of-post-training), Mar. 11 2025. `blogpost`.
- [Unleashing the reasoning potential of pre-trained LLMs by critique fine-tuning on one problem](https://arxiv.org/pdf/2506.03295), Jun. 3 2025.
- [On learning verifiers for chain-of-thought reasoning](https://arxiv.org/pdf/2505.22650), May 28 2025.
- [Disentangling reasoning and knowledge in medical large language models](https://arxiv.org/pdf/2505.11462), May 16 2025. [code](https://github.com/togethercomputer/BioMed-R1).
- [Don't overthink passage reranking: Is reasoning truly necessary](https://arxiv.org/abs/2505.16886), May 22 2025.
- [TTRL: Test-time reinforcement learning](https://arxiv.org/pdf/2504.16084), Apr. 22 2025. [code](https://github.com/PRIME-RL/TTRL).
- [Reinforcing compositional retrieval: Retrieving step-by-step for composing informative contexts](https://arxiv.org/pdf/2504.11420), Apr. 15 2025. [code](https://github.com/ruyue0001/Step-by-Step-Retrieval).
- [Med-RLVR: Emerging medical reasoning from a 3b base model via reinforcement learning](https://arxiv.org/pdf/2502.19655), Feb. 27 2025.
- [Distill not only data but also rewards: Can smaller language models surpass larger ones?](https://arxiv.org/pdf/2502.19557), Feb. 26 2025.
- [What makes math problems hard for reinforcement learning: A case study](https://arxiv.org/pdf/2408.15332v2), Feb. 11 2025.
- [Atom of thoughts for Markov LLM test-time scaling](https://arxiv.org/pdf/2502.12018), Mar. 23 2025. [code](https://github.com/qixucen/atom).
- [LLM post-training: A deep dive into reasoning large language models](https://arxiv.org/pdf/2502.21321), Mar. 24 2025.
- [Empowering LLMs with logical reasoning: A comprehensive survey](https://arxiv.org/pdf/2502.15652), Jun. 4 2025.
- [Computational-statistical tradeoffs at the next-token prediction barrier: Autoregressive and imitation learning under misspecification](https://arxiv.org/pdf/2502.12465), Feb. 18 2025.
- [Self-steering language models](https://arxiv.org/pdf/2504.07081), Apr. 9 2025.
- [Reinforcement pre-training](https://arxiv.org/pdf/2506.08007), Jun. 9 2025.
- [AbstRal: Augmenting LLMs' reasoning by reinforcing abstract thinking](https://arxiv.org/pdf/2506.07751), Jun. 11 2025.
- [OctoThinker: Revisiting mid-training in the era of rl scaling](https://natural-rugby-f7c.notion.site/OctoThinker-Revisiting-Mid-Training-In-the-Era-of-RL-Scaling-1d20b810e2d680c494a9f9dad0a90d53), 2025. [code](https://github.com/GAIR-NLP/OctoThinker).
- [Reasoning models don't always say what they think](https://arxiv.org/pdf/2505.05410), May 8 2025.
- [Advancing conversational diagnostic AI with multimodal reasoning](https://arxiv.org/abs/2505.04653), May 6 2025.
- [Perception, reason, think, and plan: A survey on large multimodal reasoning models](https://arxiv.org/pdf/2505.04921), May 8 2025.
- [Scalable chain of thoughts via elastic reasoning](https://arxiv.org/pdf/2505.05315), May 21 2025.
- [Beyond theorem proving: Formulation, framework and benchmark for formal problem-solving](https://arxiv.org/pdf/2505.04528), May 7 2025.
- [When reasoning beats scale: A 1.5b reasoning model outranks 13b LLMs as discriminator](https://arxiv.org/pdf/2505.03786), Apr. 30 2025.
- [Tina: Tiny reasoning models via LoRA](https://arxiv.org/pdf/2504.15777), Apr. 22 2025.
- [LiveCodeBench Pro: How do Olympiad medalists judge LLMs in competitive programming](https://arxiv.org/pdf/2506.11928), Jun. 13 2025.
- [Evaluation is all you need: Strategic overclaiming of LLM reasoning capabilities through evaluation design](https://arxiv.org/pdf/2506.04734), Jun. 10 2025.
- [Beyond gold standards: Epistemic ensemble of LLM judges for formal mathematical reasoning](https://arxiv.org/pdf/2506.10903), Jun. 12 2025.
- [Direct reasoning optimization: LLMs can reward and refine their own reasoning for open-ended tasks](https://arxiv.org/pdf/2506.13351), Jun. 16 2025.
- [Training large language models to reason in a continuous latent space](https://arxiv.org/pdf/2412.06769), Dec. 11 2024.
- [What do learning dynamics reveal about generalization in LLM mathematical reasoning](https://openreview.net/pdf?id=bivU8fTTDo), ICML 2025.
- [Implicit reward as bridge: A unified view of SFT and DPO algorithm](https://arxiv.org/pdf/2507.00018), Jun. 15 2025.
- [Thought anchors: Which LLM reasoning steps matter?](https://arxiv.org/pdf/2506.19143), Jun. 23 2025.
- [AdaCoT: Pareto-optimal adaptive chain-of-thought triggering via reinforcement learning](https://arxiv.org/pdf/2505.11896), May 25 2025.
- [Generalizing verifiable instruction following](https://arxiv.org/pdf/2507.02833), Jul. 3 2025. [code](https://github.com/allenai/IFBench).
- [Wider or deeper? Scaling LLM inference-time compute with adaptive branching tree search](https://arxiv.org/pdf/2503.04412), Jun. 27 2025.
- [Polaris: A post-training recipe for scaling reinforcement learning on advanced reasoning models](https://hkunlp.github.io/blog/2025/Polaris/), Jun. 20 2025. [code](https://github.com/ChenxinAn-fdu/POLARIS).
- [SPIRAL: Self-play on zero-sum games incentivizes reasoning via multi-agent multi-turn reinforcement learning](https://arxiv.org/abs/2506.24119), Jun. 30 2025. [code](https://github.com/spiral-rl/spiral).
- [Inference-aware fine-tuning for best-of-n sampling in large language models](https://arxiv.org/pdf/2412.15287), Dec. 18 2024.
- [Dissecting clinical reasoning in language models: A comparative study of prompts and model adaptation strategies](https://arxiv.org/pdf/2507.04142), Jul. 5 2025.
- [Entropys scheduling](https://howetissue.notion.site/#231618bab567801e90c4ca0c063eede3).
- [Inverse scaling in test-time compute](https://arxiv.org/pdf/2507.14417), Jul. 19 2025. [code](https://safety-research.github.io/inverse-scaling-ttc/).
- [Mixture-of-recursions: Learning dynamic recursive depths for adaptive token-level computation](https://www.alphaxiv.org/abs/2507.10524), Jul. 21 2025. [code](https://github.com/raymin0223/mixture_of_recursions).
- [Disentangling logic: The role of context in large language model reasoning capabilities](https://arxiv.org/pdf/2406.02787), Jun. 4 2024. [code](https://github.com/agiresearch/ContextHub).
- [Learning to discover abstractions for LLM reasoning](https://openreview.net/pdf?id=kzccnANFQ7), ICML 2025 Workshop.

#### Understanding reasoning

- [How well can reasoning models identify and recover from unhelpful thoughts](https://arxiv.org/pdf/2506.10979), Jun. 12 2025.
- [Reasoning by superposition: A theoretical perspective on chain of continuous thought](https://arxiv.org/pdf/2505.12514), May 18 2025.
- [Demystifing long chain-of-thought reasnoning](https://openreview.net/pdf?id=OLodUbcWjB), ICML 2025. [code](https://github.com/eddycmu/demystify-long-cot).
- [Theoretical modeling of LLM self-improvement training dynaics through solver-verifier gap](https://arxiv.org/pdf/2507.00075), Jun. 29 2025.
- [A theory of inference compute scaling: Reasoning through directed stochastic skill search](https://arxiv.org/pdf/2507.00004), Jun. 10 2025.
- [The serial scaling hypothesis](https://arxiv.org/abs/2507.12549), Jul. 16 2025. [tweet](https://x.com/layer07_yuxi/status/1947473214898377108).


