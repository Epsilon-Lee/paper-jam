
### Multi-modality

- [An introduction to vision-language modeling](https://arxiv.org/pdf/2405.17247), May 27 2024. `tutorial`.
- [A Practitionerâ€™s Guide to Continual Multimodal Pretraining](https://arxiv.org/pdf/2408.14471), Aug. 26 2024.
- [Visual agents as fast and slow thinker](https://arxiv.org/pdf/2408.08862), Aug. 16 2024.
- [NVLM: Open Frontier-Class Multimodal LLMs](https://nvlm-project.github.io/), Sep. 17 2024.
- [From generalist to specialist: Adapting vision language models via task-specific visual instruction tuning](https://arxiv.org/pdf/2410.06456), Oct. 9 2024.
- [Sample-efficient integration of new modalities into large language models](https://arxiv.org/pdf/2509.04606), Sep. 4 2025. [code](https://github.com/ospanbatyr/sample-efficient-multimodality).
- [What's in common? Multimodal models hallucinate when reasoning across scenes](https://arxiv.org/abs/2511.03768), Nov. 5 2025.
- [Contamination detection for vlms using multi-modal semantic perturbation](https://arxiv.org/abs/2511.03774), Nov. 5 2025.


