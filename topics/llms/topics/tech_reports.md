
- [Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling](https://arxiv.org/pdf/2304.01373), May 31 2023.
- [Sailor: Open Language Models for South-East Asia](https://arxiv.org/pdf/2404.03608), Apr. 4 2024.
- [LokiLM: Technical Report](https://arxiv.org/abs/2407.07370), Jul. 10 2024.
- [H2O-Danube3 Technical Report](https://arxiv.org/pdf/2407.09276), Jul. 12 2024. `made for smartphone`.
- [Falcon2-11b technical report](https://arxiv.org/pdf/2407.14885), Jul. 20 2024.
- [Aquila2 Technical Report](https://arxiv.org/pdf/2408.07410), Aug. 14 2024.
- [Apriel-Nemotron-15B-Thinker](https://arxiv.org/pdf/2508.10948), Aug. 13 2025.
  - To learn about details of mid-training, e.g. how cpt degrades or inreases scores on various benchmarks
- [Motif 2.6B technical report](https://arxiv.org/pdf/2508.09148), Aug. 2 2025.
- [Apertus tech report](https://github.com/swiss-ai/apertus-tech-report/tree/main), Sep. 1 2025.
- [SmolLM2: When smol goes big - Data-centric training of a fully open small language model](https://openreview.net/pdf?id=3JiCl2A14H), COLM 2025. [code](https://openreview.net/pdf?id=3JiCl2A14H).
- [K2-Think: A parameter-efficient reasoning system](https://arxiv.org/pdf/2509.07604v3), Sep. 9 2025.
- [CWM: An open-weights LLM for research on code generation with world models](https://arxiv.org/pdf/2510.02387). Sep. 30 2025.
- [INTELLECT-3: technical report](https://storage.googleapis.com/intellect-3-paper/INTELLECT_3_Technical_Report.pdf), Nov. 2025..
- [AM-Thinking-v1: Advancing the frontier of reasoning at 32B scale](https://arxiv.org/pdf/2505.08311), May 25 2025.

**Meituan**
- [LongCat-Flash technical report](https://arxiv.org/pdf/2509.01322), Aug. 31 2025.
- [LongCat-Flash-Thinking technical report](https://arxiv.org/abs/2509.18883), Sep. 2025.

**Baichuan**
- [Baichuan-M1: Pushing the medical capability of large language models](https://arxiv.org/pdf/2502.12671), Mar. 5 2025. [code](https://github.com/baichuan-inc/Baichuan-M1-14B).
  - A 14B model.
- [Baichuan-M2: Scaling medical capability with large verifier system](https://arxiv.org/pdf/2509.02208), Sep. 2 2025.
  - A 32B model. 

**Hunyuan**
- [Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated Parameters by Tencent](https://arxiv.org/pdf/2411.02265), Nov. 6 2024.
- [Hunyuan-MT technical report](https://github.com/Tencent-Hunyuan/Hunyuan-MT/blob/main/Hunyuan_MT_Technical_Report.pdf), Sep. 1 2025.
- [HunyuanWolrd 1.0: Generating immersive, explorable, and interactive 3D worlds from words or pixels](https://3d-models.hunyuan.tencent.com/world/HY_World_1_technical_report.pdf), 2025.

**Kimi**
- [Kimi K2: Open agentic intelligence](https://arxiv.org/pdf/2507.20534), Jul. 28 2025.

**Intern**
- [InternLM2 Technical Report](https://arxiv.org/pdf/2403.17297), Mar. 26 2024.
- [InternVL3.5: Advancing open-source multimodal models in versality, reasoning, and efficiency](https://arxiv.org/pdf/2508.18265), Aug. 2025.

**Cohere**
- [Command A: An enterprise-ready large language model](https://cohere.com/research/papers/command-a-technical-report.pdf), Mar. 27 2025.

**Nemotron**
- [Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model](https://arxiv.org/pdf/2201.11990), Feb. 4 2022.
- [Nemotron-4 340B Technical Report](https://d1qx31qr3h6wln.cloudfront.net/publications/Nemotron_4_340B_8T_0.pdf), Jun. 2024.
- [NVIDIA Nemotron Nano 2: An accurate and efficient hybrid Mamba-Transformer reasoning model](https://research.nvidia.com/labs/adlr/files/NVIDIA-Nemotron-Nano-2-Technical-Report.pdf), Aug. 18 2025.
  - The partial pre-training data is available, e.g. Nemotron-CC-v2/Math-v1/Code-v1/SFT-v1, as well as the post-training dataset.
- [Jet-Nemotron: Efficient language model with post neural architecture search](https://arxiv.org/pdf/2508.15884), Aug. 21 2025. [code](https://github.com/NVlabs/Jet-Nemotron).
- [NVIDIA Nemotron nano v2 vl](https://arxiv.org/pdf/2511.03929), Nov. 6 2025.

**Llama series**
- [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971), Feb. 27 2023.
- [Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288), Jul. 18 2023.
- [The Llama 3 Herd of Models](https://arxiv.org/pdf/2407.21783), Jul. 2024.
- [The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation](https://ai.meta.com/blog/llama-4-multimodal-intelligence/), Apr. 5 2025.

**Claude**
- [Introducing Claude](https://www.anthropic.com/news/introducing-claude), Mar. 14 2023.
- [Model Card and Evaluations for Claude Models](https://www-cdn.anthropic.com/bd2a28d2535bfb0494cc8e2a3bf135d2e7523226/Model-Card-Claude-2.pdf), Jul. 8 2023.
- [The Claude 3 Model Family: Opus, Sonnet, Haiku](https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf), [blogpost](https://www.anthropic.com/news/claude-3-family), Mar. 4 2024.
- [System Card: Claude Opus 4 & Claude Sonnet 4](https://www-cdn.anthropic.com/6be99a52cb68eb70eb9572b4cafad13df32ed995.pdf), May 2025.

**GPT series**
- [GPT-4 Technical Report](https://arxiv.org/abs/2303.08774), Mar. 15 2023.
- [GPT-4o System Card](https://arxiv.org/pdf/2410.21276), Aug. 8 2024.
- [OpenAI o3 and o4-mini system card](https://cdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/o3-and-o4-mini-system-card.pdf), Apr. 16 2025.
- [gpt-oss-120b & gpt-oss-20b model card](https://cdn.openai.com/pdf/419b6906-9da6-406c-a19d-1bb078ac7637/oai_gpt-oss_model_card.pdf), Aug. 5 2025.

**Phi series**
- [Textbooks Are All You Need](https://arxiv.org/pdf/2306.11644), Oct. 2 2023.
- [Textbooks Are All You Need II: phi-1.5 technical report](https://arxiv.org/abs/2309.05463), Sep. 11 2023.
- [Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone](https://arxiv.org/abs/2404.14219), Apr. 22 2024.
- [Phi-4 technical report](https://arxiv.org/pdf/2412.08905), Dec. 12 2024.
- [Phi-4-Mini technical report: Compact yet powerful multimodal language models via mixture-of-loras](https://arxiv.org/pdf/2503.01743), Mar. 7 2025.

**Gemini and Gemma**
- [Scaling Language Models: Methods, Analysis & Insights from Training Gopher](https://arxiv.org/pdf/2112.11446), Jan. 21 2022.
- [Gemini: A Family of Highly Capable Multimodal Models](https://arxiv.org/pdf/2312.11805), Jun. 17 2024.
- [Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context](https://arxiv.org/pdf/2403.05530), Jun. 14 2024.
- [Gemma 2: Improving Open Language Models at a Practical Size](https://storage.googleapis.com/deepmind-media/gemma/gemma-2-report.pdf), Jun. 27 2024.
- [Introducing Gemini 2.0: our new AI model for the agentic era](https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#ceo-message).
- [Gemma 3 technical report](https://arxiv.org/pdf/2503.19786), Mar. 25 2025.
- [Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context and next generation agentic capabilities](https://arxiv.org/pdf/2507.06261), Jul. 11 2025.

**Deepseek series**
- [DeepSeek LLM: Scaling Open-Source Language Models with Longtermism](https://arxiv.org/abs/2401.02954), Jan. 2024.
- [DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model](https://arxiv.org/abs/2405.04434), May 7 2024.
- [DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence](https://arxiv.org/abs/2406.11931), Jun. 17 2024.
- [DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search](https://arxiv.org/pdf/2408.08152), Aug. 2024.
- [DeepSeek-V3 Technical Report](https://arxiv.org/abs/2412.19437), Dec. 26 2024.
- [DeepSeek-R1: Incentivizing reasoning ability in LLMs via reinforcement learning](https://arxiv.org/abs/2501.12948), Jan. 22 2025.

**AI2**
- [Olmoe: Open mixture-of-experts language models](https://arxiv.org/pdf/2409.02060), Sep. 3 2024. [data](https://huggingface.co/datasets/allenai/OLMoE-mix-0924).
- [OLMo: Accelerating the Science of Language Models](https://arxiv.org/abs/2402.00838), Feb. 1 2024.
- [OLMo 2: The best fully open language model to date](https://allenai.org/blog/olmo2), Nov. 26 2024.
- [TÃœLU 3: Pushing Frontiers in Open Language Model Post-Training](https://arxiv.org/pdf/2411.15124), Dec. 6 2024.
- [2 OLMo 2 Furious](https://arxiv.org/pdf/2501.00656), Dec. 31 2024.

**Qwen series**
- [Qwen Technincal Report](https://arxiv.org/pdf/2309.16609), Sep. 28 2023.
- [Qwen2 technical report](https://arxiv.org/pdf/2407.10671), Jul. 15 2024.
- [Qwen2.5 Technical Report](https://arxiv.org/pdf/2412.15115), Dec. 19 2024.
- [Qwen3 Technical Report](https://arxiv.org/pdf/2505.09388), May 15 2025.
- [Qwen2.5-Omni Technical Report](https://arxiv.org/pdf/2503.20215), Mar. 26 2025.
- [Qwen3Guard technical report](https://arxiv.org/pdf/2510.14276), Oct. 16 2025.

**Ant's InclusionAI**
- [Ling tech report - Every FLOPs counts: Scaling a 300b moe ling llm without premium gpus](https://arxiv.org/pdf/2503.05139?), Mar. 10 2025.
- [Ring tech report - Every attent matters: An efficient hybrid architecture for long-context reasoning](https://arxiv.org/pdf/2510.19338v2), Oct. 23 2025.

**MiniCPM**
- [MiniCPM4: Ultra-efficient LLMs on end devices](https://arxiv.org/pdf/2506.07900), Jun. 9 2025.
- [MiniCPM-V 4.5: Cooking efficient MLLMs via architecture, data, and training recipes](https://arxiv.org/pdf/2509.18154), Sep. 16 2025.

**Mistral AI**
- [Magistral](https://arxiv.org/pdf/2506.10910), Jun. 12 2025.

**MiniMax**
- [MiniMax-01: Scaling foundation models with lightning attention](https://arxiv.org/pdf/2501.08313), Jan. 14 2025. [code](https://github.com/MiniMax-AI/MiniMax-01).
- [MiniMax-M1: Scaling test-time compute efficiently with lightning attention](https://github.com/MiniMax-AI/MiniMax-M1/blob/main/MiniMax_M1_tech_report.pdf), Jun. 16 2025.

**GLM**
- [ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools](https://arxiv.org/pdf/2406.12793), Jun. 18 2024.
- [GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning](https://arxiv.org/pdf/2507.01006), Jul. 2 2025.
- [GLM-4.5: Agentic, reasoning, and coding (ARC) foundation models](https://arxiv.org/pdf/2508.06471), Aug. 8 2025.

**MiMo**
- [MiMo: Unlocking the reasoning potential of language model - From pretraining to posttraining](https://arxiv.org/pdf/2505.07608), Jun. 5 2025.

**Kwai**
- [Kwai Keye-VL technical report](https://arxiv.org/pdf/2507.01949), Jul. 2 2025.
- [Kwai Keye-VL 1.5 technical report](https://arxiv.org/pdf/2509.01563), Sep. 1 2025. [code](https://github.com/Kwai-Keye/Keye).

**Hermes** by NousResearch
> They mostly conducted post-training, so they use base models from Llama and Qwen series.
- [Hermes 3 technical report](https://arxiv.org/pdf/2408.11857), Aug. 15 2024.
- [Hermes 4 technical report](https://arxiv.org/pdf/2508.18255), Sep. 2 2025.

**StepFun**
- [Step-video-t2v techinical report: The practices, challenges, and future of video foundation model](https://arxiv.org/pdf/2502.10248v1), Feb. 14 2025.
- [Step-3 is Large yet Affordable: Model-system Co-design for Cost-effective Decoding](https://arxiv.org/pdf/2507.19427), Jul. 25 2025.
- [Step-audiao-editx technical report](https://arxiv.org/pdf/2511.03601), Nov. 19 2025.
- [Step-audio-r1 technical report](https://arxiv.org/pdf/2511.15848), Nov. 26 2025.

**Doubao, aka. Seed**
- [Seed-coder: Let the code model curate data for itself](https://arxiv.org/pdf/2506.03524), Jun. 2025

### Domain LLMs

- [Galactica: A Large Language Model for Science](https://arxiv.org/pdf/2211.09085), Nov. 16 2022. `science`.
- [HuatuoGPT, towards taming language models to be a doctor](https://arxiv.org/pdf/2305.15075), May 24 2023.
- [InternLM-Law: An Open Source Chinese Legal Large Language Model](https://arxiv.org/pdf/2406.14887), Jun. 21 2024. `domain llms` `post-training`.
- [LiLiuM: eBay's Large Language Models for E-Commerce](https://arxiv.org/pdf/2406.12023), Jun. 17 2024.
- [SaulLM-54B & SaulLM-141B: Scaling Up Domain Adaptation for the Legal Domain](https://arxiv.org/pdf/2407.19584), Jul. 29 2024. `legal`.
- [SeaLLMs - Large Language Models for Southeast Asia](https://arxiv.org/pdf/2312.00738), Jul. 1 2024. `multilinguality`.
- [SeaLLMs 3: Open Foundation and Chat Multilingual Large Language Models for Southeast Asian Languages](https://arxiv.org/pdf/2407.19672), Jul. 29 2024. `multilinguality`.
- [Med42-v2: A suite of clinical LLMs](https://arxiv.org/pdf/2408.06142), Aug. 12 2024.
- [MedGemma technical report](https://arxiv.org/pdf/2507.05201), Jul. 7 2025.
- [Fleming-R1: Toward expert-level medical reasoning via reinforcement learning](https://arxiv.org/pdf/2509.15279), Sep. 18 2025. [code](https://github.com/UbiquantAI/Fleming-R1).

### Audio LLMs

- [MiMo-Audio](https://xiaomimimo.github.io/MiMo-Audio-Demo/). [paper](https://github.com/XiaomiMiMo/MiMo-Audio/blob/main/MiMo-Audio-Technical-Report.pdf). Sep. 2025.
- [VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning](https://github.com/OpenBMB/VoxCPM), Sep. 2025.


