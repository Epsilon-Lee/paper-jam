

> The science of dissecting LLMs.

### Interpretability

- [Transformer feed-forward layers are key-value memories](https://arxiv.org/pdf/2012.14913), Sep. 5 2021.
- [Transformer feed-forward layers build predictions by prompting concepts in the vocabulary space](https://arxiv.org/pdf/2203.14680), Oct. 2022.
- [Do large language models latently perform multi-hop reasoning?](https://arxiv.org/pdf/2402.16837), Feb. 26 2024.
- [A Hopfieldian View-based Interpretation for Chain-of-Thought Reasoning](https://arxiv.org/pdf/2406.12255), Jun. 18 2024. `interpretability`.
- [Exploring the Impact of a Transformerâ€™s Latent Space Geometry on Downstream Task Performance](https://arxiv.org/pdf/2406.12159), Jun. 18 2024.
- [Pre-trained Large Language Models Use Fourier Features to Compute Addition](https://arxiv.org/pdf/2406.03445), Jun. 5 2024. `mechanistic interpretability`.
- [Compact Proofs of Model Performance via Mechanistic Interpretability](https://arxiv.org/pdf/2406.11779), Jun. 17 2024. `mechanistic interpretability`.
- [Probing the Decision Boundaries of In-context Learning in Large Language Models](https://arxiv.org/pdf/2406.11233), Jun. 17 2024. [tweet](https://x.com/siyan_zhao/status/1805277462890492321). `interpretability`.
- [Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs](https://arxiv.org/pdf/2406.20086), Jun. 28 2024. [code](https://footprints.baulab.info/). `mechanistic interpretability`.
- [Transcoders Find Interpretable LLM Feature Circuits](https://arxiv.org/pdf/2406.11944), Jun. 17 2024. `mechanistic interpretability`.
- [Estimating Knowledge in Large Language Models Without Generating a Single Token](https://arxiv.org/pdf/2406.12673), Jun. 18 2024.
- [Transformer Layers as Painters](https://arxiv.org/pdf/2407.09298), Jul. 12 2024. `representation similarity`.
- [LLM Circuit Analyses Are Consistent Across Training and Scale](https://arxiv.org/pdf/2407.10827), Jul. 15 2024.
  - _"we track how model mechanisms, operationalized as circuits, emerge and evolve across 300 billion tokens of training in decoder-only LLMs, in models ranging from 70b to 2.8b parameters."_
- [Understanding Counting in Small Transformers: The Interplay between Attention and Feed-Forward Layers](https://arxiv.org/pdf/2407.11542), Jul. 16 2024.
- [Mechanistically Interpreting a Transformer-based 2-SAT Solver: An Axiomatic Approach](https://arxiv.org/pdf/2407.13594), Jul. 18 2024. [code](https://github.com/nilspalumbo/sat-mi).
- [Adversarial Circuit Evaluation](https://arxiv.org/pdf/2407.15166), Jul. 21 2024. `circuits stability`.
  - _" indicating that more robust circuits are needed for safety-critical applications."_
- [NNsight and NDIF: Democratizing access to foundational model internals](https://arxiv.org/pdf/2407.14561), Jul. 18 2024.
- [Generalization v.s. memorization: Tracing language models' capability back to pretraining data](https://arxiv.org/pdf/2407.14985), Jul. 20 2024.
- [When Can Transformers Count to n?](https://arxiv.org/pdf/2407.15160), Jul. 21 2024.
- [Dissecting Multiplication in Transformers: Insights into LLMs](https://arxiv.org/pdf/2407.15360), Jul. 22 2024.
- [Answer, Assemble, Ace: Understanding How Transformers Answer Multiple Choice Questions](https://arxiv.org/pdf/2407.15018), Jul. 21 2024.
- [Latent causal probing: A formal perspective on probing with causal models of data](https://arxiv.org/pdf/2407.13765), Jul. 18 2024.
- [Demystifying Verbatim Memorization in Large Language Models](https://arxiv.org/pdf/2407.17817), Jul. 25 2024. `verbatim memorization`
  - verbatim meaning: in a way that uses exactly the same words as were originally used.
- [iNNspector: Visual, Interactive Deep Model Debugging](https://arxiv.org/pdf/2407.17998), Jul. 25 2024.
- [Relating the Seemingly Unrelated: Principled Understanding of Generalization for Generative Models in Arithmetic Reasoning Tasks](https://arxiv.org/pdf/2407.17963), Jul. 25 2024.
- [Transformers on Markov Data: Constant Depth Suffices](https://arxiv.org/pdf/2407.17686), Jul. 25 2024. [code](https://github.com/Bond1995/Constant-depth-Transformers).
- [Unlocking Tokens as Data Points for Generalization Bounds on Larger Language Models](https://arxiv.org/pdf/2407.18158), Jul. 25 2024.
  - _"With Monarch matrices, Kronecker factorizations, and post-training quantization, we achieve non-vacuous generalization bounds for LLMs as large as LLaMA2-70B"_.
- [Physics of Language Models: Part 2.1, Grade-School Math and the Hidden Reasoning Process](https://arxiv.org/pdf/2407.20311), Jul. 29 2024.
- [Physics of Language Models: Part 2.2, How to Learn From Mistakes on Grade-School Math Problems](https://arxiv.org/pdf/2408.16293), Aug. 29 2024.
- [Memory-efficient Training of LLMs with Larger Mini-batches](https://arxiv.org/pdf/2407.19580), Jul. 28 2024.
- [The Quest for the Right Mediator: A History, Survey, and Theoretical Grounding of Causal Interpretability](https://arxiv.org/pdf/2408.01416), Aug. 2 2024.
- [Gemma Scope: Open Sparse Autoencoders Everywhere All At Once on Gemma 2](https://arxiv.org/pdf/2408.05147), Aug. 9 2024.
- [Mathematical Models of Computation in Superposition](https://arxiv.org/pdf/2408.05451), Aug. 10 2024.
- [Causal Abstraction: A Theoretical Foundation for Mechanistic Interpretability](https://arxiv.org/pdf/2301.04709), Aug. 7 2024.
  - [Causal Abstractions of Neural Networks](https://proceedings.neurips.cc/paper_files/paper/2021/file/4f5c422f4d49a5a807eda27434231040-Paper.pdf), NeurIPS 2021.
- [A Mechanistic Interpretation of Syllogistic Reasoning in Auto-Regressive Language Models](https://arxiv.org/pdf/2408.08590), Aug. 16 2024.
- [Where is the signal in tokenization space?](https://arxiv.org/pdf/2408.08541), Aug. 16 2024.
- [Reframing Human-AI Collaboration for Generating Free-Text Explanations](https://arxiv.org/abs/2112.08674), Dec. 16 2021.
  - _"Our approach is able to consistently filter GPT-3-generated explanations deemed acceptable by humans"_
- [Modularity in Transformers: Investigating Neuron Separability & Specialization](https://arxiv.org/pdf/2408.17324), Aug. 30 2024.
- [Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space](https://arxiv.org/pdf/2406.19370), Jun. 27 2024.
- [CONTEXTCITE: Attributing Model Generation to Context](https://openreview.net/pdf?id=PbIe0MNDQx),  ICML 2024 workshop.
- [A percolation model of emergence: Analyzing Transformers trained on a formal language](https://arxiv.org/pdf/2408.12578), Aug. 22 2024. [code](https://github.com/EkdeepSLubana/ConceptPercolation).
- [CONTEXTCITE: Attributing Model Generation to Context](https://arxiv.org/pdf/2409.00729), Sep. 1 2024.
- [Evaluating Synthetic Activations composed of SAE Latents in GPT-2](https://arxiv.org/pdf/2409.15019), Sep. 23 2024.
- [Investigating Layer Importance in Large Language Model](https://arxiv.org/pdf/2409.14381), Sep. 22 2024.
- [Transformer-Based Models Are Not Yet Perfect At Learning to Emulate Structural Recursion](https://arxiv.org/pdf/2401.12947), Jan. 2024.
- [Residual Stream Analysis with Multi-Layer SAEs](https://arxiv.org/pdf/2409.04185), Sep. 6 2024. [code](https://github.com/tim-lawson/mlsae).
- [Characterizing stable regions in the residual stream of LLM](https://proceedings.mlr.press/v202/li23l/li23l.pdf), Sep. 26 2024.
- [Understanding Transformers via N-gram Statistics](https://www.arxiv.org/pdf/2407.12034), Jun. 30 2024.
- [Understanding Linear Probing then Fine-tuning Language Models from NTK Perspective](https://arxiv.org/pdf/2405.16747), May 27 2024.
- [Beyond Scaling Laws: Understanding Transformer Performance with Associative Memory](https://arxiv.org/pdf/2405.08707), May 14 2024.
- [Talking Heads: Understanding Inter-layer Communication in Transformer Language Models](https://arxiv.org/pdf/2406.09519), Jun. 13 2024.
- [Transcoders Find Interpretable LLM Feature Circuits](https://arxiv.org/pdf/2406.11944), Jun. 17 2024. [github](https://github.com/jacobdunefsky/transcoder_circuits).
- [InterpBench: Semi-Synthetic Transformers for Evaluating Mechanistic Interpretability Techniques](https://arxiv.org/pdf/2407.14494), Jul. 19 2024.
- [On Mesa-Optimization in Autoregressively Trained Transformers: Emergence and Capability](https://arxiv.org/abs/2405.16845), May 27 2024.
- [Uncovering mesa-optimization algorithms in transformers](https://arxiv.org/pdf/2309.05858), Sep. 11 2023.
- [Causal Estimation of Memorisation Profiles](https://arxiv.org/pdf/2406.04327), Jun. 6 2024.
- [Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data](https://arxiv.org/pdf/2404.01413), Apr. 29 2024.
- [Recurrent Neural Networks Learn to Store and Generate Sequences using Non-Linear Representations](https://arxiv.org/pdf/2408.10920), Aug. 29 2024. [github](https://github.com/robertcsordas/onion_representations).
- [Recite, Reconstruct, Recollect: Memorization in LMs as a Multifaceted Phenomenon](https://arxiv.org/pdf/2406.17746), Jun. 25 2024. `memorization`.
- [Active-Dormant Attention Heads: Mechanistically Demystifying Extreme-Token Phenomena in LLMs](https://arxiv.org/pdf/2410.13835), Oct. 17 2024.
- [Hypothesis Testing the Circuit Hypothesis in LLMs](https://arxiv.org/pdf/2410.13032), Oct. 16 2024. `circuits`.
- [Mechanistic?](https://arxiv.org/pdf/2410.09087), Oct. 7 2024.
- [When attention sink emerges in language models: An empirical view](https://arxiv.org/pdf/2410.10781), Oct. 14 2024.
- [Investigating sensitive directions in GPT-2: An improved baseline and comparative analysis of SAEs](https://arxiv.org/pdf/2410.12555), Oct. 16 2024.
- [Analyzing (In)Abilities of SAEs via Formal Languages](https://arxiv.org/pdf/2410.11767), Oct. 15 2024.
- [VibeCheck: Discover & quantify qualitative differences in large language models](https://arxiv.org/pdf/2410.12851), Oct. 28 2024. [code](https://github.com/lisadunlap/VibeCheck).
- [Distinguishing ignorance from error in LLM hallucinations](https://arxiv.org/pdf/2410.22071), Oct. 29 2024. [code](https://github.com/technion-cs-nlp/hallucination-mitigation).
- [Features that Make a Difference: Leveraging Gradients for Improved Dictionary Learning](https://arxiv.org/pdf/2411.10397), Nov. 15 2024.
- [Mechanism and emergence of stacked attention heads in multi-layer transformers](https://arxiv.org/pdf/2411.12118), Nov. 18 2024.
- [AttriBoT: A Bag of Tricks for Efficiently Approximating Leave-One-Out Context Attribution](https://arxiv.org/pdf/2411.15102), Nov. 22 2024. [code](https://github.com/r-three/AttriBoT).
- [Does representation matter? Exploring intermediate layers in large language models](https://arxiv.org/abs/2412.09563), Dec. 12 2024.
- [Capturing the temporal dependence of training data influence](https://arxiv.org/pdf/2412.09538), Dec. 12 2024.
- [LatentQA: Teaching llms to decode activations into natural language](https://arxiv.org/pdf/2412.08686), Dec. 11 2024. [code](https://github.com/aypan17/latentqa), [blogpost](https://latentqa.github.io/).
- [The buffer mechanism for multi-step information reasoning in language models](https://arxiv.org/pdf/2405.15302), 2024.
- [Gradient routing: Masking gradients to localize computation in neural networks](https://arxiv.org/pdf/2410.04332), Nov. 29 2024. [blogpost](https://turntrout.com/gradient-routing).
- [Knowledge Mechanisms in Large Language Models: A Survey and Perspective](https://arxiv.org/pdf/2407.15017), Dec. 24 2024.
- [Open problems in mechanistic interpretability](https://arxiv.org/pdf/2501.16496), Jan. 27 2024.

#### Auto-intepretation

- [Can Large Language Models Explain Themselves? A Study of LLM-Generated Self-Explanations](https://arxiv.org/pdf/2310.11207), Oct. 17 2023.
- [SelfIE: Self-Interpretation of Large Language Model Embeddings](https://arxiv.org/pdf/2403.10949), Mar. 26 2024.
- [Are self-explanations from Large Language Models faithful?](https://arxiv.org/pdf/2401.07927), May 16 2024.
- [FaithLM: Towards Faithful Explanations for Large Language Models](https://arxiv.org/pdf/2402.04678), Jun. 26 2024.

#### Complexity theory of transformers and beyond

- [LSTM recurrent networks learn simple context free and context sensitive languages](https://sferics.idsia.ch/pub/juergen/L-IEEE.pdf), 2001.
- [On the Practical Computational Power of Finite Precision RNNs for Language Recognition(https://arxiv.org/pdf/1805.04908), May 13 2018.
- [On the Turing completeness of mordern neural network architecture](https://arxiv.org/abs/1901.03429), Jan. 10 2019.
- [A Formal Hierarchy of RNN Architectures](https://arxiv.org/pdf/2004.08500), Sep. 19 2020.
- [Theoretical Limitations of Self-Attention in Neural Sequence Models](https://arxiv.org/abs/1906.06755), Feb. 12 2020.
- [Attention is Turing Complete](https://jmlr.org/papers/volume22/20-302/20-302.pdf), JMLR 2021.
- [What Formal Languages Can Transformers Express? A Survey](https://arxiv.org/pdf/2311.00208), Sep. 4 2024.
- [Transformers in DLOGTIME-Uniform TC0](https://arxiv.org/pdf/2409.13629), Sep. 2024.
- [On the practical computational power of finite precision rnns for language recognition](https://aclanthology.org/P18-2117.pdf), ACL 2018.
- [On Efficiently Representing Regular Languages as RNNs](https://aclanthology.org/2024.findings-acl.244.pdf), ACL 2024. [code](https://github.com/rycolab/bpdas).
- [InversionView: A general-purpose method for reading information from neural activations](https://arxiv.org/pdf/2405.17653), Nov. 2 2024. [code](https://github.com/huangxt39/InversionView).

#### Theory of Transformers

- [Representational Strengths and Limitations of Transformers](https://arxiv.org/pdf/2306.02896), Nov. 16 2023.
- [A mathematical perspective on Transformers](https://arxiv.org/pdf/2312.10794), Aug. 12 2024.
- [How Transformers learn structured data: Insights from hierarchical filtering](https://arxiv.org/pdf/2408.15138), Aug. 27 2024.
- [Out-of-distribution generalization via composition: a lens through induction heads in Transformers](https://arxiv.org/pdf/2408.09503), Aug. 18 2024.
- [Transformers in DLOGTIME-Uniform TC0](https://arxiv.org/pdf/2409.13629), Sep. 20 2024.
- [Optimal Memorization Capacity of Transformers](https://arxiv.org/pdf/2409.17677), Sep. 26 2024.
- [Neural Networks Generalize on Low Complexity Data](https://arxiv.org/pdf/2409.17357), Sep. 25 2024.
- [Learning linear attention in polynomial time](https://arxiv.org/pdf/2410.10101), Oct. 18 2024.
- [Bilinear sequence regression: A model for learning from long sequences of high-dimensional tokens](https://arxiv.org/pdf/2410.18858), Oct. 24 2024. [code](https://github.com/SPOC-group/bilinear-sequence-regression).
- [Circuit Complexity Bounds for RoPE-based Transformer Architecture](https://arxiv.org/pdf/2411.07602), Nov. 12 2024.
- [Unraveling the Gradient Descent Dynamics of Transformers](https://arxiv.org/pdf/2411.07538), Nov. 12 2024.
- [One-Layer Transformer Provably Learns One-Nearest Neighbor In Context](https://arxiv.org/pdf/2411.10830), Nov. 16 2024.
- [When can transformers ground and compose: Insights from compositional generalization benchmarks](https://arxiv.org/pdf/2210.12786), Oct. 31 2022. [code](https://github.com/ankursikarwar/Grounded-Compositional-Generalization).

#### Theory of pre-training

- [A Law of Next-Token Prediction in Large Language Models](https://arxiv.org/pdf/2408.13442), Aug. 24 2024.
- [Non-asymptotic Convergence of Training Transformers for Next-token Prediction](https://arxiv.org/pdf/2409.17335), Sep. 25 2024.
- [Benign or Not-Benign Overfitting in Token Selection of Attention Mechanism](https://arxiv.org/pdf/2409.17625), Sep. 26 2024.
- [Implicit Bias of Next-Token Prediction](https://arxiv.org/pdf/2402.18551), Feb. 28 2024.

#### Theory of icl and prompting

- [One-layer transformers fail to solve the induction heads task](https://arxiv.org/pdf/2408.14332), Aug. 26 2024.
- [Unveiling the Statistical Foundations of Chain-of-Thought Prompting Methods](https://arxiv.org/pdf/2408.14511), Aug. 25 2024.
- [In-Context Learning with Representations: Contextual Generalization of Trained Transformers](https://arxiv.org/pdf/2408.10147), Aug. 19 2024.
- [A Mechanism for Sample-Efficient In-Context Learning for Sparse Retrieval Tasks](https://proceedings.mlr.press/v237/abernethy24a/abernethy24a.pdf), alt 2024.
- [Unveiling Induction Heads: Provable Training Dynamics and Feature Learning in Transformers](https://arxiv.org/pdf/2409.17357), Sep. 25 2024.
- [Transformers as Algorithms: Generalization and Stability in In-context Learning](https://proceedings.mlr.press/v202/li23l/li23l.pdf), ICML 2023.
- [ALPINE: Unveiling the Planning Capability of Autoregressive Learning in Language Models](https://arxiv.org/pdf/2405.09220). May 27 2024.
- [Can in-context learning really generalize to out-of-distribution tasks?](https://arxiv.org/pdf/2410.09695), Oct. 13 2024.
- [Towards the effect of examples on in-context learning: A theoretical case study](https://arxiv.org/pdf/2410.09411), Oct. 12 2024.
- [Inference and Verbalization Functions During In-Context Learning](https://arxiv.org/pdf/2410.09349), Oct. 12 2024. [code](https://github.com/JunyiTao/infer-then-verbalize-during-icl).
- [How Transformers Implement Induction Heads: Approximation and Optimization Analysis](https://arxiv.org/pdf/2410.11474), Oct. 16 2024.
- [Context-scaling versus task-scaling in in-context learning](https://arxiv.org/pdf/2410.12783), Oct. 16 2024.
- [A theory of emergent in-context learning as implicit structure induction](https://arxiv.org/pdf/2303.07971), Mar. 14 2024.
- [Can generative ai solve your in-context learning problem? A martingale perspective](https://arxiv.org/pdf/2412.06033), Dec. 8 2024.


