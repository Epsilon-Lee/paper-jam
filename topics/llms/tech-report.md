
- [Scaling Language Models: Methods, Analysis & Insights from Training Gopher](https://arxiv.org/pdf/2112.11446), Jan. 21 2022.
- [Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model](https://arxiv.org/pdf/2201.11990), Feb. 4 2022.
- [QWen Technincal Report](https://arxiv.org/pdf/2309.16609), Sep. 28 2023.
- [Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling](https://arxiv.org/pdf/2304.01373), May 31 2023.
- [InternLM2 Technical Report](https://arxiv.org/pdf/2403.17297), Mar. 26 2024.
- [Sailor: Open Language Models for South-East Asia](https://arxiv.org/pdf/2404.03608), Apr. 4 2024.
- [DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence](https://arxiv.org/pdf/2406.11931), Jun. 17 2024.
- [Nemotron-4 340B Technical Report](https://d1qx31qr3h6wln.cloudfront.net/publications/Nemotron_4_340B_8T_0.pdf), Jun. 2024.
- [ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools](https://arxiv.org/pdf/2406.12793), Jun. 18 2024.
- [Gemini: A Family of Highly Capable Multimodal Models](https://arxiv.org/pdf/2312.11805), Jun. 17 2024.
- [Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context](https://arxiv.org/pdf/2403.05530), Jun. 14 2024.
- [Gemma 2: Improving Open Language Models at a Practical Size](https://storage.googleapis.com/deepmind-media/gemma/gemma-2-report.pdf), Jun. 27 2024.
- [H2O-Danube3 Technical Report](https://arxiv.org/pdf/2407.09276), Jul. 12 2024.
- [LokiLM: Technical Report](https://arxiv.org/abs/2407.07370), Jul. 10 2024.
- [H2O-Danube3 Technical Report](https://arxiv.org/pdf/2407.09276), Jul. 12 2024. `made for smartphone`.
- [Qwen2 technical report](https://arxiv.org/pdf/2407.10671), Jul. 15 2024.
- [Falcon2-11b technical report](https://arxiv.org/pdf/2407.14885), Jul. 20 2024.
- [The Llama 3 herd of models](https://scontent-nrt1-1.xx.fbcdn.net/v/t39.2365-6/452387774_1036916434819166_4173978747091533306_n.pdf?_nc_cat=104&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=t6egZJ8QdI4Q7kNvgGEgnHv&_nc_ht=scontent-nrt1-1.xx&oh=00_AYCRNeyng8Ti3PRi27xvMptEr8ajxVxOVJhz9PanLEya1g&oe=66A642CD), Jul. 23 2024.
- [Aquila2 Technical Report](https://arxiv.org/pdf/2408.07410), Aug. 14 2024.
- [DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search](https://arxiv.org/pdf/2408.08152).

### Domain LLMs

- [Galactica: A Large Language Model for Science](https://arxiv.org/pdf/2211.09085), Nov. 16 2022. `science`.
- [HuatuoGPT, towards taming language models to be a doctor](https://arxiv.org/pdf/2305.15075), May 24 2023.
- [InternLM-Law: An Open Source Chinese Legal Large Language Model](https://arxiv.org/pdf/2406.14887), Jun. 21 2024. `domain llms` `post-training`.
- [LiLiuM: eBay's Large Language Models for E-Commerce](https://arxiv.org/pdf/2406.12023), Jun. 17 2024.
- [SaulLM-54B & SaulLM-141B: Scaling Up Domain Adaptation for the Legal Domain](https://arxiv.org/pdf/2407.19584), Jul. 29 2024. `legal`.
- [SeaLLMs - Large Language Models for Southeast Asia](https://arxiv.org/pdf/2312.00738), Jul. 1 2024. `multilinguality`.
- [SeaLLMs 3: Open Foundation and Chat Multilingual Large Language Models for Southeast Asian Languages](https://arxiv.org/pdf/2407.19672), Jul. 29 2024. `multilinguality`.

